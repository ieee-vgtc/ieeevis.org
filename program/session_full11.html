<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/2.1/auth0-spa-js.production.js"></script><script>
              const auth0_domain = "ieeevis.us.auth0.com";
              const auth0_client_id = "oF5BXUklWOjSjUeg5Tzai2DysHITXYhT";
            </script><script src="/static/2025/js/modules/auth0protect.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2025/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2025/js/data/persistor.js"></script><script src="/static/2025/js/data/api.js"></script><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2025/css/Zilla.css" rel="stylesheet"><link href="/static/2025/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2025/css/main.css"><link rel="stylesheet" href="/static/2025/css/fa_solid.css"><link rel="stylesheet" href="/static/2025/css/lazy_load.css"><link rel="stylesheet" href="/static/2025/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2025 - Session: VIS Full Papers: Embeddings & Metrics"><meta name="twitter:description" content="See the session and its presentations inside."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="See the session and its presentations inside."><meta name="title" property="og:title" content="Virtual IEEE VIS 2025 - Session: VIS Full Papers: Embeddings & Metrics"><meta property="og:type" content="website"><title>IEEE VIS 2025 Content: VIS Full Papers: Embeddings &amp; Metrics</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style="display: none;"><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-8"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item" aria-current="page"><a href="events.html">All events</a></li><li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">Embeddings &amp; Metrics</li></ol></nav><h1 class="session-title">VIS Full Papers: Embeddings &amp; Metrics</h1><h3 class="session-url"><a href="https://ieeevis.org/year/2025/program/event_v-full.html" target="_blank"><span class="fas mr-1">&#xf57c;</span> https://ieeevis.org/year/2025/program/event_v-full.html</a></h3><h3 class="session-chair"><span class="fas mr-1">&#xf007;</span> Session chair: Rebecca Faust </h3><h3 class="session-room mt-4"> Room: Hall E2 </h3><h3 class="session-date"><span class="fas mr-1">&#xf017;</span><span class="format-date-span-full">2025-11-05T13:00:00+00:00 &ndash; 2025-11-05T14:15:00+00:00</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2025-11-05T13:00:00+00:00 &ndash; 2025-11-05T14:15:00+00:00</span><span class="current-time tztooltiptext"></span></span></h3></div><div class="col-md-1"></div><div class="col-md-3 session-links"><h5 class="session-info my-4"><a href="#list"><span class="fas mr-2">&#xf358;</span> Jump to event listing </a></h5><h5 class="session-info my-4"><a href="https://data.tech.ieeevis.org/storage/v1/object/public/ics/vis2025/full11.ics"><span class="fas mr-2">&#xf073;</span> Add to Calendar</a></h5></div></div><div class="row my-5 discord-public-link hide-auth-controls"><div class="col-md-8"><p><span class="fas mx-1">&#xf086;</span><a href="https://discord.com/channels/1422883912660549696/1430945422318505994" target="_blank">Discord link</a></p></div></div><div class="row my-5"><div class="col-md-8"><p>Recordings will be made available after the session.</p></div></div><hr><div class="row my-4"><div class="col-md-8"><h2 class="room_session_descriptor d-block py-2"><a name="list">Presentations in this session:</a></h2></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1641&#39;, &#39;session_id&#39;: &#39;full11&#39;, &#39;title&#39;: &#39;GhostUMAP2: Measuring and Analyzing (r,d)-Stability of UMAP&#39;, &#39;contributors&#39;: [&#39;Myeongwon Jung&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T13:00:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T13:00:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T13:12:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Myeongwon Jung&#39;, &#39;email&#39;: &#39;mw.jung@skku.edu&#39;, &#39;affiliation&#39;: &#39;Sungkyunkwan University&#39;}, {&#39;name&#39;: &#39;Takanori Fujiwara&#39;, &#39;email&#39;: &#39;tfujiwara@ucdavis.edu&#39;, &#39;affiliation&#39;: &#39;Linköping University&#39;}, {&#39;name&#39;: &#39;Jaemin Jo&#39;, &#39;email&#39;: &#39;jmjo@skku.edu&#39;, &#39;affiliation&#39;: &#39;Sungkyunkwan University&#39;}], &#39;abstract&#39;: &#39;Despite the widespread use of Uniform Manifold Approximation and Projection (UMAP), the impact of its stochastic optimization process on the results remains underexplored. We observed that it often produces unstable results where the projections of data points are determined mostly by chance rather than reflecting neighboring structures. To address this limitation, we introduce (r,d)-stability to UMAP: a framework that analyzes the stochastic positioning of data points in the projection space. To assess how stochastic elements—specifically, initial projection positions and negative sampling—impact UMAP results, we introduce “ghosts”, or duplicates of data points representing potential positional variations due to stochasticity. We define a data point’s projection as (r,d)-stable if its ghosts perturbed within a circle of radius r in the initial projection remain confined within a circle of radius d for their final positions. To efficiently compute the ghost projections, we develop an adaptive dropping scheme that reduces a runtime up to 60% compared to an unoptimized baseline while maintaining approximately 90% of unstable points. We also present a visualization tool that supports the interactive exploration of the (r,d)-stability of data points. Finally, we demonstrate the effectiveness of our framework by examining the stability of projections of real-world datasets and present usage guidelines for the effective use of our framework.&#39;, &#39;uid&#39;: &#39;28a61ed9-3f15-4835-a688-e72b1fd6fa0c&#39;, &#39;keywords&#39;: [&#39;Dimensionality reduction&#39;, &#39;manifold learning&#39;, &#39;stochastic optimization&#39;, &#39;reliability&#39;, &#39;visualization&#39;, &#39;WebGPU&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2507.17174&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_28a61ed9-3f15-4835-a688-e72b1fd6fa0c.html"> GhostUMAP2: Measuring and Analyzing (r,d)-Stability of UMAP <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Myeongwon Jung, Takanori Fujiwara, Jaemin Jo </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Myeongwon Jung </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T13:00:00.000Z &ndash; 2025-11-05T13:12:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1838&#39;, &#39;session_id&#39;: &#39;full11&#39;, &#39;title&#39;: &#39;Uncertainty-Aware PCA Revisited&#39;, &#39;contributors&#39;: [&#39;Lukas Friesecke&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T13:12:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T13:12:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T13:24:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Lukas Friesecke&#39;, &#39;email&#39;: &#39;lukas.friesecke@ovgu.de&#39;, &#39;affiliation&#39;: &#39;University of Magdeburg&#39;}, {&#39;name&#39;: &#39;Christian Braune&#39;, &#39;email&#39;: &#39;christian.braune@ovgu.de&#39;, &#39;affiliation&#39;: &#39;University of Magdeburg&#39;}, {&#39;name&#39;: &#39;Christian Roessl&#39;, &#39;email&#39;: &#39;roessl@isg.cs.uni-magdeburg.de&#39;, &#39;affiliation&#39;: &#39;University of Magdeburg&#39;}, {&#39;name&#39;: &#39;Holger Theisel&#39;, &#39;email&#39;: &#39;theisel@ovgu.de&#39;, &#39;affiliation&#39;: &#39;University of Magdeburg&#39;}], &#39;abstract&#39;: &#39;Principal Component Analysis (PCA) is perhaps the most popular linear projection technique for dimensionality reduction. We consider PCA under the assumption that the high-dimensional data points are equipped with Gaussian uncertainty. Several approaches to such uncertainty-aware PCA have been developed recently in the visualization community. Since PCA is a discontinuous map, a small uncertainty in the data points can result in a huge uncertainty in the projected points. We show that the uncertainty of the data points also creates uncertainty in the eigenvectors of the covariance matrix that defines the PCA projection. We present a closed-form expression to quantify eigenvector uncertainty. Based on this, we propose a 3D glyph that supports the decision whether existing solutions for uncertainty-aware PCA are sufficient, or whether a more expensive sampling-based approach is required. We apply our approach to several test data sets.&#39;, &#39;uid&#39;: &#39;367cd3fe-b8ff-4bee-bd9f-ae8e51feeb9e&#39;, &#39;keywords&#39;: [&#39;PCA&#39;, &#39;dimensionality reduction&#39;, &#39;uncertainty visualization&#39;], &#39;preprint_link&#39;: &#39;https://vc.cs.ovgu.de/assets/publications/2025/Friesecke_2025_VIS.pdf&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://github.com/lfriesecke/uncertainty-aware-pca-revisited&#39;} <h3 class="session-list-title"><a href="paper_367cd3fe-b8ff-4bee-bd9f-ae8e51feeb9e.html"> Uncertainty-Aware PCA Revisited <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Lukas Friesecke, Christian Braune, Christian Roessl, Holger Theisel </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Lukas Friesecke </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T13:12:00.000Z &ndash; 2025-11-05T13:24:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1919&#39;, &#39;session_id&#39;: &#39;full11&#39;, &#39;title&#39;: &#39;What Makes a Visualization Image Complex?&#39;, &#39;contributors&#39;: [&#39;Jian Chen&#39;, &#39;Zefeng Qiu&#39;, &#39;Shuning Jiang&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T13:24:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T13:24:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T13:36:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Mengdi Chu&#39;, &#39;email&#39;: &#39;chu.752@osu.edu&#39;, &#39;affiliation&#39;: &#39;The Ohio State University&#39;}, {&#39;name&#39;: &#39;Zefeng Qiu&#39;, &#39;email&#39;: &#39;qiu.573@osu.edu&#39;, &#39;affiliation&#39;: &#39;The Ohio State University&#39;}, {&#39;name&#39;: &#39;Meng Ling&#39;, &#39;email&#39;: &#39;ling.253@osu.edu&#39;, &#39;affiliation&#39;: &#39;The Ohio State University&#39;}, {&#39;name&#39;: &#39;Shuning Jiang&#39;, &#39;email&#39;: &#39;jiang.2126@osu.edu&#39;, &#39;affiliation&#39;: &#39;The Ohio State University&#39;}, {&#39;name&#39;: &#39;Robert Laramee&#39;, &#39;email&#39;: &#39;robert.laramee@nottingham.ac.uk&#39;, &#39;affiliation&#39;: &#39;University of Nottingham&#39;}, {&#39;name&#39;: &#39;Michael Sedlmair&#39;, &#39;email&#39;: &#39;michael.sedlmair@visus.uni-stuttgart.de&#39;, &#39;affiliation&#39;: &#39;University of Stuttgart&#39;}, {&#39;name&#39;: &#39;Jian Chen&#39;, &#39;email&#39;: &#39;chen.8028@osu.edu&#39;, &#39;affiliation&#39;: &#39;The Ohio State University&#39;}], &#39;abstract&#39;: &#39;We investigate the perceived visual complexity (VC) in data visualizations using objective image-based metrics. We collected VC scores through a large-scale crowdsourcing experiment involving 349 participants and 1,800 visualization images. We then examined how these scores align with 12 image-based metrics spanning pixel-based and statistic-information-theoretic (clutter), color, shape, and our two new object-based metrics (meaningful-color-count (MeC) and text-to-ink ratio (TiR)). Our results show that both low-level edges and high-level elements affect perceived VC in visualization images; the number of corners and distinct colors are robust metrics across visualizations. Second, feature congestion, a statistical information-theoretic metric capturing color and texture patterns, is the strongest predictor of perceived complexity in visualizations rich in the same continuous color/texture stimuli; edge density effectively explains VC in node-link diagrams. Additionally, we observe a bell-curve effect for texts: increasing TiR initially reduces complexity, reaching an optimal point, beyond which further text increases VC. Our quantification model is also interpretable - enabling metric-based explanations - grounded in the VisComplexity2K dataset, bridging computational metrics with human perceptual responses. The preregistration is available at osf.io/5xe8a. osf.io/bdet6 has the dataset and analysis code.&#39;, &#39;uid&#39;: &#39;5cf45946-05e6-4d9c-876e-abeacdf5b8e1&#39;, &#39;keywords&#39;: [&#39;Perceived visual complexity&#39;, &#39;image-based metrics&#39;, &#39;scene-like&#39;, &#39;text-ink-ratio&#39;, &#39;meaningful-color-count&#39;], &#39;preprint_link&#39;: &#39;https://osf.io/preprints/osf/ypez4&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://osf.io/bdet6/&#39;} <h3 class="session-list-title"><a href="paper_5cf45946-05e6-4d9c-876e-abeacdf5b8e1.html"> What Makes a Visualization Image Complex? <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Mengdi Chu, Zefeng Qiu, Meng Ling, Shuning Jiang, Robert Laramee, Michael Sedlmair, Jian Chen </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Jian Chen, Zefeng Qiu, Shuning Jiang </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T13:24:00.000Z &ndash; 2025-11-05T13:36:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-2004&#39;, &#39;session_id&#39;: &#39;full11&#39;, &#39;title&#39;: &#39;Interactive Composition Operators: An Alternative Approach for Selecting Linear Embedding Parameters&#39;, &#39;contributors&#39;: [&#39;Kai M. Blum&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T13:36:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T13:36:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T13:48:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Dirk Lehmann&#39;, &#39;email&#39;: &#39;di.lehmann@ostfalia.de&#39;, &#39;affiliation&#39;: &#39;Ostfalia University of Applied Sciences&#39;}, {&#39;name&#39;: &#39;Kai M. Blum&#39;, &#39;email&#39;: &#39;kaiblum95@web.de&#39;, &#39;affiliation&#39;: &#39;Institute for Information Engineering&#39;}, {&#39;name&#39;: &#39;Manuel Rubio-Sánchez&#39;, &#39;email&#39;: &#39;manuel.rubio@urjc.es&#39;, &#39;affiliation&#39;: &#39;Universidad Rey Juan Carlos&#39;}, {&#39;name&#39;: &#39;Konrad Simon&#39;, &#39;email&#39;: &#39;konrad.simon2@de.bosch.com&#39;, &#39;affiliation&#39;: &#39;Robert Bosch GmbH, Stuttgart, GERMANY&#39;}], &#39;abstract&#39;: &#39;Linear embeddings support interactive visual exploration by mapping high-dimensional (nD) data into a two-dimensional\nspace. Despite their popularity, selecting meaningful projection parameters remains a key challenge due to the infi nite 2n-dimensional\nparameter space. Once an informative projection is found, users often seek similar ones that emphasize specifi c items differently\nwhile preserving global structure. For instance: Do clusters become outliers under slight changes? Can grouped items separate—or\nmerge—through parameter adjustments? Which changes to the embedding parameters lead to such projections — and do they exist\nat all? Answering these questions effi ciently is critical for effective visual search. Yet, current methods—such as projection tours or\nmanual parameter tuning—are time-consuming and risk overlooking important views, including those of specifi c interest. We propose\nComposition Operators, a mathematical foundation for a novel set-of-point manipulation concept for linear embeddings—such as Star\nCoordinates—as an alternative approach to selecting informative embedding parameters in a more controllable manner with respect to\nthe desired outcome. Users specify item-based constraints on the projection result; the corresponding 2n parameters are then derived\nautomatically, eliminating the need to exhaustively search the entire parameter space to get a similar outcome. Neither the embedding\nspace nor the set of parameters is altered – only the mechanism for navigating and selecting parameters is redefi ned. We provide\nclosed-form solutions for this and demonstrate our interactive prototype on nD datasets from the UCI repository.&#39;, &#39;uid&#39;: &#39;b43c7d8b-fdda-4a75-818d-e1fb4e4dfe31&#39;, &#39;keywords&#39;: [&#39;Star Coordinates&#39;, &#39;Multivariate Projections&#39;, &#39;Composition Operators&#39;, &#39;Multidimensional Data&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_b43c7d8b-fdda-4a75-818d-e1fb4e4dfe31.html"> Interactive Composition Operators: An Alternative Approach for Selecting Linear Embedding Parameters <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Dirk Lehmann, Kai M. Blum, Manuel Rubio-Sánchez, Konrad Simon </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Kai M. Blum </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T13:36:00.000Z &ndash; 2025-11-05T13:48:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG3471181&#39;, &#39;session_id&#39;: &#39;full11&#39;, &#39;title&#39;: &#39;HUMAP: Hierarchical Uniform Manifold Approximation and Projection&#39;, &#39;contributors&#39;: [&#39;Wilson Estécio Marcílio Júnior&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T13:48:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T13:48:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T14:00:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Wilson E. Marcílio-Jr&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Danilo M. Eler&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Fernando V. Paulovich&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Rafael M. Martins&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Dimensionality reduction (DR) techniques help analysts to understand patterns in high-dimensional spaces. These techniques, often represented by scatter plots, are employed in diverse science domains and facilitate similarity analysis among clusters and data samples. For datasets containing many granularities or when analysis follows the information visualization mantra, hierarchical DR techniques are the most suitable approach since they present major structures beforehand and details on demand. This work presents HUMAP, a novel hierarchical dimensionality reduction technique designed to be flexible on preserving local and global structures and preserve the mental map throughout hierarchical exploration. We provide empirical evidence of our technique’s superiority compared with current hierarchical approaches and show a case study applying HUMAP for dataset labelling.&#39;, &#39;uid&#39;: &#39;da094703-efa1-46d2-8f43-76453818ceb3&#39;, &#39;keywords&#39;: [&#39;Layout&#39;, &#39;Dimensionality reduction&#39;, &#39;Manifolds&#39;, &#39;Visualization&#39;, &#39;Kernel&#39;, &#39;Organizations&#39;, &#39;Graphics processing units&#39;, &#39;Engines&#39;, &#39;Deep learning&#39;, &#39;Data visualization&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2106.07718&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2024.3471181&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_da094703-efa1-46d2-8f43-76453818ceb3.html"> HUMAP: Hierarchical Uniform Manifold Approximation and Projection <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Wilson E. Marcílio-Jr, Danilo M. Eler, Fernando V. Paulovich, Rafael M. Martins </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Wilson Estécio Marcílio Júnior </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T13:48:00.000Z &ndash; 2025-11-05T14:00:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-08-0736&#39;, &#39;session_id&#39;: &#39;full11&#39;, &#39;title&#39;: &#39;ReorderBench: A Benchmark for Matrix Reordering&#39;, &#39;contributors&#39;: [&#39;Zheng Wang&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T14:00:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T14:00:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T14:12:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Jiangning Zhu&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Zheng Wang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Zhiyang Shen&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Lai Wei&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Fengyuan Tian&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Mengchen Liu&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Shixia Liu&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Matrix reordering permutes the rows and columns of a matrix to reveal meaningful visual patterns, such as blocks that represent clusters. A comprehensive collection of matrices, along with a scoring method for measuring the quality of visual patterns in these matrices, contributes to building a benchmark. This benchmark is essential for selecting or designing suitable reordering algorithms for revealing specific patterns. In this paper, we build a matrix-reordering benchmark, ReorderBench, with the goal of evaluating and improving matrix-reordering techniques. This is achieved by generating a large set of representative and diverse matrices and scoring these matrices with a convolution- and entropy-based method. Our benchmark contains 2,835,000 binary matrices and 5,670,000 continuous matrices, each generated to exhibit one of four visual patterns: block, off-diagonal block, star, or band, along with 450 real-world matrices featuring hybrid visual patterns. We demonstrate the usefulness of ReorderBench through three main applications in matrix reordering: 1) evaluating different reordering algorithms, 2) creating a unified scoring model to measure the visual patterns in any matrix, and 3) developing a deep learning model for matrix reordering.&#39;, &#39;uid&#39;: &#39;e5d145d6-1bb2-45a6-9333-b5123f205c08&#39;, &#39;keywords&#39;: [&#39;Visualization&#39;, &#39;Measurement&#39;, &#39;Benchmark testing&#39;, &#39;Heuristic algorithms&#39;, &#39;Approximation algorithms&#39;, &#39;Stars&#39;, &#39;Symmetric matrices&#39;, &#39;Indexes&#39;, &#39;Deep learning&#39;, &#39;Training&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2408.12169&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2025.3560345&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_e5d145d6-1bb2-45a6-9333-b5123f205c08.html"> ReorderBench: A Benchmark for Matrix Reordering <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Jiangning Zhu, Zheng Wang, Zhiyang Shen, Lai Wei, Fengyuan Tian, Mengchen Liu, Shixia Liu </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Zheng Wang </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T14:00:00.000Z &ndash; 2025-11-05T14:12:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row my-5"><div class="col-md-8"><p>You may want to also jump to the parent event to see related presentations: <a href="event_v-full.html">VIS Full Papers</a></p></div></div><script src="/static/2025/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script><script>

$(document).ready(function() {
    setInterval(updateSessionStatus, 30 * 1000);
    updateSessionStatus(true)
})

function updateSessionStatus(onFirstLoad) {
    // We need to write the session timings into the page to calculate current/next session.
    // See blueprint_2025.py
    startTime = '2025-11-05T13:00:00+00:00'
    endTime = '2025-11-05T14:15:00+00:00'

    // We take a 8 minute grace period to the start of a session
    const sessionStart = moment(startTime).tz(current_timezone).subtract(8, 'minutes');
    const sessionEnd = moment(endTime).tz(current_timezone);

    const sessionIsCurrent = moment().tz(current_timezone).isBetween(sessionStart, sessionEnd);
    const sessionIsFuture = moment().tz(current_timezone).isBefore(sessionStart);
    const sessionIsPast = moment().tz(current_timezone).isAfter(sessionStart);

    const classesToHide = ['.future_session_alert', '.current_session_alert', '.past_session_alert', '.room_session_stream']
    classesToHide.forEach((c) => { $(c).hide();});
    if (sessionIsCurrent) {
        $('.current_session_alert').show();
    } else if (sessionIsFuture) {
        $('.future_session_alert').show();
    } else {
        // Session is in the future
        $('#zoom_alert').hide();
        $('.past_session_alert').show();
        $('.room_session_stream').show();
    }

    // Update youtube link for older sessions
    // EDIT - We don't need this when the conference isn't live
    if(sessionIsPast){
        const roomidjson = "e2-"+moment(startTime).format('ddd').toLowerCase()+".json"
        // console.log("this session was in:" , roomidjson)

        return fetch("https://virtual-data.ieeevis.org/"+roomidjson, {cache: "no-store"})
        .then(response => response.json())
        .then(data => {
            //console.log(data)
            // console.log('youtube_url: ' + data.youtube_url)
            //$("ytold").attr("href",data.youtube_url)

            // clear link element to avoid multiple appends
            document.getElementById("ytold").innerHTML = '';

            var a = document.createElement('a'); 
            var link = document.createTextNode(data.youtube_url);  
            a.appendChild(link); 
            a.title = "YouTube Link"; 
            a.href = data.youtube_url; 
            
            document.getElementById("ytold").appendChild(a);
        })
        .catch(error => {
            console.log("err: ", error);
        })
    }
    

}

</script></body></html>