<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/2.1/auth0-spa-js.production.js"></script><script>
              const auth0_domain = "ieeevis.us.auth0.com";
              const auth0_client_id = "oF5BXUklWOjSjUeg5Tzai2DysHITXYhT";
            </script><script src="/static/2025/js/modules/auth0protect.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2025/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2025/js/data/persistor.js"></script><script src="/static/2025/js/data/api.js"></script><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2025/css/Zilla.css" rel="stylesheet"><link href="/static/2025/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2025/css/main.css"><link rel="stylesheet" href="/static/2025/css/fa_solid.css"><link rel="stylesheet" href="/static/2025/css/lazy_load.css"><link rel="stylesheet" href="/static/2025/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2025 - Session: VIS Full Papers: Interaction, Provenance, and Collaboration"><meta name="twitter:description" content="See the session and its presentations inside."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="See the session and its presentations inside."><meta name="title" property="og:title" content="Virtual IEEE VIS 2025 - Session: VIS Full Papers: Interaction, Provenance, and Collaboration"><meta property="og:type" content="website"><title>IEEE VIS 2025 Content: VIS Full Papers: Interaction, Provenance, and Collaboration</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style="display: none;"><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-8"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item" aria-current="page"><a href="events.html">All events</a></li><li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">Interaction, Provenance, and Collaboration</li></ol></nav><h1 class="session-title">VIS Full Papers: Interaction, Provenance, and Collaboration</h1><h3 class="session-url"><a href="https://ieeevis.org/year/2025/program/event_v-full.html" target="_blank"><span class="fas mr-1">&#xf57c;</span> https://ieeevis.org/year/2025/program/event_v-full.html</a></h3><h3 class="session-chair"><span class="fas mr-1">&#xf007;</span> Session chair: Gabriela Molina Leon </h3><h3 class="session-room mt-4"> Room: Hall E1 </h3><h3 class="session-date"><span class="fas mr-1">&#xf017;</span><span class="format-date-span-full">2025-11-06T14:45:00+00:00 &ndash; 2025-11-06T16:00:00+00:00</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2025-11-06T14:45:00+00:00 &ndash; 2025-11-06T16:00:00+00:00</span><span class="current-time tztooltiptext"></span></span></h3></div><div class="col-md-1"></div><div class="col-md-3 session-links"><h5 class="session-info my-4"><a href="#list"><span class="fas mr-2">&#xf358;</span> Jump to event listing </a></h5><h5 class="session-info my-4"><a href="https://data.tech.ieeevis.org/storage/v1/object/public/ics/vis2025/full19.ics"><span class="fas mr-2">&#xf073;</span> Add to Calendar</a></h5></div></div><div class="row my-5 discord-public-link hide-auth-controls"><div class="col-md-8"><p><span class="fas mx-1">&#xf086;</span><a href="https://discord.com/channels/1422883912660549696/1430945308053078097" target="_blank">Discord link</a></p></div></div><div class="row my-5"><div class="col-md-8"><p>Recordings will be made available after the session.</p></div></div><hr><div class="row my-4"><div class="col-md-8"><h2 class="room_session_descriptor d-block py-2"><a name="list">Presentations in this session:</a></h2></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1170&#39;, &#39;session_id&#39;: &#39;full19&#39;, &#39;title&#39;: &#39;Visual Extraction of Interaction Patterns Guided by Hierarchical Clustering and Process Mining&#39;, &#39;contributors&#39;: [&#39;Peilin Yu&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T14:45:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T14:45:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T14:57:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Peilin Yu&#39;, &#39;email&#39;: &#39;peilin.yu@liu.se&#39;, &#39;affiliation&#39;: &#39;Linköping University&#39;}, {&#39;name&#39;: &#39;Aida Nordman&#39;, &#39;email&#39;: &#39;aida.vitoria@liu.se&#39;, &#39;affiliation&#39;: &#39;Linköping University&#39;}, {&#39;name&#39;: &#39;Takanori Fujiwara&#39;, &#39;email&#39;: &#39;tfujiwara@ucdavis.edu&#39;, &#39;affiliation&#39;: &#39;Linköping University&#39;}, {&#39;name&#39;: &#39;Marta Koc-Januchta&#39;, &#39;email&#39;: &#39;marta.koc-januchta@liu.se&#39;, &#39;affiliation&#39;: &#39;Linköping University&#39;}, {&#39;name&#39;: &#39;Konrad Schönborn&#39;, &#39;email&#39;: &#39;konrad.schonborn@liu.se&#39;, &#39;affiliation&#39;: &#39;Linköping University&#39;}, {&#39;name&#39;: &#39;Lonni Besançon&#39;, &#39;email&#39;: &#39;lonni.besancon@gmail.com&#39;, &#39;affiliation&#39;: &#39;Linköping University&#39;}, {&#39;name&#39;: &#39;Katerina Vrotsou&#39;, &#39;email&#39;: &#39;katerina.vrotsou@liu.se&#39;, &#39;affiliation&#39;: &#39;Linköping University&#39;}], &#39;abstract&#39;: &#34;Understanding user interactions in digital systems is essential in analyzing user behaviors and improving system usability. However, a collection of interaction sequences is often large and unstructured, making it challenging to uncover interaction patterns. To address this challenge, we introduce a visual analytics approach that integrates hierarchical clustering and process mining techniques to support analysts in exploring unstructured, large interaction sequence data. Our system employs a tailored dynamic time warping-based similarity measure to enable comparison of interaction sequences. Based on the sequence similarities, we provide stepwise, interactive navigation of clustering results with contextual visual cues for refinement and validation. We further apply process mining to characterize derived clusters. Through these hierarchical clustering and process mining steps, analysts can progressively uncover meaningful interaction patterns while utilizing visual guidance and incorporating domain expertise. We demonstrate our system&#39;s effectiveness and applicability through two case studies involving system designers, developers, and domain experts.&#34;, &#39;uid&#39;: &#39;440d12ea-914c-49b0-a380-163dab6a3e41&#39;, &#39;keywords&#39;: [&#39;Pattern discovery in interaction logs&#39;, &#39;visual analytics&#39;, &#39;dynamic time warping&#39;, &#39;hierarchical clustering&#39;, &#39;process mining&#39;], &#39;preprint_link&#39;: &#39;https://doi.org/10.31219/osf.io/n5dxe_v1&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: &#39;Our work provides sufficient supplemental materials.&#39;, &#39;open_access_supplemental_link&#39;: &#39;https://osf.io/6az29/&#39;} <h3 class="session-list-title"><a href="paper_440d12ea-914c-49b0-a380-163dab6a3e41.html"> Visual Extraction of Interaction Patterns Guided by Hierarchical Clustering and Process Mining <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Peilin Yu, Aida Nordman, Takanori Fujiwara, Marta Koc-Januchta, Konrad Schönborn, Lonni Besançon, Katerina Vrotsou </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Peilin Yu </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T14:45:00.000Z &ndash; 2025-11-06T14:57:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1844&#39;, &#39;session_id&#39;: &#39;full19&#39;, &#39;title&#39;: &#39;Visualization Badges: Communicating Design and Provenance through Graphical Labels Alongside Visualizations&#39;, &#39;contributors&#39;: [&#39;Valentin EDELSBRUNNER&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T14:57:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T14:57:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T15:09:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Valentin Edelsbrunner&#39;, &#39;email&#39;: &#39;valentin.edelsbrunner@inria.fr&#39;, &#39;affiliation&#39;: &#39;Inria&#39;}, {&#39;name&#39;: &#39;Jinrui Wang&#39;, &#39;email&#39;: &#39;jinrui.w@outlook.com&#39;, &#39;affiliation&#39;: &#39;The University of Edinburgh&#39;}, {&#39;name&#39;: &#39;Alexis Pister&#39;, &#39;email&#39;: &#39;alexis.pister@hotmail.com&#39;, &#39;affiliation&#39;: &#39;University of Edinburgh&#39;}, {&#39;name&#39;: &#39;Tomas Vancisin&#39;, &#39;email&#39;: &#39;tvancisi@ed.ac.uk&#39;, &#39;affiliation&#39;: &#39;School of Law (PeaceRep)&#39;}, {&#39;name&#39;: &#39;Sian Phillips&#39;, &#39;email&#39;: &#39;sian.phillips@ed.ac.uk&#39;, &#39;affiliation&#39;: &#39;The University of Edinburgh&#39;}, {&#39;name&#39;: &#39;Min Chen&#39;, &#39;email&#39;: &#39;min.chen@oerc.ox.ac.uk&#39;, &#39;affiliation&#39;: &#39;University of Oxford&#39;}, {&#39;name&#39;: &#39;Benjamin Bach&#39;, &#39;email&#39;: &#39;bbach@inf.ed.ac.uk&#39;, &#39;affiliation&#39;: &#39;Inria&#39;}], &#39;abstract&#39;: &#39;This paper presents Visualization Badges, graphical labels shown alongside visualizations to communicate provenance and design considerations to enhance understandability and transparency. Badges may, for example, highlight a major finding, disclose that an axis has been truncated, or warn of possible visual artifacts. Inspired by nutrition and energy labels on product packaging, visualization badges aim (i) to allow visualization authors to justify and disclose analysis and design decisions and (ii) to make readers aware of important information when viewing and interpreting visualizations. Collectively, visualization badges aim to foster trust in visualizations and prevent readers from drawing incorrect conclusions. Based on a series of co-design workshops, we define and evaluate the concept of visualization badges and formulate a conceptual framework for analysis, application, and further research. Our framework includes a catalog of 132 visualization badges, categorization schemes, design options for their visual representations, applied visualization examples, and guidelines for their use. We hope that visualization badges will help communicate data and collectively improve communication, visualization literacy, and the quality of visualization techniques. Our badges, workshops, and guidelines can be found online https://vis-badges.github.io.&#39;, &#39;uid&#39;: &#39;49b63c40-81c7-41ec-a38a-9d433769c1c6&#39;, &#39;keywords&#39;: [&#39;Data Visualization&#39;, &#39;Communication&#39;, &#39;Transparency&#39;], &#39;preprint_link&#39;: &#39;https://hal.science/view/index/docid/5199752&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://vis-badges.github.io/#/about&#39;} <h3 class="session-list-title"><a href="paper_49b63c40-81c7-41ec-a38a-9d433769c1c6.html"> Visualization Badges: Communicating Design and Provenance through Graphical Labels Alongside Visualizations <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Valentin Edelsbrunner, Jinrui Wang, Alexis Pister, Tomas Vancisin, Sian Phillips, Min Chen, Benjamin Bach </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Valentin EDELSBRUNNER </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T14:57:00.000Z &ndash; 2025-11-06T15:09:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2023-10-0637&#39;, &#39;session_id&#39;: &#39;full19&#39;, &#39;title&#39;: &#39;Authoring Data-Driven Chart Animations through Direct Manipulation&#39;, &#39;contributors&#39;: [&#39;Yuancheng Shen&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T15:09:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T15:09:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T15:21:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Yuancheng Shen&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Yue Zhao&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Yunhai Wang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Tong Ge&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Haoyan Shi&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Bongshin Lee&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#34;We present an authoring tool, called CAST+ (Canis Studio Plus), that enables the interactive creation of chart animations through the direct manipulation of keyframes. It introduces the visual specification of chart animations consisting of keyframes that can be played sequentially or simultaneously, and animation parameters (e.g., duration, delay). Building on Canis (Ge et al. 2020), a declarative chart animation grammar that leverages data-enriched SVG charts, CAST+ supports auto-completion for constructing both keyframes and keyframe sequences. It also enables users to refine the animation specification (e.g., aligning keyframes across tracks to play them together, adjusting delay) with direct manipulation. We report a user study conducted to assess the visual specification and system usability with its initial version. We enhanced the system&#39;s expressiveness and usability: CAST+ now supports the animation of multiple types of visual marks in the same keyframe group with new auto-completion algorithms based on generalized selection. This enables the creation of more expressive animations, while reducing the number of interactions needed to create comparable animations. We present a gallery of examples and four usage scenarios to demonstrate the expressiveness of CAST+. Finally, we discuss the limitations, comparison, and potentials of CAST+ as well as directions for future research.&#34;, &#39;uid&#39;: &#39;d997f9c2-6bfc-421f-bfe6-26e0072cbe76&#39;, &#39;keywords&#39;: [&#39;Animation&#39;, &#39;Visualization&#39;, &#39;Programming&#39;, &#39;Grammar&#39;, &#39;Data visualization&#39;, &#39;Authoring systems&#39;, &#39;Planning&#39;, &#39;Delays&#39;, &#39;Videos&#39;, &#39;Usability&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2024.3491504&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_d997f9c2-6bfc-421f-bfe6-26e0072cbe76.html"> Authoring Data-Driven Chart Animations through Direct Manipulation <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Yuancheng Shen, Yue Zhao, Yunhai Wang, Tong Ge, Haoyan Shi, Bongshin Lee </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Yuancheng Shen </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T15:09:00.000Z &ndash; 2025-11-06T15:21:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-06-0442.R1&#39;, &#39;session_id&#39;: &#39;full19&#39;, &#39;title&#39;: &#39;DashSpace: A Live Collaborative Platform for Immersive and Ubiquitous Analytics&#39;, &#39;contributors&#39;: [&#39;Marcel Borowski&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T15:21:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T15:21:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T15:33:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Marcel Borowski&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Peter W. S. Butcher&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Janus Bager Kristensen&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Jonas Oxenbøll Petersen&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Panagiotis D. Ritsos&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Clemens N. Klokmose&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Niklas Elmqvist&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;We introduce DashSpace, a live collaborative immersive and ubiquitous analytics (IA/UA) platform designed for handheld and head-mounted Augmented/Extended Reality (AR/XR) implemented using WebXR and open standards. To bridge the gap between existing web-based visualizations and the immersive analytics setting, DashSpace supports visualizing both legacy D3 and Vega-Lite visualizations on 2D planes, and extruding Vega-Lite specifications into 2.5D. It also supports fully 3D visual representations using the Optomancy grammar. To facilitate authoring new visualizations in immersive XR, the platform provides a visual authoring mechanism where the user groups specification snippets to construct visualizations dynamically. The approach is fully persistent and collaborative, allowing multiple participants—whose presence is shown using 3D avatars and webcam feeds—to interact with the shared space synchronously, both co-located and remotely. We present three examples of DashSpace in action: immersive data analysis in 3D space, synchronous collaboration, and immersive data presentations.&#39;, &#39;uid&#39;: &#39;1ff943c3-7fda-4abd-a68d-9831af7b78f2&#39;, &#39;keywords&#39;: [&#39;Data visualization&#39;, &#39;Three-dimensional displays&#39;, &#39;Collaboration&#39;, &#39;Grammar&#39;, &#39;Software&#39;, &#39;Visualization&#39;, &#39;Hardware&#39;, &#39;Data analysis&#39;, &#39;Mobile handsets&#39;, &#39;Media&#39;], &#39;preprint_link&#39;: &#39;https://pure.au.dk/portal/en/publications/dashspace-a-live-collaborative-platform-for-immersive-and-ubiquit&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2025.3537679&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_1ff943c3-7fda-4abd-a68d-9831af7b78f2.html"> DashSpace: A Live Collaborative Platform for Immersive and Ubiquitous Analytics <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Marcel Borowski, Peter W. S. Butcher, Janus Bager Kristensen, Jonas Oxenbøll Petersen, Panagiotis D. Ritsos, Clemens N. Klokmose, Niklas Elmqvist </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Marcel Borowski </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T15:21:00.000Z &ndash; 2025-11-06T15:33:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-09-0808.R1&#39;, &#39;session_id&#39;: &#39;full19&#39;, &#39;title&#39;: &#39;TraVIS: a User Trace Analyzer to Support the User-Centered Design of Visual Analytics Solutions&#39;, &#39;contributors&#39;: [&#39;Marco Angelini&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T15:33:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T15:33:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T15:45:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Matteo Filosa&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Alexandra Plexousaki&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Matteo Di Stadio&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Francesco Bovi&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Dario Benvenuti&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Tiziana Catarci&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Marco Angelini&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Visual Analytics (VA) has become a paramount discipline in supporting data analysis in many scientific domains, empowering the human user with automatic capabilities while keeping the lead in the analysis. At the same time, designing an effective VA solution is not a simple task, requiring its adaptation to the problem at hand and the intended user of the system. In this scenario, the User-Centered Design (UCD) methodology provides the framework to incorporate user needs into the design of a VA solution. On the other hand, its implementation mainly relies on qualitative feedback, with the designer missing tools supporting her in quantitatively reporting the user feedback and using it to hypothesize and test the successive changes to the VA solution. To overcome this limitation, we propose TraVIS, a Visual Analytics solution allowing the loading of a web-based VA system, collecting user traces, and analyzing them with respect to the system at hand. In this process, the designer can leverage the collected traces and relate them to the tasks the VA solution supports and how those can be achieved. Using TraVIS, the designer can identify ineffective interaction paths, analyze the user traces support to task completion, hypothesize corrections to the design, and evaluate the effect of changes. We evaluated TraVIS through experimentation with 11 VA systems from literature, a use case, and user evaluation with five experts. Results show the benefits that TraVIS provides in terms of identifying design problems and efficient support for UCD.&#39;, &#39;uid&#39;: &#39;8d730321-05df-42cd-bb4d-013ae3589399&#39;, &#39;keywords&#39;: [&#39;Visual analytics&#39;, &#39;Data visualization&#39;, &#39;User centered design&#39;, &#39;Optimization&#39;, &#39;Taxonomy&#39;, &#39;Process mining&#39;, &#39;Iterative methods&#39;, &#39;Hands&#39;, &#39;Focusing&#39;, &#39;Training&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2025.3546863&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_8d730321-05df-42cd-bb4d-013ae3589399.html"> TraVIS: a User Trace Analyzer to Support the User-Centered Design of Visual Analytics Solutions <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Matteo Filosa, Alexandra Plexousaki, Matteo Di Stadio, Francesco Bovi, Dario Benvenuti, Tiziana Catarci, Marco Angelini </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Marco Angelini </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T15:33:00.000Z &ndash; 2025-11-06T15:45:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-08-0792.R2&#39;, &#39;session_id&#39;: &#39;full19&#39;, &#39;title&#39;: &#39;Utilizing Provenance as an Attribute for Visual Data Analysis: A Design Probe with ProvenanceLens&#39;, &#39;contributors&#39;: [&#39;Arpit Narechania&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T15:45:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T15:45:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T15:57:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Arpit Narechania&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Shunan Guo&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Eunyee Koh&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Alex Endert&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Jane Hoffswell&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#34;Analytic provenance can be visually encoded to help users track their ongoing analysis trajectories, recall past interactions, and inform new analytic directions. Despite its significance, provenance is often hardwired into analytics systems, affording limited user control and opportunities for self-reflection. We thus propose modeling provenance as an attribute that is available to users during analysis. We demonstrate this concept by modeling two provenance attributes that track the recency and frequency of user interactions with data. We integrate these attributes into a visual data analysis system prototype, ProvenanceLens, wherein users can visualize their interaction recency and frequency by mapping them to encoding channels (e.g., color, size) or applying data transformations (e.g., filter, sort). Using ProvenanceLens as a design probe, we conduct an exploratory study with sixteen users to investigate how these provenance-tracking affordances are utilized for both decision-making and self-reflection. We find that users can accurately and confidently answer questions about their analysis, and we show that mismatches between the user&#39;s mental model and the provenance encodings can be surprising, thereby prompting useful self-reflection. We also report on the user strategies surrounding these affordances, and reflect on their intuitiveness and effectiveness in representing provenance.&#34;, &#39;uid&#39;: &#39;063cc125-d8ef-4935-baa1-e74f6262ea81&#39;, &#39;keywords&#39;: [&#39;Data visualization&#39;, &#39;Visualization&#39;, &#39;Analytical models&#39;, &#39;Encoding&#39;, &#39;Data models&#39;, &#39;Data analysis&#39;, &#39;Image color analysis&#39;, &#39;History&#39;, &#39;Time-frequency analysis&#39;, &#39;Probes&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2505.11784&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2025.3571708&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_063cc125-d8ef-4935-baa1-e74f6262ea81.html"> Utilizing Provenance as an Attribute for Visual Data Analysis: A Design Probe with ProvenanceLens <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Arpit Narechania, Shunan Guo, Eunyee Koh, Alex Endert, Jane Hoffswell </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Arpit Narechania </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T15:45:00.000Z &ndash; 2025-11-06T15:57:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row my-5"><div class="col-md-8"><p>You may want to also jump to the parent event to see related presentations: <a href="event_v-full.html">VIS Full Papers</a></p></div></div><script src="/static/2025/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script><script>

$(document).ready(function() {
    setInterval(updateSessionStatus, 30 * 1000);
    updateSessionStatus(true)
})

function updateSessionStatus(onFirstLoad) {
    // We need to write the session timings into the page to calculate current/next session.
    // See blueprint_2025.py
    startTime = '2025-11-06T14:45:00+00:00'
    endTime = '2025-11-06T16:00:00+00:00'

    // We take a 8 minute grace period to the start of a session
    const sessionStart = moment(startTime).tz(current_timezone).subtract(8, 'minutes');
    const sessionEnd = moment(endTime).tz(current_timezone);

    const sessionIsCurrent = moment().tz(current_timezone).isBetween(sessionStart, sessionEnd);
    const sessionIsFuture = moment().tz(current_timezone).isBefore(sessionStart);
    const sessionIsPast = moment().tz(current_timezone).isAfter(sessionStart);

    const classesToHide = ['.future_session_alert', '.current_session_alert', '.past_session_alert', '.room_session_stream']
    classesToHide.forEach((c) => { $(c).hide();});
    if (sessionIsCurrent) {
        $('.current_session_alert').show();
    } else if (sessionIsFuture) {
        $('.future_session_alert').show();
    } else {
        // Session is in the future
        $('#zoom_alert').hide();
        $('.past_session_alert').show();
        $('.room_session_stream').show();
    }

    // Update youtube link for older sessions
    // EDIT - We don't need this when the conference isn't live
    if(sessionIsPast){
        const roomidjson = "e1-"+moment(startTime).format('ddd').toLowerCase()+".json"
        // console.log("this session was in:" , roomidjson)

        return fetch("https://virtual-data.ieeevis.org/"+roomidjson, {cache: "no-store"})
        .then(response => response.json())
        .then(data => {
            //console.log(data)
            // console.log('youtube_url: ' + data.youtube_url)
            //$("ytold").attr("href",data.youtube_url)

            // clear link element to avoid multiple appends
            document.getElementById("ytold").innerHTML = '';

            var a = document.createElement('a'); 
            var link = document.createTextNode(data.youtube_url);  
            a.appendChild(link); 
            a.title = "YouTube Link"; 
            a.href = data.youtube_url; 
            
            document.getElementById("ytold").appendChild(a);
        })
        .catch(error => {
            console.log("err: ", error);
        })
    }
    

}

</script></body></html>