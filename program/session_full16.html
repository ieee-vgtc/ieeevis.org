<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/2.1/auth0-spa-js.production.js"></script><script>
              const auth0_domain = "ieeevis.us.auth0.com";
              const auth0_client_id = "oF5BXUklWOjSjUeg5Tzai2DysHITXYhT";
            </script><script src="/static/2025/js/modules/auth0protect.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2025/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2025/js/data/persistor.js"></script><script src="/static/2025/js/data/api.js"></script><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2025/css/Zilla.css" rel="stylesheet"><link href="/static/2025/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2025/css/main.css"><link rel="stylesheet" href="/static/2025/css/fa_solid.css"><link rel="stylesheet" href="/static/2025/css/lazy_load.css"><link rel="stylesheet" href="/static/2025/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2025 - Session: VIS Full Papers: Games, Sports, and Music"><meta name="twitter:description" content="See the session and its presentations inside."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="See the session and its presentations inside."><meta name="title" property="og:title" content="Virtual IEEE VIS 2025 - Session: VIS Full Papers: Games, Sports, and Music"><meta property="og:type" content="website"><title>IEEE VIS 2025 Content: VIS Full Papers: Games, Sports, and Music</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style="display: none;"><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-8"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item" aria-current="page"><a href="events.html">All events</a></li><li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">Games, Sports, and Music</li></ol></nav><h1 class="session-title">VIS Full Papers: Games, Sports, and Music</h1><h3 class="session-url"><a href="https://ieeevis.org/year/2025/program/event_v-full.html" target="_blank"><span class="fas mr-1">&#xf57c;</span> https://ieeevis.org/year/2025/program/event_v-full.html</a></h3><h3 class="session-chair"><span class="fas mr-1">&#xf007;</span> Session chair: Yu Fu </h3><h3 class="session-room mt-4"> Room: Hall M1 </h3><h3 class="session-date"><span class="fas mr-1">&#xf017;</span><span class="format-date-span-full">2025-11-06T10:15:00+00:00 &ndash; 2025-11-06T11:30:00+00:00</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2025-11-06T10:15:00+00:00 &ndash; 2025-11-06T11:30:00+00:00</span><span class="current-time tztooltiptext"></span></span></h3></div><div class="col-md-1"></div><div class="col-md-3 session-links"><h5 class="session-info my-4"><a href="#list"><span class="fas mr-2">&#xf358;</span> Jump to event listing </a></h5><h5 class="session-info my-4"><a href="https://data.tech.ieeevis.org/storage/v1/object/public/ics/vis2025/full16.ics"><span class="fas mr-2">&#xf073;</span> Add to Calendar</a></h5></div></div><div class="row my-5 discord-public-link hide-auth-controls"><div class="col-md-8"><p><span class="fas mx-1">&#xf086;</span><a href="https://discord.com/channels/1422883912660549696/1430945302608609290" target="_blank">Discord link</a></p></div></div><div class="row my-5"><div class="col-md-8"><p>Recordings will be made available after the session.</p></div></div><hr><div class="row my-4"><div class="col-md-8"><h2 class="room_session_descriptor d-block py-2"><a name="list">Presentations in this session:</a></h2></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1066&#39;, &#39;session_id&#39;: &#39;full16&#39;, &#39;title&#39;: &#39;InsightChaser: Enhancing Visual Reasoning of Sports Tactical Visualization with Visual-Text Linking&#39;, &#39;contributors&#39;: [&#39;Ziao Liu&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T10:15:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T10:15:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T10:27:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Ziao Liu&#39;, &#39;email&#39;: &#39;ziao_liu@outlook.com&#39;, &#39;affiliation&#39;: &#39;Zhejiang University&#39;}, {&#39;name&#39;: &#39;Wenshuo Zhao&#39;, &#39;email&#39;: &#39;zhao_ws@zju.edu.cn&#39;, &#39;affiliation&#39;: &#39;Zhejiang University&#39;}, {&#39;name&#39;: &#39;Xiao Xie&#39;, &#39;email&#39;: &#39;xxie@zju.edu.cn&#39;, &#39;affiliation&#39;: &#39;Zhejiang University&#39;}, {&#39;name&#39;: &#39;Anqi Cao&#39;, &#39;email&#39;: &#39;caoanqi28@163.com&#39;, &#39;affiliation&#39;: &#39;Zhejiang University&#39;}, {&#39;name&#39;: &#39;Yihong Wu&#39;, &#39;email&#39;: &#39;wuyihong0606@gmail.com&#39;, &#39;affiliation&#39;: &#39;Zhejiang University&#39;}, {&#39;name&#39;: &#39;Hui Zhang&#39;, &#39;email&#39;: &#39;zhang_hui@zju.edu.cn&#39;, &#39;affiliation&#39;: &#39;Zhejiang University&#39;}, {&#39;name&#39;: &#39;Yingcai Wu&#39;, &#39;email&#39;: &#39;ycwu@zju.edu.cn&#39;, &#39;affiliation&#39;: &#39;Zhejiang University&#39;}], &#39;abstract&#39;: &#39;In sports analytics, tactical visualization is widely used to convey valuable insights. However, due to the complex domain knowledge and contextual information involved in tactical visualizations, it is challenging for users to connect high-level tactical insights to corresponding visual patterns. This requires users to engage in a reasoning process to interpret insights within game contexts, which remains insufficiently supported in existing visual-text linking studies. In this work, we propose InsightChaser, a novel approach to bridge tactical insights and soccer visualizations through visual-text linking and visual reasoning enhancement. InsightChaser constructs knowledge graphs to represent both visual elements and contextual game information. Integrating large language models (LLMs), our approach retrieves relevant visual elements and establishes explicit links with insights. Moreover, InsightChaser utilizes LLMs to enhance these visual-text links by providing reasoning explanations and visual effects. We further develop an interactive visualization system that supports navigation and explanation of enhanced visual-text links. Users can explore linked tactical insights interactively and reason through enhanced visual explanations. We conduct two case studies using real-world soccer data and a user study to demonstrate the effectiveness of our approach.&#39;, &#39;uid&#39;: &#39;ce206043-1fa9-45b7-801b-2910c1dec585&#39;, &#39;keywords&#39;: [&#39;Sports visualization&#39;, &#39;tactical analysis&#39;, &#39;visual-text linking&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_ce206043-1fa9-45b7-801b-2910c1dec585.html"> InsightChaser: Enhancing Visual Reasoning of Sports Tactical Visualization with Visual-Text Linking <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Ziao Liu, Wenshuo Zhao, Xiao Xie, Anqi Cao, Yihong Wu, Hui Zhang, Yingcai Wu </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Ziao Liu </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T10:15:00.000Z &ndash; 2025-11-06T10:27:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1732&#39;, &#39;session_id&#39;: &#39;full16&#39;, &#39;title&#39;: &#39;Beyond the Broadcast: Enhancing VR Tennis Broadcasting through Embedded Visualizations and Camera Techniques&#39;, &#39;contributors&#39;: [&#39;Jun-Hsiang Yao&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T10:27:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T10:27:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T10:39:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Jun-Hsiang Yao&#39;, &#39;email&#39;: &#39;peter650059@hotmail.com&#39;, &#39;affiliation&#39;: &#39;Fudan University&#39;}, {&#39;name&#39;: &#39;Jielin Feng&#39;, &#39;email&#39;: &#39;23110980031@m.fudan.edu.cn&#39;, &#39;affiliation&#39;: &#39;Fudan University&#39;}, {&#39;name&#39;: &#39;Xinfang Tian&#39;, &#39;email&#39;: &#39;xinfangtian0206@163.com&#39;, &#39;affiliation&#39;: &#39;Hunan University&#39;}, {&#39;name&#39;: &#39;Kai Xu&#39;, &#39;email&#39;: &#39;kai.xu@nottingham.ac.uk&#39;, &#39;affiliation&#39;: &#39;University of Nottingham&#39;}, {&#39;name&#39;: &#39;Gulshat Amirkhanova&#39;, &#39;email&#39;: &#39;gulshat.aa@gmail.com&#39;, &#39;affiliation&#39;: &#39;Al-Farabi Kazakh National University&#39;}, {&#39;name&#39;: &#39;Siming Chen&#39;, &#39;email&#39;: &#39;simingchen3@gmail.com&#39;, &#39;affiliation&#39;: &#39;Fudan University&#39;}], &#39;abstract&#39;: &#34;Virtual Reality (VR) broadcasting has emerged as a promising medium for providing immersive viewing experiences of major sports events such as tennis. However, current VR broadcast systems often lack an effective camera language and do not adequately incorporate dynamic, in-game visualizations, limiting viewer engagement and narrative clarity. To address these limitations, we analyze 400 out-of-play segments from eight major tennis broadcasts to develop a tennis-specific design framework that effectively combines cinematic camera movements with embedded visualizations. We further refine our framework by examining 25 cinematic VR animations, comparing their camera techniques with traditional tennis broadcasts to identify key differences and inform adaptations for VR. Based on data extracted from the broadcast videos, we reconstruct a simulated game that captures the players&#39; and ball&#39;s motion and trajectories. Leveraging this design framework and processing pipeline, we develope Beyond the Broadcast, a VR tennis viewing system that integrates embedded visualizations with adaptive camera motions to construct a comprehensive and engaging narrative. Our system dynamically overlays tactical information and key match events onto the simulated environment, enhancing viewer comprehension and narrative engagement while ensuring perceptual immersion and viewing comfort. A user study involving tennis viewers demonstrate that our approach outperforms traditional VR broadcasting methods in delivering an immersive, informative viewing experience.&#34;, &#39;uid&#39;: &#39;d2d68e75-88a1-4f4a-a1c5-7d8cb6706524&#39;, &#39;keywords&#39;: [&#39;Tennis&#39;, &#39;VR Broadcasting&#39;, &#39;Embedded Visualization&#39;, &#39;Camera Motion&#39;, &#39;Immersive Experience&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2507.20006&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_d2d68e75-88a1-4f4a-a1c5-7d8cb6706524.html"> Beyond the Broadcast: Enhancing VR Tennis Broadcasting through Embedded Visualizations and Camera Techniques <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Jun-Hsiang Yao, Jielin Feng, Xinfang Tian, Kai Xu, Gulshat Amirkhanova, Siming Chen </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Jun-Hsiang Yao </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T10:27:00.000Z &ndash; 2025-11-06T10:39:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1897&#39;, &#39;session_id&#39;: &#39;full16&#39;, &#39;title&#39;: &#39;TactiVis: Towards Better Understanding of Team-based Combat Tactics&#39;, &#39;contributors&#39;: [&#39;Hancheng Zhang&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T10:39:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T10:39:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T10:51:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Hancheng Zhang&#39;, &#39;email&#39;: &#39;3120215511@bit.edu.cn&#39;, &#39;affiliation&#39;: &#39;Beijing Institute of Technology&#39;}, {&#39;name&#39;: &#39;Guozheng Li&#39;, &#39;email&#39;: &#39;liguozhengsdu@gmail.com&#39;, &#39;affiliation&#39;: &#39;Beijing Institute of Technology&#39;}, {&#39;name&#39;: &#39;Min Lu&#39;, &#39;email&#39;: &#39;lumin.vis@gmail.com&#39;, &#39;affiliation&#39;: &#39;Shenzhen University&#39;}, {&#39;name&#39;: &#39;Jincheng Li&#39;, &#39;email&#39;: &#39;jinchengli@bnu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Beijing Normal University&#39;}, {&#39;name&#39;: &#39;Chi Harold Liu&#39;, &#39;email&#39;: &#39;liuchi02@gmail.com&#39;, &#39;affiliation&#39;: &#39;Beijing Institute of Technology&#39;}], &#39;abstract&#39;: &#39;Team-based combat scenarios are prevalent in various real-world applications like video gaming. Analyzing tactics in these scenarios is essential for gaining insights into game processes and improving combat behaviors. The decision-making data in team-based combat include character actions, movement trajectories, and event sequences. Existing studies face challenges in visualizing and analyzing combat tactics due to the complexity and the multifaceted characteristics of the decision-making data. To address these challenges, we introduce TactiVis, a visual analytics system designed for analyzing combat decision-making behavior. Using MOBA game as a representative case of team-based combat, TactiVis adopts a macro-to-micro tactics visual analytics framework consisting of three stages: match-level analysis, event-level understanding, and character-level comparison. In the TactiVis system, we introduce the v-storyline visualization, which encodes positions along the vertical axis to reveal tactical patterns. Case studies and a usability study demonstrate the utility and usability of TactiVis for helping analysts understand combat patterns and analyze tactics.&#39;, &#39;uid&#39;: &#39;5f806c3f-27b1-47e9-81ce-9255b7532d0f&#39;, &#39;keywords&#39;: [&#39;Team-based combat&#39;, &#39;storyline visualization&#39;, &#39;MOBA games&#39;, &#39;tactic analysis.&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_5f806c3f-27b1-47e9-81ce-9255b7532d0f.html"> TactiVis: Towards Better Understanding of Team-based Combat Tactics <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Hancheng Zhang, Guozheng Li, Min Lu, Jincheng Li, Chi Harold Liu </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Hancheng Zhang </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T10:39:00.000Z &ndash; 2025-11-06T10:51:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-07-0603.R1&#39;, &#39;session_id&#39;: &#39;full16&#39;, &#39;title&#39;: &#39;Deciphering Explicit and Implicit Features for Reliable, Interpretable, and Actionable User Churn Prediction in Online Video Games&#39;, &#39;contributors&#39;: [&#39;Quan Li&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T10:51:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T10:51:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T11:03:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Xiyuan Wang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Laixin Xie&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;He Wang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Xingxing Xing&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Wei Wan&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Ziming Wu&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Xiaojuan Ma&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Quan Li&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;The burgeoning online video game industry has sparked intense competition among providers to both expand their user base and retain existing players, particularly within social interaction genres. To anticipate player churn, there is an increasing reliance on machine learning (ML) models that focus on social interaction dynamics. However, the prevalent opacity of most ML algorithms poses a significant hurdle to their acceptance among domain experts, who often view them as “opaque models”. Despite the availability of eXplainable Artificial Intelligence (XAI) techniques capable of elucidating model decisions, their adoption in the gaming industry remains limited. This is primarily because non-technical domain experts, such as product managers and game designers, encounter substantial challenges in deciphering the “explicit” and “implicit” features embedded within computational models. This study proposes a reliable, interpretable, and actionable solution for predicting player churn by restructuring model inputs into explicit and implicit features. It explores how establishing a connection between explicit and implicit features can assist experts in understanding the underlying implicit features. Moreover, it emphasizes the necessity for XAI techniques that not only offer implementable interventions but also pinpoint the most crucial features for those interventions. Two case studies, including expert feedback and a within-subject user study, demonstrate the efficacy of our approach.&#39;, &#39;uid&#39;: &#39;26915272-41cc-4235-9570-43e77fa756af&#39;, &#39;keywords&#39;: [&#39;Games&#39;, &#39;Predictive models&#39;, &#39;Social networking (online)&#39;, &#39;Prediction algorithms&#39;, &#39;Computational modeling&#39;, &#39;Industries&#39;, &#39;Visual analytics&#39;, &#39;Reliability&#39;, &#39;Interviews&#39;, &#39;Explainable AI&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2024.3487974&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: &#39;Github repository contains the source code of the framework, including the Interface: Contains frontend code. Backend: Contains backend code. The counterfactual generation in the backend is inspired by and builds upon the DECE framework: https://github.com/ChengFR/DECE-research.&#39;, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_26915272-41cc-4235-9570-43e77fa756af.html"> Deciphering Explicit and Implicit Features for Reliable, Interpretable, and Actionable User Churn Prediction in Online Video Games <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Xiyuan Wang, Laixin Xie, He Wang, Xingxing Xing, Wei Wan, Ziming Wu, Xiaojuan Ma, Quan Li </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Quan Li </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T10:51:00.000Z &ndash; 2025-11-06T11:03:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-08-0704.R1&#39;, &#39;session_id&#39;: &#39;full16&#39;, &#39;title&#39;: &#39;MAICO: A Visualization Design Study on AI-Assisted Music Composition&#39;, &#39;contributors&#39;: [&#39;Simeon Rau&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T11:03:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T11:03:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T11:15:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Simeon Rau&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Frank Heyen&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Benedikt Brachtel&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Michael Sedlmair&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;We contribute a design study on using visual analytics for AI-assisted music composition. The main result is the interface MAICO (Music AI Co-creativity), which allows composers and other music creators to interactively generate, explore, select, edit, and compare samples from generative music models. MAICO is based on the idea of visual parameter space analysis and supports the simultaneous analysis of hundreds of short samples of symbolic music from multiple models, displaying them in different metric- and similarity-based layouts. We developed and evaluated MAICO together with a professional composer who actively used it for five months to create, among other things, a composition for the Biennale Arte 2024 in Venice, which was recorded by the Munich Symphonic Orchestra. We discuss our design choices and lessons learned from this endeavor to support Human-AI co-creativity with visual analytics.&#39;, &#39;uid&#39;: &#39;652040d5-96ca-48fd-a25f-f9bc2bb89dd1&#39;, &#39;keywords&#39;: [&#39;Music&#39;, &#39;Artificial intelligence&#39;, &#39;Analytical models&#39;, &#39;Data visualization&#39;, &#39;Data models&#39;, &#39;Visual analytics&#39;, &#39;Aerospace electronics&#39;, &#39;Training&#39;, &#39;Generative AI&#39;, &#39;Computational modeling&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2025.3539779&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_652040d5-96ca-48fd-a25f-f9bc2bb89dd1.html"> MAICO: A Visualization Design Study on AI-Assisted Music Composition <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Simeon Rau, Frank Heyen, Benedikt Brachtel, Michael Sedlmair </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Simeon Rau </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T11:03:00.000Z &ndash; 2025-11-06T11:15:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-short-1277&#39;, &#39;session_id&#39;: &#39;full16&#39;, &#39;title&#39;: &#39;Animated Visual Encoding and Layer Blending for Identification of Educational Game Strategies&#39;, &#39;contributors&#39;: [&#39;Braden Roper&#39;], &#39;paper_type&#39;: &#39;Short&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T11:15:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T11:15:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T11:24:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Braden Roper&#39;, &#39;email&#39;: &#39;bradenroper@ou.edu&#39;, &#39;affiliation&#39;: &#39;The University of Oklahoma&#39;}, {&#39;name&#39;: &#39;William Thompson&#39;, &#39;email&#39;: &#39;will.thompson@ou.edu&#39;, &#39;affiliation&#39;: &#39;The University of Oklahoma&#39;}, {&#39;name&#39;: &#39;Chris Weaver&#39;, &#39;email&#39;: &#39;cweaver@ou.edu&#39;, &#39;affiliation&#39;: &#39;University of Oklahoma&#39;}], &#39;abstract&#39;: &#39;Game-Based Learning has proven to be an effective method for enhancing engagement with educational material. However, gaining a deeper understanding of player strategies remains challenging. Sequential game-state and action-based tracking tools often gather extensive data that can be difficult to interpret as long-term strategy. This data presents unique problems to visualization, as it can be fairly natural, noisy data but is constrained within synthetic, controlled environments, leading to issues such as overplotting which can make interpretation complicated. We propose an animated visual encoding tool that utilizes kinetic visualization to address these issues. This tool enables researchers to construct animated data narratives through the configuration of parameter interpolation curves and blending layers. Finally, we demonstrate the usefulness of the tool while addressing specific interests as outlined by a domain expert collaborator.&#39;, &#39;uid&#39;: &#39;dfb38658-4e3c-42b8-9333-ac8f04df3106&#39;, &#39;keywords&#39;: [&#39;Kinetic visualization&#39;, &#39;kinetic queries&#39;, &#39;animated encoding&#39;, &#39;game-based learning&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2507.01134&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://osf.io/tf245&#39;} <h3 class="session-list-title"><a href="paper_dfb38658-4e3c-42b8-9333-ac8f04df3106.html"> Animated Visual Encoding and Layer Blending for Identification of Educational Game Strategies <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Braden Roper, William Thompson, Chris Weaver </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Braden Roper </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T11:15:00.000Z &ndash; 2025-11-06T11:24:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row my-5"><div class="col-md-8"><p>You may want to also jump to the parent event to see related presentations: <a href="event_v-full.html">VIS Full Papers</a></p></div></div><script src="/static/2025/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script><script>

$(document).ready(function() {
    setInterval(updateSessionStatus, 30 * 1000);
    updateSessionStatus(true)
})

function updateSessionStatus(onFirstLoad) {
    // We need to write the session timings into the page to calculate current/next session.
    // See blueprint_2025.py
    startTime = '2025-11-06T10:15:00+00:00'
    endTime = '2025-11-06T11:30:00+00:00'

    // We take a 8 minute grace period to the start of a session
    const sessionStart = moment(startTime).tz(current_timezone).subtract(8, 'minutes');
    const sessionEnd = moment(endTime).tz(current_timezone);

    const sessionIsCurrent = moment().tz(current_timezone).isBetween(sessionStart, sessionEnd);
    const sessionIsFuture = moment().tz(current_timezone).isBefore(sessionStart);
    const sessionIsPast = moment().tz(current_timezone).isAfter(sessionStart);

    const classesToHide = ['.future_session_alert', '.current_session_alert', '.past_session_alert', '.room_session_stream']
    classesToHide.forEach((c) => { $(c).hide();});
    if (sessionIsCurrent) {
        $('.current_session_alert').show();
    } else if (sessionIsFuture) {
        $('.future_session_alert').show();
    } else {
        // Session is in the future
        $('#zoom_alert').hide();
        $('.past_session_alert').show();
        $('.room_session_stream').show();
    }

    // Update youtube link for older sessions
    // EDIT - We don't need this when the conference isn't live
    if(sessionIsPast){
        const roomidjson = "m1-"+moment(startTime).format('ddd').toLowerCase()+".json"
        // console.log("this session was in:" , roomidjson)

        return fetch("https://virtual-data.ieeevis.org/"+roomidjson, {cache: "no-store"})
        .then(response => response.json())
        .then(data => {
            //console.log(data)
            // console.log('youtube_url: ' + data.youtube_url)
            //$("ytold").attr("href",data.youtube_url)

            // clear link element to avoid multiple appends
            document.getElementById("ytold").innerHTML = '';

            var a = document.createElement('a'); 
            var link = document.createTextNode(data.youtube_url);  
            a.appendChild(link); 
            a.title = "YouTube Link"; 
            a.href = data.youtube_url; 
            
            document.getElementById("ytold").appendChild(a);
        })
        .catch(error => {
            console.log("err: ", error);
        })
    }
    

}

</script></body></html>