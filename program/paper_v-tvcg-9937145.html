<!DOCTYPE html><html lang="en"> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2023/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/1.12/auth0-spa-js.production.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2023/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2023/js/data/persistor.js"></script><script src="/static/2023/js/data/api.js"></script><link rel="shortcut icon" href="/static/2023/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2023/css/Zilla.css" rel="stylesheet"><link href="/static/2023/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2023/css/main.css"><link rel="stylesheet" href="/static/2023/css/fa_solid.css"><link rel="stylesheet" href="/static/2023/css/lazy_load.css"><link rel="stylesheet" href="/static/2023/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="Virtual IEEE VIS 2023 - Paper: The Transform-and-Perform framework: Explainable deep learning beyond classification"><meta name="twitter:description" content="In recent years, visual analytics (VA) has shown promise in alleviating the challenges of interpreting black-box deep learning (DL) models. While the focus of VA for explainable DL has been mainly on classification problems, DL is gaining popularity in high-dimensional-to-high-dimensional (H-H) problems such as image-to-image translation. In contrast to classification, H-H problems have no explicit instance groups or classes to study. Each output is continuous, high-dimensional, and changes in an unknown non-linear manner with changes in the input. These unknown relations between the input, model and output necessitate the user to analyze them in conjunction, leveraging symmetries between them. Since classification tasks do not exhibit some of these challenges, most existing VA systems and frameworks allow limited control of the components required to analyze models beyond classification. Hence, we identify the need for and present a unified conceptual framework, the Transform-and-Perform framework (T&P), to facilitate the design of VA systems for DL model analysis focusing on H-H problems. T&P provides a checklist to structure and identify workflows and analysis strategies to design new VA systems, and understand existing ones to uncover potential gaps for improvements. The goal is to aid the creation of effective VA systems that support the structuring of model understanding and identifying actionable insights for model improvements. We highlight the growing need for new frameworks like T&P with a real-world image-to image translation application. We illustrate how T&P effectively supports the understanding and identification of potential gaps in existing VA systems."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2023/paper_images/v-tvcg-9937145.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2023/paper_images/v-tvcg-9937145.png"><meta name="description" property="og:description" content="In recent years, visual analytics (VA) has shown promise in alleviating the challenges of interpreting black-box deep learning (DL) models. While the focus of VA for explainable DL has been mainly on classification problems, DL is gaining popularity in high-dimensional-to-high-dimensional (H-H) problems such as image-to-image translation. In contrast to classification, H-H problems have no explicit instance groups or classes to study. Each output is continuous, high-dimensional, and changes in an unknown non-linear manner with changes in the input. These unknown relations between the input, model and output necessitate the user to analyze them in conjunction, leveraging symmetries between them. Since classification tasks do not exhibit some of these challenges, most existing VA systems and frameworks allow limited control of the components required to analyze models beyond classification. Hence, we identify the need for and present a unified conceptual framework, the Transform-and-Perform framework (T&P), to facilitate the design of VA systems for DL model analysis focusing on H-H problems. T&P provides a checklist to structure and identify workflows and analysis strategies to design new VA systems, and understand existing ones to uncover potential gaps for improvements. The goal is to aid the creation of effective VA systems that support the structuring of model understanding and identifying actionable insights for model improvements. We highlight the growing need for new frameworks like T&P with a real-world image-to image translation application. We illustrate how T&P effectively supports the understanding and identification of potential gaps in existing VA systems."><meta name="title" property="og:title" content="Virtual IEEE VIS 2023 - Paper: The Transform-and-Perform framework: Explainable deep learning beyond classification"><meta property="og:type" content="website"><title>IEEE VIS 2023 Content: The Transform-and-Perform framework: Explainable deep learning beyond classification</title></head> <body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style> <div class="container mb-5"> <div class="tabs"> </div> <div class="content"> <div class="row mt-3"> <div class="col-md-12"> <nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"> <ol class="breadcrumb"> <li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a> </li> <li class="breadcrumb-item"><a href="session_full30.html">VIS for ML</a> </li> <li class="breadcrumb-item active text-truncate" aria-current="page">The Transform-and-Perform framework: Explainable deep learning beyond classification</li> </ol> </nav> <h1 class="paper-title">The Transform-and-Perform framework: Explainable deep learning beyond classification</h1> <div class="checkbox-bookmark fas" style="font-size: 24pt;position: absolute; top:10px; right:20px;" data-tippy-content="(un-)bookmark this paper"> &#xf02e; </div> <h3 class="paper-authors pb-2 mt-3">Vidya Prasad, Ruud J. G. van Sloun, Stef van den Elzen, Anna Vilanova, Nicola Pezzotti</h3> <h5 class="paper-link pb-2"> <a href="https://doi.org/10.1109/TVCG.2022.3219248"> <span class="fas mr-1">&#xf15c;</span> DOI: 10.1109/TVCG.2022.3219248 </a> </h5> <h3 class="session-room mt-4"> <span class="fas mr-1">&#xf108;</span> Room: 109 </h3> <h5 class="paper-presentation pb-2"> <span class="format-date">2023-10-25T04:57:00Z</span> <span alt="Change timezone on schedule page" class="timezone tztooltip"> <strong>GMT<span class="selectedTimezone">-0600</span></strong> <span class="tztooltiptext">Change your timezone on the schedule page</span> </span> <br> <span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"> <span class="relative-time">2023-10-25T04:57:00Z</span> <span class="current-time tztooltiptext"></span> </span> </h5> </div> </div> <div class="row my-3"> <div class="col-md-8"> <figure class="figure"> <img class="figure-img img-fluid" src="https://ieeevis.b-cdn.net/vis_2023/paper_images/v-tvcg-9937145.png" alt="Exemplar figure, described by caption below" aria-describedby="figure-caption"> <figcaption class="figure-caption" id="figure-caption">We introduce the Transform-and-Perform (T&amp;P) framework, designed to assist visual analytics (VA) designers in creating VA systems with general applicability to high-dimensional-to-high-dimensional (H-H) problems. T&amp;P helps identify workflows and analysis strategies for designing new VA systems. It also helps reveal potential gaps in existing systems. T&amp;P enables analysis across the &#34;3Ws&#34; of model behavior: 1) when a behavior occurs (input analysis), 2) how &amp; why it occurs (model analysis), and 3) what the behavior is (output analysis). By utilizing input-output symmetries, T&amp;P offers a formal approach to understanding a model&#39;s inductive biases, crucial for analyzing a range of DL models.</figcaption> </figure> </div> </div> <div class="row my-3"> <div class="col-md-8"> </div> </div> <div class="row my-3"> <div class="col-md-8"> <h5 class="paper-details-heading">Fast forward</h5> <iframe width="730" height="410" src="https://www.youtube-nocookie.com/embed/NT6ajUlK18c?rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> </div> </div> <div class="row my-3"> <div class="col-md-8"> <h5 class="paper-details-heading">Full Video</h5> <iframe width="730" height="410" src="https://www.youtube-nocookie.com/embed/EsEtAxp0QVk?rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> </div> </div> <div class="row my-3"> <div class="col-md-8"> <h5 class="paper-details-heading">Keywords</h5> <p>Visual Analytics;Explainable AI;XAI;Framework;Deep Learning;High-dimensional-to-high-dimensional translation</p> <h5 class="paper-details-heading">Abstract</h5> <p>In recent years, visual analytics (VA) has shown promise in alleviating the challenges of interpreting black-box deep learning (DL) models. While the focus of VA for explainable DL has been mainly on classification problems, DL is gaining popularity in high-dimensional-to-high-dimensional (H-H) problems such as image-to-image translation. In contrast to classification, H-H problems have no explicit instance groups or classes to study. Each output is continuous, high-dimensional, and changes in an unknown non-linear manner with changes in the input. These unknown relations between the input, model and output necessitate the user to analyze them in conjunction, leveraging symmetries between them. Since classification tasks do not exhibit some of these challenges, most existing VA systems and frameworks allow limited control of the components required to analyze models beyond classification. Hence, we identify the need for and present a unified conceptual framework, the Transform-and-Perform framework (T&amp;P), to facilitate the design of VA systems for DL model analysis focusing on H-H problems. T&amp;P provides a checklist to structure and identify workflows and analysis strategies to design new VA systems, and understand existing ones to uncover potential gaps for improvements. The goal is to aid the creation of effective VA systems that support the structuring of model understanding and identifying actionable insights for model improvements. We highlight the growing need for new frameworks like T&amp;P with a real-world image-to image translation application. We illustrate how T&amp;P effectively supports the understanding and identification of potential gaps in existing VA systems.</p> </div> </div> <script lang="js">
      const paperID = "v-tvcg-9937145"
      $(document).ready(() => {
        tippy('[data-tippy-content]');

        const allBookmarks =
          d3.selectAll('.checkbox-bookmark')
            .on("click", function () {
              const newValue = !d3.select(this).classed('selected');
              API.markSet(API.storeIDs.bookmarked, paperID, newValue);
              d3.select(this).classed('selected', newValue);
            })
        API.markGet(API.storeIDs.bookmarked, paperID).then(is_bookmarked => {
          is_bookmarked = !!is_bookmarked;
          allBookmarks.classed('selected', is_bookmarked);
        })
        API.markSet(API.storeIDs.visited, paperID, true);

      })

    </script> <script src="/static/2023/js/views/timezone.js"></script> </div> </div> <script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" â€“ ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script> </body> </html>