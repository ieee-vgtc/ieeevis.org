<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2024/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/1.12/auth0-spa-js.production.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2024/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2024/js/data/persistor.js"></script><script src="/static/2024/js/data/api.js"></script><link rel="shortcut icon" href="/static/2024/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2024/css/Zilla.css" rel="stylesheet"><link href="/static/2024/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2024/css/main.css"><link rel="stylesheet" href="/static/2024/css/fa_solid.css"><link rel="stylesheet" href="/static/2024/css/lazy_load.css"><link rel="stylesheet" href="/static/2024/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2024 - Paper: VisTellAR: Embedding Data Visualization to Short-form Videos Using Mobile Augmented Reality"><meta name="twitter:description" content="With the rise of short-form video platforms and the increasing availability of data, we see the potential for people to share short-form videos embedded with data in situ (e.g., daily steps when running) to increase the credibility and expressiveness of their stories. However, creating and sharing such videos in situ is challenging since it involves multiple steps and skills (e.g., data visualization creation and video editing), especially for amateurs. By conducting a formative study (N=10) using three design probes, we collected the motivations and design requirements. We then built VisTellAR, a mobile AR authoring tool, to help amateur video creators embed data visualizations in short-form videos in situ. A two-day user study shows that participants (N=12) successfully created various videos with data visualizations in situ and they confirmed the ease of use and learning. AR pre-stage authoring was useful to assist people in setting up data visualizations in reality with more designs in camera movements and interaction with gestures and physical objects to storytelling."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2024/paper_images/v-tvcg-20243372104_Image.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2024/paper_images/v-tvcg-20243372104_Image.png"><meta name="description" property="og:description" content="With the rise of short-form video platforms and the increasing availability of data, we see the potential for people to share short-form videos embedded with data in situ (e.g., daily steps when running) to increase the credibility and expressiveness of their stories. However, creating and sharing such videos in situ is challenging since it involves multiple steps and skills (e.g., data visualization creation and video editing), especially for amateurs. By conducting a formative study (N=10) using three design probes, we collected the motivations and design requirements. We then built VisTellAR, a mobile AR authoring tool, to help amateur video creators embed data visualizations in short-form videos in situ. A two-day user study shows that participants (N=12) successfully created various videos with data visualizations in situ and they confirmed the ease of use and learning. AR pre-stage authoring was useful to assist people in setting up data visualizations in reality with more designs in camera movements and interaction with gestures and physical objects to storytelling."><meta name="title" property="og:title" content="Virtual IEEE VIS 2024 - Paper: VisTellAR: Embedding Data Visualization to Short-form Videos Using Mobile Augmented Reality"><meta property="og:type" content="website"><title>IEEE VIS 2024 Content: VisTellAR: Embedding Data Visualization to Short-form Videos Using Mobile Augmented Reality</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-12"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a></li><li class="breadcrumb-item"><a href="session_full25.html">Once Upon a Visualization</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">VisTellAR: Embedding Data Visualization to Short-form Videos Using Mobile Augmented Reality</li></ol></nav><h1 class="paper-title">VisTellAR: Embedding Data Visualization to Short-form Videos Using Mobile Augmented Reality</h1><div class="checkbox-bookmark fas" style="font-size: 24pt;position: absolute; top:10px; right:20px;" data-tippy-content="(un-)bookmark this paper"> &#xf02e; </div><h4 class="paper-authors pb-2 mt-2"><span class="fas mr-1">&#xf183;</span><a href="mailto:">Wai Tong</a> - </h4><h4 class="paper-authors pb-2 mt-2"><span class="fas mr-1">&#xf183;</span> Kento Shigyo - </h4><h4 class="paper-authors pb-2 mt-2"><span class="fas mr-1">&#xf183;</span> Lin-Ping Yuan - </h4><h4 class="paper-authors pb-2 mt-2"><span class="fas mr-1">&#xf183;</span> Mingming Fan - </h4><h4 class="paper-authors pb-2 mt-2"><span class="fas mr-1">&#xf183;</span> Ting-Chuen Pong - </h4><h4 class="paper-authors pb-2 mt-2"><span class="fas mr-1">&#xf183;</span> Huamin Qu - </h4><h4 class="paper-authors pb-2 mt-2"><span class="fas mr-1">&#xf183;</span> Meng Xia - </h4><h5 class="paper-link pb-2"><a href="https://www.researchgate.net/publication/378657335_VisTellAR_Embedding_Data_Visualization_to_Short-form_Videos_Using_Mobile_Augmented_Reality"><span class="fas mr-1" title="This paper has an author's preprint available online.">&#xf09c;</span> Download preprint PDF </a></h5><h5 class="paper-link pb-2"><a href="https://doi.org/10.1109/TVCG.2024.3372104"><span class="fas mr-1">&#xf15c;</span> DOI: 10.1109/TVCG.2024.3372104 </a></h5><h3 class="session-room mt-4"><span class="fas mr-1">&#xf108;</span><a href="room_bayshore5.html"> Room: Bayshore V </a></h3><h5 class="paper-presentation pb-2"><span class="format-date">2024-10-17T16:24:00Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2024-10-17T16:24:00Z</span><span class="current-time tztooltiptext"></span></span></h5></div></div><div class="row my-3"><div class="col-md-8"><figure class="figure"><img class="figure-img img-fluid" src="https://ieeevis.b-cdn.net/vis_2024/paper_images/v-tvcg-20243372104_Image.png" alt="Exemplar figure, described by caption below" aria-describedby="figure-caption"><figcaption class="figure-caption" id="figure-caption">This figure illustrates an authoring process. (a-b) VisTellAR detects planes and objects for users to anchor visualizations in reality. Users can edit the data, mark, axis, and behavior. (c-d) During video-taking, users can voice over, perform hand gestures, and see a countdown that notifies them when the visualization will be shown. (e-f) After taking the video, a timeline is shown to indicate when visualizations take place in the video. Users can reconfigure visualizations if needed. </figcaption></figure></div></div><div class="row my-3"><div class="col-md-8"></div></div><div class="row my-3"><div class="col-md-8"><h5 class="paper-details-heading">Fast forward</h5><iframe width="730" height="410" src="https://www.youtube-nocookie.com/embed/EeX1q0ZhSII?rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></div></div><div class="row my-3"><div class="col-md-8"><h5 class="paper-details-heading">Keywords</h5><p>Personal data, augmented reality, data visualization, storytelling, short-form video</p><h5 class="paper-details-heading">Abstract</h5><p>With the rise of short-form video platforms and the increasing availability of data, we see the potential for people to share short-form videos embedded with data in situ (e.g., daily steps when running) to increase the credibility and expressiveness of their stories. However, creating and sharing such videos in situ is challenging since it involves multiple steps and skills (e.g., data visualization creation and video editing), especially for amateurs. By conducting a formative study (N=10) using three design probes, we collected the motivations and design requirements. We then built VisTellAR, a mobile AR authoring tool, to help amateur video creators embed data visualizations in short-form videos in situ. A two-day user study shows that participants (N=12) successfully created various videos with data visualizations in situ and they confirmed the ease of use and learning. AR pre-stage authoring was useful to assist people in setting up data visualizations in reality with more designs in camera movements and interaction with gestures and physical objects to storytelling.</p></div></div><script lang="js">
      const paperID = "v-tvcg-20243372104"
      $(document).ready(() => {
        tippy('[data-tippy-content]');

        const allBookmarks =
          d3.selectAll('.checkbox-bookmark')
            .on("click", function () {
              const newValue = !d3.select(this).classed('selected');
              API.markSet(API.storeIDs.bookmarked, paperID, newValue);
              d3.select(this).classed('selected', newValue);
            })
        API.markGet(API.storeIDs.bookmarked, paperID).then(is_bookmarked => {
          is_bookmarked = !!is_bookmarked;
          allBookmarks.classed('selected', is_bookmarked);
        })
        API.markSet(API.storeIDs.visited, paperID, true);

      })

    </script><script src="/static/2024/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" â€“ ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script></body></html>