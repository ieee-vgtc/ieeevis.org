<!DOCTYPE html><html lang="en"> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2023/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/1.12/auth0-spa-js.production.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2023/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2023/js/data/persistor.js"></script><script src="/static/2023/js/data/api.js"></script><link rel="shortcut icon" href="/static/2023/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2023/css/Zilla.css" rel="stylesheet"><link href="/static/2023/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2023/css/main.css"><link rel="stylesheet" href="/static/2023/css/fa_solid.css"><link rel="stylesheet" href="/static/2023/css/lazy_load.css"><link rel="stylesheet" href="/static/2023/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="Virtual IEEE VIS 2023 - Paper: EVNet: An Explainable Deep Network for Dimension Reduction"><meta name="twitter:description" content="Dimension reduction (DR) is commonly utilized to capture the intrinsic structure and transform high-dimensional data into low-dimensional space while retaining meaningful properties of the original data. It is used in various applications, such as image recognition, single-cell sequencing analysis, and biomarker discovery. However, contemporary parametric-free and parametric DR techniques suffer from several significant shortcomings, such as the inability to preserve global and local features and the pool generalization performance. On the other hand, regarding explainability, it is crucial to comprehend the embedding process, especially the contribution of each part to the embedding process, while understanding how each feature affects the embedding results that identify critical components and help diagnose the embedding process. To address these problems, we have developed a deep neural network method called EVNet, which provides not only excellent performance in structural maintainability but also explainability to the DR therein. EVNet starts with data augmentation and a manifold-based loss function to improve embedding performance. The explanation is based on saliency maps and aims to examine the trained EVNet parameters and contributions of components during the embedding process. The proposed techniques are integrated with a visual interface to help the user to adjust EVNet to achieve better DR performance and explainability. The interactive visual interface makes it easier to illustrate the data features, compare different DR techniques, and investigate DR. An in-depth experimental comparison shows that EVNet consistently outperforms the state-of-the-art methods in both performance measures and explainability."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="Dimension reduction (DR) is commonly utilized to capture the intrinsic structure and transform high-dimensional data into low-dimensional space while retaining meaningful properties of the original data. It is used in various applications, such as image recognition, single-cell sequencing analysis, and biomarker discovery. However, contemporary parametric-free and parametric DR techniques suffer from several significant shortcomings, such as the inability to preserve global and local features and the pool generalization performance. On the other hand, regarding explainability, it is crucial to comprehend the embedding process, especially the contribution of each part to the embedding process, while understanding how each feature affects the embedding results that identify critical components and help diagnose the embedding process. To address these problems, we have developed a deep neural network method called EVNet, which provides not only excellent performance in structural maintainability but also explainability to the DR therein. EVNet starts with data augmentation and a manifold-based loss function to improve embedding performance. The explanation is based on saliency maps and aims to examine the trained EVNet parameters and contributions of components during the embedding process. The proposed techniques are integrated with a visual interface to help the user to adjust EVNet to achieve better DR performance and explainability. The interactive visual interface makes it easier to illustrate the data features, compare different DR techniques, and investigate DR. An in-depth experimental comparison shows that EVNet consistently outperforms the state-of-the-art methods in both performance measures and explainability."><meta name="title" property="og:title" content="Virtual IEEE VIS 2023 - Paper: EVNet: An Explainable Deep Network for Dimension Reduction"><meta property="og:type" content="website"><title>IEEE VIS 2023 Content: EVNet: An Explainable Deep Network for Dimension Reduction</title></head> <body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style> <div class="container mb-5"> <div class="tabs"> </div> <div class="content"> <div class="row mt-3"> <div class="col-md-12"> <nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"> <ol class="breadcrumb"> <li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a> </li> <li class="breadcrumb-item"><a href="session_full10.html">High Dimensional Data</a> </li> <li class="breadcrumb-item active text-truncate" aria-current="page">EVNet: An Explainable Deep Network for Dimension Reduction</li> </ol> </nav> <h1 class="paper-title">EVNet: An Explainable Deep Network for Dimension Reduction</h1> <div class="checkbox-bookmark fas" style="font-size: 24pt;position: absolute; top:10px; right:20px;" data-tippy-content="(un-)bookmark this paper"> &#xf02e; </div> <h3 class="paper-authors pb-2 mt-3">Zelin Zang, Shenghui Cheng, Linyan Lu, Hanchen Xia, Liangyu Li, Yaoting Sun, Yongjie Xu, Lei Shang, Baigui Sun, Stan Z. Li</h3> <h5 class="paper-link pb-2"> <a href="https://doi.org/10.1109/TVCG.2022.3223399"> <span class="fas mr-1">&#xf15c;</span> DOI: 10.1109/TVCG.2022.3223399 </a> </h5> <h3 class="session-room mt-4"> <span class="fas mr-1">&#xf108;</span> Room: 106 </h3> <h5 class="paper-presentation pb-2"> <span class="format-date">2023-10-24T22:24:00Z</span> <span alt="Change timezone on schedule page" class="timezone tztooltip"> <strong>GMT<span class="selectedTimezone">-0600</span></strong> <span class="tztooltiptext">Change your timezone on the schedule page</span> </span> <br> <span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"> <span class="relative-time">2023-10-24T22:24:00Z</span> <span class="current-time tztooltiptext"></span> </span> </h5> </div> </div> <div class="row my-3"> <div class="col-md-8"> <figure class="figure"> <img class="figure-img img-fluid" src="https://ieeevis.b-cdn.net/vis_2023/paper_images/blank.png" alt="Exemplar figure, but none was provided by the authors"> <figcaption class="figure-caption" id="figure-caption"></figcaption> </figure> </div> </div> <div class="row my-3"> <div class="col-md-8"> </div> </div> <div class="row my-3"> <div class="col-md-8"> <h5 class="paper-details-heading">Keywords</h5> <p>Dimension Reduction;Explainability of DR Models;Deep Learning;Parametric Model</p> <h5 class="paper-details-heading">Abstract</h5> <p>Dimension reduction (DR) is commonly utilized to capture the intrinsic structure and transform high-dimensional data into low-dimensional space while retaining meaningful properties of the original data. It is used in various applications, such as image recognition, single-cell sequencing analysis, and biomarker discovery. However, contemporary parametric-free and parametric DR techniques suffer from several significant shortcomings, such as the inability to preserve global and local features and the pool generalization performance. On the other hand, regarding explainability, it is crucial to comprehend the embedding process, especially the contribution of each part to the embedding process, while understanding how each feature affects the embedding results that identify critical components and help diagnose the embedding process. To address these problems, we have developed a deep neural network method called EVNet, which provides not only excellent performance in structural maintainability but also explainability to the DR therein. EVNet starts with data augmentation and a manifold-based loss function to improve embedding performance. The explanation is based on saliency maps and aims to examine the trained EVNet parameters and contributions of components during the embedding process. The proposed techniques are integrated with a visual interface to help the user to adjust EVNet to achieve better DR performance and explainability. The interactive visual interface makes it easier to illustrate the data features, compare different DR techniques, and investigate DR. An in-depth experimental comparison shows that EVNet consistently outperforms the state-of-the-art methods in both performance measures and explainability.</p> </div> </div> <script lang="js">
      const paperID = "v-tvcg-9956753"
      $(document).ready(() => {
        tippy('[data-tippy-content]');

        const allBookmarks =
          d3.selectAll('.checkbox-bookmark')
            .on("click", function () {
              const newValue = !d3.select(this).classed('selected');
              API.markSet(API.storeIDs.bookmarked, paperID, newValue);
              d3.select(this).classed('selected', newValue);
            })
        API.markGet(API.storeIDs.bookmarked, paperID).then(is_bookmarked => {
          is_bookmarked = !!is_bookmarked;
          allBookmarks.classed('selected', is_bookmarked);
        })
        API.markSet(API.storeIDs.visited, paperID, true);

      })

    </script> <script src="/static/2023/js/views/timezone.js"></script> </div> </div> <script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" â€“ ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script> </body> </html>