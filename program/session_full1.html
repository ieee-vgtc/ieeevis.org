<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/2.1/auth0-spa-js.production.js"></script><script>
              const auth0_domain = "ieeevis.us.auth0.com";
              const auth0_client_id = "oF5BXUklWOjSjUeg5Tzai2DysHITXYhT";
            </script><script src="/static/2025/js/modules/auth0protect.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2025/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2025/js/data/persistor.js"></script><script src="/static/2025/js/data/api.js"></script><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2025/css/Zilla.css" rel="stylesheet"><link href="/static/2025/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2025/css/main.css"><link rel="stylesheet" href="/static/2025/css/fa_solid.css"><link rel="stylesheet" href="/static/2025/css/lazy_load.css"><link rel="stylesheet" href="/static/2025/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2025 - Session: VIS Full Papers: Agentic Visualization and Intelligent Systems"><meta name="twitter:description" content="See the session and its presentations inside."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="See the session and its presentations inside."><meta name="title" property="og:title" content="Virtual IEEE VIS 2025 - Session: VIS Full Papers: Agentic Visualization and Intelligent Systems"><meta property="og:type" content="website"><title>IEEE VIS 2025 Content: VIS Full Papers: Agentic Visualization and Intelligent Systems</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style="display: none;"><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-8"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item" aria-current="page"><a href="events.html">All events</a></li><li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">Agentic Visualization and Intelligent Systems</li></ol></nav><h1 class="session-title">VIS Full Papers: Agentic Visualization and Intelligent Systems</h1><h3 class="session-url"><a href="https://ieeevis.org/year/2025/program/event_v-full.html" target="_blank"><span class="fas mr-1">&#xf57c;</span> https://ieeevis.org/year/2025/program/event_v-full.html</a></h3><h3 class="session-chair"><span class="fas mr-1">&#xf007;</span> Session chair: Sungahn Ko </h3><h3 class="session-room mt-4"> Room: Hall E1 </h3><h3 class="session-date"><span class="fas mr-1">&#xf017;</span><span class="format-date-span-full">2025-11-05T14:45:00+00:00 &ndash; 2025-11-05T16:00:00+00:00</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2025-11-05T14:45:00+00:00 &ndash; 2025-11-05T16:00:00+00:00</span><span class="current-time tztooltiptext"></span></span></h3></div><div class="col-md-1"></div><div class="col-md-3 session-links"><h5 class="session-info my-4"><a href="#list"><span class="fas mr-2">&#xf358;</span> Jump to event listing </a></h5><h5 class="session-info my-4"><a href="https://data.tech.ieeevis.org/storage/v1/object/public/ics/vis2025/full1.ics"><span class="fas mr-2">&#xf073;</span> Add to Calendar</a></h5></div></div><div class="row my-5 discord-public-link hide-auth-controls"><div class="col-md-8"><p><span class="fas mx-1">&#xf086;</span><a href="https://discord.com/channels/1422883912660549696/1430945416660254782" target="_blank">Discord link</a></p></div></div><div class="row my-5"><div class="col-md-8"><p>Recordings will be made available after the session.</p></div></div><hr><div class="row my-4"><div class="col-md-8"><h2 class="room_session_descriptor d-block py-2"><a name="list">Presentations in this session:</a></h2></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1045&#39;, &#39;session_id&#39;: &#39;full1&#39;, &#39;title&#39;: &#39;ProactiveVA: Proactive Visual Analytics with LLM-based UI Agent&#39;, &#39;contributors&#39;: [&#39;Yuheng Zhao&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T14:45:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T14:45:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T14:57:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Yuheng Zhao&#39;, &#39;email&#39;: &#39;yuhengzhao_cn@163.com&#39;, &#39;affiliation&#39;: &#39;Fudan Univerisity&#39;}, {&#39;name&#39;: &#39;Xueli Shu&#39;, &#39;email&#39;: &#39;3504936154@qq.com&#39;, &#39;affiliation&#39;: &#39;Fudan University&#39;}, {&#39;name&#39;: &#39;Liwen Fan&#39;, &#39;email&#39;: &#39;flwfdd@gmail.com&#39;, &#39;affiliation&#39;: &#39;Beijing Institute of Technology&#39;}, {&#39;name&#39;: &#39;Lin Gao&#39;, &#39;email&#39;: &#39;lgao.lynne@gmail.com&#39;, &#39;affiliation&#39;: &#39;Fudan University&#39;}, {&#39;name&#39;: &#39;Yu Zhang&#39;, &#39;email&#39;: &#39;yuzhang94@outlook.com&#39;, &#39;affiliation&#39;: &#39;University of Oxford&#39;}, {&#39;name&#39;: &#39;Siming Chen&#39;, &#39;email&#39;: &#39;simingchen3@gmail.com&#39;, &#39;affiliation&#39;: &#39;Fudan University&#39;}], &#39;abstract&#39;: &#34;Visual analytics (VA) is typically applied to complex data, thus requiring complex tools.\nWhile visual analytics empowers analysts in data analysis, analysts may get lost in the complexity occasionally. This highlights the need for intelligent assistance mechanisms.\nHowever, even the latest LLM-assisted VA systems only provide help when explicitly requested by the user, making them insufficiently intelligent to offer suggestions when analysts need them the most. We propose a ProactiveVA framework in which LLM-powered UI agent monitors user interactions and delivers context-aware assistance proactively. To design effective proactive assistance, we first conducted a formative study analyzing help-seeking behaviors in user interaction logs, identifying when users need proactive help, what assistance they require, and how the agent should intervene. Based on this analysis, we distilled key design requirements in terms of intent recognition, solution generation, interpretability and controllability. Guided by these requirements, we develop a three-stage UI agent pipeline including perception, reasoning, and acting. The agent autonomously perceives users&#39; needs from VA interaction logs, providing tailored suggestions and intuitive guidance through interactive exploration of the system. We implemented the framework in two representative types of VA systems, demonstrating its generalizability, and evaluated the effectiveness through an algorithm evaluation, case and expert study and a user study. We also discuss current design trade-offs of proactive VA and areas for further exploration.&#34;, &#39;uid&#39;: &#39;47c46990-8edb-4014-be27-c1c07f128d60&#39;, &#39;keywords&#39;: [&#39;Visual analytics&#39;, &#39;mixed-initiative&#39;, &#39;large language model&#39;, &#39;interface agent&#39;, &#39;proactive agent&#39;, &#39;human-AI collaboration&#39;], &#39;preprint_link&#39;: &#39;https://www.arxiv.org/abs/2507.18165&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_47c46990-8edb-4014-be27-c1c07f128d60.html"> ProactiveVA: Proactive Visual Analytics with LLM-based UI Agent <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Yuheng Zhao, Xueli Shu, Liwen Fan, Lin Gao, Yu Zhang, Siming Chen </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Yuheng Zhao </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T14:45:00.000Z &ndash; 2025-11-05T14:57:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2023-12-0857&#39;, &#39;session_id&#39;: &#39;full1&#39;, &#39;title&#39;: &#39;FinFlier: Automating Graphical Overlays for Financial Visualizations With Knowledge-Grounding Large Language Model&#39;, &#39;contributors&#39;: [&#39;Jianing Hao&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T14:57:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T14:57:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:09:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Jianing Hao&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Manling Yang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Qing Shi&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Yuzhe Jiang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Guang Zhang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Wei Zeng&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Graphical overlays that layer visual elements onto charts, are effective to convey insights and context in financial narrative visualizations. However, automating graphical overlays is challenging due to complex narrative structures and limited understanding of effective overlays. To address the challenge, we first summarize the commonly used graphical overlays and narrative structures, and the proper correspondence between them in financial narrative visualizations, elected by a survey of 1752 layered charts with corresponding narratives. We then design FinFlier, a two-stage innovative system leveraging a knowledge-grounding large language model to automate graphical overlays for financial visualizations. The text-data binding module enhances the connection between financial vocabulary and tabular data through advanced prompt engineering, and the graphics overlaying module generates effective overlays with narrative sequencing. We demonstrate the feasibility and expressiveness of FinFlier through a gallery of graphical overlays covering diverse financial narrative visualizations. Performance evaluations and user studies further confirm system’s effectiveness and the quality of generated layered charts.&#39;, &#39;uid&#39;: &#39;94381081-f2ce-4b6b-873e-14124be28e0b&#39;, &#39;keywords&#39;: [&#39;Data visualization&#39;, &#39;Visualization&#39;, &#39;Economic indicators&#39;, &#39;Vocabulary&#39;, &#39;Surveys&#39;, &#39;Finance&#39;, &#39;Authoring systems&#39;, &#39;Terminology&#39;, &#39;Prompt engineering&#39;, &#39;Market research&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2412.06821&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2024.3514138&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_94381081-f2ce-4b6b-873e-14124be28e0b.html"> FinFlier: Automating Graphical Overlays for Financial Visualizations With Knowledge-Grounding Large Language Model <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Jianing Hao, Manling Yang, Qing Shi, Yuzhe Jiang, Guang Zhang, Wei Zeng </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Jianing Hao </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T14:57:00.000Z &ndash; 2025-11-05T15:09:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-02-0095&#39;, &#39;session_id&#39;: &#39;full1&#39;, &#39;title&#39;: &#39;HINTs: Sensemaking on large collections of documents with Hypergraph visualization and INTelligent agents&#39;, &#39;contributors&#39;: [&#39;Sam Yu-Te Lee&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T15:09:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T15:09:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:21:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Sam Yu-Te Lee&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Kwan-Liu Ma&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#34;Sensemaking on a large collection of documents (corpus) is a challenging task often found in fields such as market research, legal studies, intelligence analysis, political science, or computational linguistics. Previous works approach this problem from topic- and entity-based perspectives, but the capability of the underlying NLP model limits their effectiveness. Recent advances in prompting with LLMs present opportunities to enhance such approaches with higher accuracy and customizability. However, poorly designed prompts and visualizations could mislead users into falsely interpreting the visualizations and hinder the system&#39;s trustworthiness. In this paper, we address this issue by taking into account the user analysis tasks and visualization goals in the prompt-based data extraction stage, thereby extending the concept of Model Alignment. We present HINTs, a VA system for supporting sensemaking on large collections of documents, combining previous entity-based and topic-based approaches. The visualization pipeline of HINTs consists of three stages. First, entities and topics are extracted from the corpus with prompts. Then, the result is modeled as a hypergraph and hierarchically clustered. Finally, an enhanced space-filling curve layout is applied to visualize the hypergraph for interactive exploration. The system further integrates an LLM-based intelligent chatbot agent in the interface to facilitate the sensemaking of interested documents. To demonstrate the generalizability and effectiveness of the HINTs system, we present two case studies on different domains and a comparative user study. We report our insights on the behavior patterns and challenges when intelligent agents are used to facilitate sensemaking. We find that while intelligent agents can address many challenges in sensemaking, the visual hints that visualizations provide are still necessary. We discuss limitations and future work for combining interactive visualization and LLMs more profoundly to better support corpus analysis.&#34;, &#39;uid&#39;: &#39;7eeae5e6-01ae-4570-90f6-069956401413&#39;, &#39;keywords&#39;: [&#39;Data visualization&#39;, &#39;Data mining&#39;, &#39;Intelligent agents&#39;, &#39;Visual analytics&#39;, &#39;Tag clouds&#39;, &#39;Pipelines&#39;, &#39;Fake news&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2403.02752&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2024.3459961&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_7eeae5e6-01ae-4570-90f6-069956401413.html"> HINTs: Sensemaking on large collections of documents with Hypergraph visualization and INTelligent agents <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Sam Yu-Te Lee, Kwan-Liu Ma </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Sam Yu-Te Lee </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T15:09:00.000Z &ndash; 2025-11-05T15:21:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024.3496112&#39;, &#39;session_id&#39;: &#39;full1&#39;, &#39;title&#39;: &#39;LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution&#39;, &#39;contributors&#39;: [&#39;Yuheng Zhao&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T15:21:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T15:21:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:33:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Yuheng Zhao&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Junjie Wang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Linbin Xiang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Xiaowen Zhang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Zifei Guo&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Cagatay Turkay&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Yu Zhang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Siming Chen&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Visual analytics (VA) requires analysts to iteratively propose analysis tasks based on observations and execute tasks by creating visualizations and interactive exploration to gain insights. This process demands skills in programming, data processing, and visualization tools, highlighting the need for a more intelligent, streamlined VA approach. Large language models (LLMs) have recently been developed as agents to handle various tasks with dynamic planning and tool-using capabilities, offering the potential to enhance the efficiency and versatility of VA. We propose LightVA, a lightweight VA framework that supports task decomposition, data analysis, and interactive exploration through human-agent collaboration. Our method is designed to help users progressively translate high-level analytical goals into low-level tasks, producing visualizations and deriving insights. Specifically, we introduce an LLM agent-based task planning and execution strategy, employing a recursive process involving a planner, executor, and controller. The planner is responsible for recommending and decomposing tasks, the executor handles task execution, including data analysis, visualization generation and multi-view composition, and the controller coordinates the interaction between the planner and executor. Building on the framework, we develop a system with a hybrid user interface that includes a task flow diagram for monitoring and managing the task planning process, a visualization panel for interactive data exploration, and a chat view for guiding the model through natural language instructions. We examine the effectiveness of our method through a usage scenario and an expert study.&#39;, &#39;uid&#39;: &#39;aab34439-1bda-4a07-916a-80e89f82ff62&#39;, &#39;keywords&#39;: [&#39;Data visualization&#39;, &#39;Planning&#39;, &#39;Data analysis&#39;, &#39;Data models&#39;, &#39;Visual analytics&#39;, &#39;Analytical models&#39;, &#39;Market research&#39;, &#39;Data mining&#39;, &#39;Collaboration&#39;, &#39;Adaptation models&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2411.05651&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2024.3496112&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_aab34439-1bda-4a07-916a-80e89f82ff62.html"> LightVA: Lightweight Visual Analytics with LLM Agent-Based Task Planning and Execution <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Yuheng Zhao, Junjie Wang, Linbin Xiang, Xiaowen Zhang, Zifei Guo, Cagatay Turkay, Yu Zhang, Siming Chen </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Yuheng Zhao </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T15:21:00.000Z &ndash; 2025-11-05T15:33:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-07-0597.R2&#39;, &#39;session_id&#39;: &#39;full1&#39;, &#39;title&#39;: &#39;Visualizationary: Automating Design Feedback for Visualization Designers Using Large Language Models&#39;, &#39;contributors&#39;: [&#39;Sungbok Shin&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T15:33:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T15:33:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:45:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Sungbok Shin&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Sanghyun Hong&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Niklas Elmqvist&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Interactive visualization editors empower users to author visualizations without writing code, but do not provide guidance on the art and craft of effective visual communication. In this article, we explore the potential of using an off-the-shelf large language models (LLMs) to provide actionable and customized feedback to visualization designers. Our implementation, Visualizationary, demonstrates how ChatGPT can be used for this purpose through two key components: a preamble of visualization design guidelines and a suite of perceptual filters that extract salient metrics from a visualization image. We present findings from a longitudinal user study involving 13 visualization designers—6 novices, 4 intermediates, and 3 experts—who authored a new visualization from scratch over several days. Our results indicate that providing guidance in natural language via an LLM can aid even seasoned designers in refining their visualizations.&#39;, &#39;uid&#39;: &#39;63daa1e4-de6c-4f05-8528-64eaf5d0295c&#39;, &#39;keywords&#39;: [&#39;Data visualization&#39;, &#39;Visualization&#39;, &#39;Computational modeling&#39;, &#39;Training&#39;, &#39;Measurement&#39;, &#39;Filters&#39;, &#39;Predictive models&#39;, &#39;Image color analysis&#39;, &#39;Translation&#39;, &#39;Large language models&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2409.13109&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2025.3579700&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_63daa1e4-de6c-4f05-8528-64eaf5d0295c.html"> Visualizationary: Automating Design Feedback for Visualization Designers Using Large Language Models <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Sungbok Shin, Sanghyun Hong, Niklas Elmqvist </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Sungbok Shin </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T15:33:00.000Z &ndash; 2025-11-05T15:45:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2025-02-0146&#39;, &#39;session_id&#39;: &#39;full1&#39;, &#39;title&#39;: &#39;VOICE: Visual Oracle for Interaction, Conversation, and Explanation&#39;, &#39;contributors&#39;: [&#39;Donggang Jia&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T15:45:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T15:45:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:57:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Donggang Jia&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Alexandra Irger&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Lonni Besançon&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Ondřej Strnad&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Deng Luo&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Johanna Björklund&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Alexandre Kouyoumdjian&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Anders Ynnerman&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Ivan Viola&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;We present VOICE, a novel approach to science communication that connects large language models’ conversational capabilities with interactive exploratory visualization. VOICE introduces several innovative technical contributions that drive our conversational visualization framework. Based on the collected design requirements, we introduce a two-layer agent architecture that can perform task assignment, instruction extraction, and coherent content generation. We employ fine-tuning and prompt engineering techniques to tailor agents’ performance to their specific roles and accurately respond to user queries. Our interactive text-to-visualization method generates a flythrough sequence matching the content explanation. In addition, natural language interaction provides capabilities to navigate and manipulate 3D models in real-time. The VOICE framework can receive arbitrary voice commands from the user and respond verbally, tightly coupled with a corresponding visual representation, with low latency and high accuracy. We demonstrate the effectiveness of our approach by implementing a proof-of-concept prototype and applying it to the molecular visualization domain: analyzing three 3D molecular models with multiscale and multi-instance attributes. Finally, we conduct a comprehensive evaluation of the system, including quantitative and qualitative analyses on our collected dataset, along with a detailed public user study and expert interviews. The results confirm that our framework and prototype effectively meet the design requirements and cater to the needs of diverse target users.&#39;, &#39;uid&#39;: &#39;82b3ce83-b1a6-4d36-af15-47e7a8d42033&#39;, &#39;keywords&#39;: [&#39;Visualization&#39;, &#39;Data visualization&#39;, &#39;Oral communication&#39;, &#39;Biology&#39;, &#39;Biological system modeling&#39;, &#39;Three-dimensional displays&#39;, &#39;Solid modeling&#39;, &#39;Real-time systems&#39;, &#39;Prototypes&#39;, &#39;Interviews&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2304.04083&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2025.3579956&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_82b3ce83-b1a6-4d36-af15-47e7a8d42033.html"> VOICE: Visual Oracle for Interaction, Conversation, and Explanation <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Donggang Jia, Alexandra Irger, Lonni Besançon, Ondřej Strnad, Deng Luo, Johanna Björklund, Alexandre Kouyoumdjian, Anders Ynnerman, Ivan Viola </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Donggang Jia </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T15:45:00.000Z &ndash; 2025-11-05T15:57:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row my-5"><div class="col-md-8"><p>You may want to also jump to the parent event to see related presentations: <a href="event_v-full.html">VIS Full Papers</a></p></div></div><script src="/static/2025/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script><script>

$(document).ready(function() {
    setInterval(updateSessionStatus, 30 * 1000);
    updateSessionStatus(true)
})

function updateSessionStatus(onFirstLoad) {
    // We need to write the session timings into the page to calculate current/next session.
    // See blueprint_2025.py
    startTime = '2025-11-05T14:45:00+00:00'
    endTime = '2025-11-05T16:00:00+00:00'

    // We take a 8 minute grace period to the start of a session
    const sessionStart = moment(startTime).tz(current_timezone).subtract(8, 'minutes');
    const sessionEnd = moment(endTime).tz(current_timezone);

    const sessionIsCurrent = moment().tz(current_timezone).isBetween(sessionStart, sessionEnd);
    const sessionIsFuture = moment().tz(current_timezone).isBefore(sessionStart);
    const sessionIsPast = moment().tz(current_timezone).isAfter(sessionStart);

    const classesToHide = ['.future_session_alert', '.current_session_alert', '.past_session_alert', '.room_session_stream']
    classesToHide.forEach((c) => { $(c).hide();});
    if (sessionIsCurrent) {
        $('.current_session_alert').show();
    } else if (sessionIsFuture) {
        $('.future_session_alert').show();
    } else {
        // Session is in the future
        $('#zoom_alert').hide();
        $('.past_session_alert').show();
        $('.room_session_stream').show();
    }

    // Update youtube link for older sessions
    // EDIT - We don't need this when the conference isn't live
    if(sessionIsPast){
        const roomidjson = "e1-"+moment(startTime).format('ddd').toLowerCase()+".json"
        // console.log("this session was in:" , roomidjson)

        return fetch("https://virtual-data.ieeevis.org/"+roomidjson, {cache: "no-store"})
        .then(response => response.json())
        .then(data => {
            //console.log(data)
            // console.log('youtube_url: ' + data.youtube_url)
            //$("ytold").attr("href",data.youtube_url)

            // clear link element to avoid multiple appends
            document.getElementById("ytold").innerHTML = '';

            var a = document.createElement('a'); 
            var link = document.createTextNode(data.youtube_url);  
            a.appendChild(link); 
            a.title = "YouTube Link"; 
            a.href = data.youtube_url; 
            
            document.getElementById("ytold").appendChild(a);
        })
        .catch(error => {
            console.log("err: ", error);
        })
    }
    

}

</script></body></html>