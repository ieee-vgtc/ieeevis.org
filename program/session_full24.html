<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/2.1/auth0-spa-js.production.js"></script><script>
              const auth0_domain = "ieeevis.us.auth0.com";
              const auth0_client_id = "oF5BXUklWOjSjUeg5Tzai2DysHITXYhT";
            </script><script src="/static/2025/js/modules/auth0protect.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2025/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2025/js/data/persistor.js"></script><script src="/static/2025/js/data/api.js"></script><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2025/css/Zilla.css" rel="stylesheet"><link href="/static/2025/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2025/css/main.css"><link rel="stylesheet" href="/static/2025/css/fa_solid.css"><link rel="stylesheet" href="/static/2025/css/lazy_load.css"><link rel="stylesheet" href="/static/2025/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2025 - Session: VIS Full Papers: Ordering and Layout"><meta name="twitter:description" content="See the session and its presentations inside."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="See the session and its presentations inside."><meta name="title" property="og:title" content="Virtual IEEE VIS 2025 - Session: VIS Full Papers: Ordering and Layout"><meta property="og:type" content="website"><title>IEEE VIS 2025 Content: VIS Full Papers: Ordering and Layout</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style="display: none;"><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-8"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item" aria-current="page"><a href="events.html">All events</a></li><li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">Ordering and Layout</li></ol></nav><h1 class="session-title">VIS Full Papers: Ordering and Layout</h1><h3 class="session-url"><a href="https://ieeevis.org/year/2025/program/event_v-full.html" target="_blank"><span class="fas mr-1">&#xf57c;</span> https://ieeevis.org/year/2025/program/event_v-full.html</a></h3><h3 class="session-chair"><span class="fas mr-1">&#xf007;</span> Session chair: Marc Streit </h3><h3 class="session-room mt-4"> Room: Hall M2 </h3><h3 class="session-date"><span class="fas mr-1">&#xf017;</span><span class="format-date-span-full">2025-11-05T13:00:00+00:00 &ndash; 2025-11-05T14:15:00+00:00</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2025-11-05T13:00:00+00:00 &ndash; 2025-11-05T14:15:00+00:00</span><span class="current-time tztooltiptext"></span></span></h3></div><div class="col-md-1"></div><div class="col-md-3 session-links"><h5 class="session-info my-4"><a href="#list"><span class="fas mr-2">&#xf358;</span> Jump to event listing </a></h5><h5 class="session-info my-4"><a href="https://data.tech.ieeevis.org/storage/v1/object/public/ics/vis2025/full24.ics"><span class="fas mr-2">&#xf073;</span> Add to Calendar</a></h5></div></div><div class="row my-5 discord-public-link hide-auth-controls"><div class="col-md-8"><p><span class="fas mx-1">&#xf086;</span><a href="https://discord.com/channels/1422883912660549696/1430945427381030953" target="_blank">Discord link</a></p></div></div><div class="row my-5"><div class="col-md-8"><p>Recordings will be made available after the session.</p></div></div><hr><div class="row my-4"><div class="col-md-8"><h2 class="room_session_descriptor d-block py-2"><a name="list">Presentations in this session:</a></h2></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1431&#39;, &#39;session_id&#39;: &#39;full24&#39;, &#39;title&#39;: &#39;Mixture of Cluster-guided Experts for Retrieval-Augmented Label Placement&#39;, &#39;contributors&#39;: [&#39;Pingshun Zhang&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T13:00:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T13:00:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T13:12:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Pingshun Zhang&#39;, &#39;email&#39;: &#39;z2211973606@email.swu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Southwest University&#39;}, {&#39;name&#39;: &#39;Enyu Che&#39;, &#39;email&#39;: &#39;enyuche@gmail.com&#39;, &#39;affiliation&#39;: &#39;Southwest University&#39;}, {&#39;name&#39;: &#39;Yinan Chen&#39;, &#39;email&#39;: &#39;out1147205215@outlook.com&#39;, &#39;affiliation&#39;: &#39;COLLEGE OF COMPUTER AND INFORMATION SCIENCE, SOUTHWEST UNIVERSITY SCHOOL OF SOFTWAREC&#39;}, {&#39;name&#39;: &#39;Bingyao Huang&#39;, &#39;email&#39;: &#39;bihuang@cs.stonybrook.edu&#39;, &#39;affiliation&#39;: &#39;Southwest University&#39;}, {&#39;name&#39;: &#39;Haibin Ling&#39;, &#39;email&#39;: &#39;hling@cs.stonybrook.edu&#39;, &#39;affiliation&#39;: &#39;Stony Brook University&#39;}, {&#39;name&#39;: &#39;Jingwei Qu&#39;, &#39;email&#39;: &#39;qujingwei@swu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Southwest University&#39;}], &#39;abstract&#39;: &#39;Text labels are widely used to convey auxiliary information in visualization and graphic design. The substantial variability in the categories and structures of labeled objects leads to diverse label layouts. Recent single-model learning-based solutions in label placement struggle to capture fine-grained differences between these layouts, which in turn limits their performance. In addition, although human designers often consult previous works to gain design insights, existing label layouts typically serve merely as training data, limiting the extent to which embedded design knowledge can be exploited. To address these challenges, we propose a mixture of cluster-guided experts (MoCE) solution for label placement. In this design, multiple experts jointly refine layout features, with each expert responsible for a specific cluster of layouts. A cluster-based gating function assigns input samples to experts based on representation clustering. We implement this idea through the Label Placement Cluster-guided Experts (LPCE) model, in which a MoCE layer integrates multiple feed-forward networks (FFNs), with each expert composed of a pair of FFNs. Furthermore, we introduce a retrieval augmentation strategy into LPCE, which retrieves and encodes reference layouts for each input sample to enrich its representations. Extensive experiments demonstrate that LPCE achieves superior performance in label placement, both quantitatively and qualitatively, surpassing a range of state-of-the-art baselines. Our algorithm is available at https://github.com/PingshunZhang/LPCE.&#39;, &#39;uid&#39;: &#39;4becbe1b-2bde-4b12-adfd-e45a36678884&#39;, &#39;keywords&#39;: [&#39;Label placement&#39;, &#39;Mixture of experts&#39;, &#39;Retrieval augmentation&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://jingweiqu.github.io/project/LPCE&#39;} <h3 class="session-list-title"><a href="paper_4becbe1b-2bde-4b12-adfd-e45a36678884.html"> Mixture of Cluster-guided Experts for Retrieval-Augmented Label Placement <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Pingshun Zhang, Enyu Che, Yinan Chen, Bingyao Huang, Haibin Ling, Jingwei Qu </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Pingshun Zhang </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T13:00:00.000Z &ndash; 2025-11-05T13:12:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1718&#39;, &#39;session_id&#39;: &#39;full24&#39;, &#39;title&#39;: &#39;SynAnno: Interactive Guided Proofreading of Synaptic Annotations&#39;, &#39;contributors&#39;: [&#39;Leander Lauenburg&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T13:12:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T13:12:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T13:24:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Leander Lauenburg&#39;, &#39;email&#39;: &#39;leander.lauenburg@gmail.com&#39;, &#39;affiliation&#39;: &#39;Technical University of Munich&#39;}, {&#39;name&#39;: &#39;Jakob Troidl&#39;, &#39;email&#39;: &#39;jakob.troidl@googlemail.com&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Adam Gohain&#39;, &#39;email&#39;: &#39;gohaina@bc.edu&#39;, &#39;affiliation&#39;: &#39;Boston College&#39;}, {&#39;name&#39;: &#39;Zudi Lin&#39;, &#39;email&#39;: &#39;linzudi@gmail.com&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Hanspeter Pfister&#39;, &#39;email&#39;: &#39;pfister@seas.harvard.edu&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Donglai Wei&#39;, &#39;email&#39;: &#39;donglai.wei@bc.edu&#39;, &#39;affiliation&#39;: &#39;Boston College&#39;}], &#39;abstract&#39;: &#39;Connectomics, a subfield of neuroscience, aims to map and analyze synapse-level wiring diagrams of the nervous system. While recent advances in deep learning have accelerated automated neuron and synapse segmentation, reconstructing accurate connectomes still demands extensive human proofreading to correct segmentation errors.\nWe present SynAnno, an interactive tool designed to streamline and enhance the proofreading of synaptic annotations in large-scale connectomics datasets. SynAnno integrates into existing neuroscience workflows by enabling guided, neuron-centric proofreading. To address the challenges posed by the complex spatial branching of neurons, it introduces a structured workflow with an optimized traversal path and a 3D mini-map for tracking progress. In addition, SynAnno incorporates fine-tuned machine learning models to assist with error detection and correction, reducing the manual burden and increasing proofreading efficiency.\nWe evaluate SynAnno through a user and case study involving seven neuroscience experts. Results show that SynAnno significantly accelerates synapse proofreading while reducing cognitive load and annotation errors through structured guidance and visualization support. The source code and interactive demo are available at: https://github.com/PytorchConnectomics/SynAnno.&#39;, &#39;uid&#39;: &#39;b5d2c402-def7-4b9d-a6df-ac4ad7572111&#39;, &#39;keywords&#39;: [&#39;Connectomics&#39;, &#39;Synaptic Annotations&#39;, &#39;Neuron-Centric&#39;, &#39;Proofreading Workflow&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://github.com/PytorchConnectomics/SynAnno&#39;} <h3 class="session-list-title"><a href="paper_b5d2c402-def7-4b9d-a6df-ac4ad7572111.html"> SynAnno: Interactive Guided Proofreading of Synaptic Annotations <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Leander Lauenburg, Jakob Troidl, Adam Gohain, Zudi Lin, Hanspeter Pfister, Donglai Wei </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Leander Lauenburg </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T13:12:00.000Z &ndash; 2025-11-05T13:24:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1781&#39;, &#39;session_id&#39;: &#39;full24&#39;, &#39;title&#39;: &#39;DKMap: Interactive Exploration of Vision-Language Alignment in Multimodal Embeddings via Dynamic Kernel Enhanced Projection&#39;, &#39;contributors&#39;: [&#39;Yilin Ye&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T13:24:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T13:24:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T13:36:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Yilin Ye&#39;, &#39;email&#39;: &#39;yyebd@connect.ust.hk&#39;, &#39;affiliation&#39;: &#39;The Hong Kong University of Science and Technology (Guangzhou)&#39;}, {&#39;name&#39;: &#39;Chenxi Ruan&#39;, &#39;email&#39;: &#39;chenxiruan64@gmail.com&#39;, &#39;affiliation&#39;: &#39;South China University of Technology&#39;}, {&#39;name&#39;: &#39;Yu Zhang&#39;, &#39;email&#39;: &#39;yuzhang94@outlook.com&#39;, &#39;affiliation&#39;: &#39;University of Oxford&#39;}, {&#39;name&#39;: &#39;Zikun Deng&#39;, &#39;email&#39;: &#39;zkdeng@scut.edu.cn&#39;, &#39;affiliation&#39;: &#39;South China University of Technology&#39;}, {&#39;name&#39;: &#39;Wei Zeng&#39;, &#39;email&#39;: &#39;zengwei81@gmail.com&#39;, &#39;affiliation&#39;: &#39;The Hong Kong University of Science and Technology (Guangzhou)&#39;}], &#39;abstract&#39;: &#39;Examining vision-language alignment in multimodal embeddings is crucial for various tasks, such as evaluating generative models and filtering pretraining data. The intricate nature of high-dimensional features necessitates dimensionality reduction (DR) methods to explore alignment of multimodal embeddings. However, existing DR methods fail to account for cross-modal alignment metrics, resulting in severe occlusion of points with divergent metrics clustered together, inaccurate contour maps from over-aggregation, and insufficient support for multi-scale exploration. To address these problems, this paper introduces DKMap, a novel DR visualization technique for interactive exploration of multimodal embeddings through Dynamic Kernel enhanced projection. First, rather than performing dimensionality reduction and contour estimation sequentially, we introduce a kernel regression supervised t-SNE that directly integrates post-projection contour mapping into the projection learning process, ensuring cross-modal alignment mapping accuracy. Second, to enable multi-scale exploration with dynamic zooming and progressively enhanced local detail, we integrate validation-constrained α refinement of a generalized t-kernel with quad-tree-based multi-resolution technique, ensuring reliable kernel parameter tuning without overfitting. DKMap is implemented as a multi-platform visualization tool, featuring a web-based system for interactive exploration and a Python package for computational notebook analysis. Quantitative comparisons with baseline DR techniques demonstrate DKMap’s superiority in accurately mapping cross-modal alignment metrics. We further demonstrate generalizability and scalability of DKMap with three usage scenarios, including visualizing million-scale text-to-image corpus, comparatively evaluating generative models, and exploring a billion-scale pretraining dataset.&#39;, &#39;uid&#39;: &#39;3d649242-7596-4300-84fe-793b6a69b69c&#39;, &#39;keywords&#39;: [&#39;Kernel Regression&#39;, &#39;Vision-language Alignment&#39;, &#39;Multimodal Embeddings&#39;, &#39;Interactive Exploration&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://github.com/HKUST-CIVAL/DKMap&#39;} <h3 class="session-list-title"><a href="paper_3d649242-7596-4300-84fe-793b6a69b69c.html"> DKMap: Interactive Exploration of Vision-Language Alignment in Multimodal Embeddings via Dynamic Kernel Enhanced Projection <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Yilin Ye, Chenxi Ruan, Yu Zhang, Zikun Deng, Wei Zeng </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Yilin Ye </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T13:24:00.000Z &ndash; 2025-11-05T13:36:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-09-0854.R1&#39;, &#39;session_id&#39;: &#39;full24&#39;, &#39;title&#39;: &#39;Fast and Readable Layered Network Visualizations Using Large Neighborhood Search&#39;, &#39;contributors&#39;: [&#39;Connor Wilson&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T13:36:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T13:36:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T13:48:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Connor Wilson&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Tarik Crnovrsanin&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Eduardo Puerta&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Cody Dunne&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Layered network visualizations assign each node to one of several parallel axes. They can convey sequence or flow data, hierarchies, or multiple data classes, but edge crossings and long edges often impair readability. Layout algorithms can reduce edge crossings and shorten edges using quick heuristics or optimal methods that prioritize human readability over computation speed. This work uses an optimization metaheuristic to provide the best of both worlds: high-quality layouts within a predetermined execution time. Our adaptation of the large neighborhood search (LNS) metaheuristic repeatedly selects fixed-sized subgraphs to lay out optimally. We conducted a computational evaluation using 450 synthetic networks to compare five ways of selecting candidate nodes, four ways of selecting their neighboring subgraph, and three criteria for determining subgraph size. LNS generally halved the number of crossings versus the barycentric heuristic while maintaining a reasonable runtime. Our best approach randomly selected candidate nodes, used degree centrality to pick cluster-like neighborhoods, and chose smaller neighborhoods that could be optimally laid out in 0.6 or 1.2 seconds (versus 6 seconds). In a case study visualizing 13 control flow graphs, most with over 1000 nodes, we show that our method can be employed to create visualizations with fewer crossings than Tabu Search, another metaheuristic, and vastly outperforms an ILP solver when runtime is bounded.&#39;, &#39;uid&#39;: &#39;06d5d55a-bd4b-4c6f-9f01-60b54e657562&#39;, &#39;keywords&#39;: [&#39;Layout&#39;, &#39;Metaheuristics&#39;, &#39;Visualization&#39;, &#39;Runtime&#39;, &#39;Optimization models&#39;, &#39;Search problems&#39;, &#39;Reverse engineering&#39;, &#39;Minimization&#39;, &#39;Heuristic algorithms&#39;, &#39;Graph drawing&#39;], &#39;preprint_link&#39;: &#39;https://osf.io/preprints/osf/fytk7&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2025.3537898&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_06d5d55a-bd4b-4c6f-9f01-60b54e657562.html"> Fast and Readable Layered Network Visualizations Using Large Neighborhood Search <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Connor Wilson, Tarik Crnovrsanin, Eduardo Puerta, Cody Dunne </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Connor Wilson </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T13:36:00.000Z &ndash; 2025-11-05T13:48:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-02-0150&#39;, &#39;session_id&#39;: &#39;full24&#39;, &#39;title&#39;: &#39;Versatile Ordering Network: An Attention-based Neural Network for Ordering Across Scales and Quality Metrics&#39;, &#39;contributors&#39;: [&#39;Zehua Yu&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T13:48:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T13:48:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T14:00:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Zehua Yu&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Weihan Zhang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Sihan Pan&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Jun Tao&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Ordering has been extensively studied in many visualization applications, such as axis and matrix reordering, for the simple reason that the order will greatly impact the perceived pattern of data. Many quality metrics concerning data pattern, perception, and aesthetics are proposed, and respective optimization algorithms are developed. However, the optimization problems related to ordering are often difficult to solve (e.g., TSP is NP-complete), and developing specialized optimization algorithms is costly. In this paper, we propose Versatile Ordering Network (VON), which automatically learns the strategy to order given a quality metric. VON uses the quality metric to evaluate its solutions, and leverages reinforcement learning with a greedy rollout baseline to improve itself. This keeps the metric transparent and allows VON to optimize over different metrics. Additionally, VON uses the attention mechanism to collect information across scales and reposition the data points with respect to the current context. This allows VONs to deal with data points following different distributions. We examine the effectiveness of VON under different usage scenarios and metrics. The results demonstrate that VON can produce comparable results to specialized solvers.&#39;, &#39;uid&#39;: &#39;13eab0df-a9ad-4614-bc89-4a645ab9438a&#39;, &#39;keywords&#39;: [&#39;Measurement&#39;, &#39;Visualization&#39;, &#39;Attention mechanisms&#39;, &#39;Neural networks&#39;, &#39;Layout&#39;, &#39;Data visualization&#39;, &#39;Reinforcement learning&#39;, &#39;Optimization&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2412.12759&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2024.3520208&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_13eab0df-a9ad-4614-bc89-4a645ab9438a.html"> Versatile Ordering Network: An Attention-based Neural Network for Ordering Across Scales and Quality Metrics <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Zehua Yu, Weihan Zhang, Sihan Pan, Jun Tao </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Zehua Yu </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T13:48:00.000Z &ndash; 2025-11-05T14:00:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-06-0415/TVCG3528197&#39;, &#39;session_id&#39;: &#39;full24&#39;, &#39;title&#39;: &#39;ZigzagNetVis: Suggesting temporal resolutions for graph visualization using zigzag persistence&#39;, &#39;contributors&#39;: [&#39;Claudio Linhares&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T14:00:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T14:00:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T14:12:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Raphael Tinarrage&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Jean R. Ponciano&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Claudio D. G. Linhares&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Agma J. M. Traina&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Jorge Poco&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Temporal graphs are commonly used to represent complex systems and track the evolution of their constituents over time. Visualizing these graphs is crucial as it allows one to quickly identify anomalies, trends, patterns, and other properties that facilitate better decision-making. In this context, selecting an appropriate temporal resolution is essential for constructing and visually analyzing the layout. The choice of resolution is particularly important, especially when dealing with temporally sparse graphs. In such cases, changing the temporal resolution by grouping events (i.e., edges) from consecutive timestamps — a technique known as timeslicing — can aid in the analysis and reveal patterns that might not be discernible otherwise. However, selecting an appropriate temporal resolution is a challenging task. In this paper, we propose ZigzagNetVis, a methodology that suggests temporal resolutions potentially relevant for analyzing a given graph, i.e., resolutions that lead to substantial topological changes in the graph structure. ZigzagNetVis achieves this by leveraging zigzag persistent homology, a well-established technique from Topological Data Analysis (TDA). To improve visual graph analysis, ZigzagNetVis incorporates the colored barcode, a novel timeline-based visualization inspired by persistence barcodes commonly used in TDA. We also contribute with a web-based system prototype that implements suggestion methodology and visualization tools. Finally, we demonstrate the usefulness and effectiveness of ZigzagNetVis through a usage scenario, a user study with 27 participants, and a detailed quantitative evaluation.&#39;, &#39;uid&#39;: &#39;b56f8c0d-ce95-474d-9c61-f650be7278d5&#39;, &#39;keywords&#39;: [&#39;Visualization&#39;, &#39;Filtration&#39;, &#39;Layout&#39;, &#39;Prototypes&#39;, &#39;Market research&#39;, &#39;Data analysis&#39;, &#39;Computer science&#39;, &#39;Complex systems&#39;, &#39;Surveys&#39;, &#39;Standards&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2304.03828&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2025.3528197&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: &#39;particularly substantial supplemental material&#39;, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_b56f8c0d-ce95-474d-9c61-f650be7278d5.html"> ZigzagNetVis: Suggesting temporal resolutions for graph visualization using zigzag persistence <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Raphael Tinarrage, Jean R. Ponciano, Claudio D. G. Linhares, Agma J. M. Traina, Jorge Poco </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Claudio Linhares </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T14:00:00.000Z &ndash; 2025-11-05T14:12:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row my-5"><div class="col-md-8"><p>You may want to also jump to the parent event to see related presentations: <a href="event_v-full.html">VIS Full Papers</a></p></div></div><script src="/static/2025/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script><script>

$(document).ready(function() {
    setInterval(updateSessionStatus, 30 * 1000);
    updateSessionStatus(true)
})

function updateSessionStatus(onFirstLoad) {
    // We need to write the session timings into the page to calculate current/next session.
    // See blueprint_2025.py
    startTime = '2025-11-05T13:00:00+00:00'
    endTime = '2025-11-05T14:15:00+00:00'

    // We take a 8 minute grace period to the start of a session
    const sessionStart = moment(startTime).tz(current_timezone).subtract(8, 'minutes');
    const sessionEnd = moment(endTime).tz(current_timezone);

    const sessionIsCurrent = moment().tz(current_timezone).isBetween(sessionStart, sessionEnd);
    const sessionIsFuture = moment().tz(current_timezone).isBefore(sessionStart);
    const sessionIsPast = moment().tz(current_timezone).isAfter(sessionStart);

    const classesToHide = ['.future_session_alert', '.current_session_alert', '.past_session_alert', '.room_session_stream']
    classesToHide.forEach((c) => { $(c).hide();});
    if (sessionIsCurrent) {
        $('.current_session_alert').show();
    } else if (sessionIsFuture) {
        $('.future_session_alert').show();
    } else {
        // Session is in the future
        $('#zoom_alert').hide();
        $('.past_session_alert').show();
        $('.room_session_stream').show();
    }

    // Update youtube link for older sessions
    // EDIT - We don't need this when the conference isn't live
    if(sessionIsPast){
        const roomidjson = "m2-"+moment(startTime).format('ddd').toLowerCase()+".json"
        // console.log("this session was in:" , roomidjson)

        return fetch("https://virtual-data.ieeevis.org/"+roomidjson, {cache: "no-store"})
        .then(response => response.json())
        .then(data => {
            //console.log(data)
            // console.log('youtube_url: ' + data.youtube_url)
            //$("ytold").attr("href",data.youtube_url)

            // clear link element to avoid multiple appends
            document.getElementById("ytold").innerHTML = '';

            var a = document.createElement('a'); 
            var link = document.createTextNode(data.youtube_url);  
            a.appendChild(link); 
            a.title = "YouTube Link"; 
            a.href = data.youtube_url; 
            
            document.getElementById("ytold").appendChild(a);
        })
        .catch(error => {
            console.log("err: ", error);
        })
    }
    

}

</script></body></html>