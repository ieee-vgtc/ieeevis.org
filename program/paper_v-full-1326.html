<!DOCTYPE html><html lang="en"> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2024/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/1.12/auth0-spa-js.production.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2024/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2024/js/data/persistor.js"></script><script src="/static/2024/js/data/api.js"></script><link rel="shortcut icon" href="/static/2024/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2024/css/Zilla.css" rel="stylesheet"><link href="/static/2024/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2024/css/main.css"><link rel="stylesheet" href="/static/2024/css/fa_solid.css"><link rel="stylesheet" href="/static/2024/css/lazy_load.css"><link rel="stylesheet" href="/static/2024/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2024 - Paper: LLM Comparator: Interactive Analysis of Side-by-Side Evaluation of Large Language Models"><meta name="twitter:description" content="Evaluating large language models (LLMs) presents unique challenges. While automatic side-by-side evaluation, also known as LLM-as-a-judge, has become a promising solution, model developers and researchers face difficulties with scalability and interpretability when analyzing these evaluation outcomes. To address these challenges, we introduce LLM Comparator, a new visual analytics tool designed for side-by-side evaluations of LLMs. This tool provides analytical workflows that help users understand when and why one LLM outperforms or underperforms another, and how their responses differ. Through close collaboration with practitioners developing LLMs at Google, we have iteratively designed, developed, and refined the tool. Qualitative feedback from these users highlights that the tool facilitates in-depth analysis of individual examples while enabling users to visually overview and flexibly slice data. This empowers users to identify undesirable patterns, formulate hypotheses about model behavior, and gain insights for model improvement. LLM Comparator has been integrated into Google's LLM evaluation platforms and open-sourced."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="Evaluating large language models (LLMs) presents unique challenges. While automatic side-by-side evaluation, also known as LLM-as-a-judge, has become a promising solution, model developers and researchers face difficulties with scalability and interpretability when analyzing these evaluation outcomes. To address these challenges, we introduce LLM Comparator, a new visual analytics tool designed for side-by-side evaluations of LLMs. This tool provides analytical workflows that help users understand when and why one LLM outperforms or underperforms another, and how their responses differ. Through close collaboration with practitioners developing LLMs at Google, we have iteratively designed, developed, and refined the tool. Qualitative feedback from these users highlights that the tool facilitates in-depth analysis of individual examples while enabling users to visually overview and flexibly slice data. This empowers users to identify undesirable patterns, formulate hypotheses about model behavior, and gain insights for model improvement. LLM Comparator has been integrated into Google's LLM evaluation platforms and open-sourced."><meta name="title" property="og:title" content="Virtual IEEE VIS 2024 - Paper: LLM Comparator: Interactive Analysis of Side-by-Side Evaluation of Large Language Models"><meta property="og:type" content="website"><title>IEEE VIS 2024 Content: LLM Comparator: Interactive Analysis of Side-by-Side Evaluation of Large Language Models</title></head> <body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style> <div class="container mb-5"> <div class="tabs"> </div> <div class="content"> <div class="row mt-3"> <div class="col-md-12"> <nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"> <ol class="breadcrumb"> <li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a> </li> <li class="breadcrumb-item"><a href="session_full14.html">Look, Learn, Language Models</a> </li> <li class="breadcrumb-item active text-truncate" aria-current="page">LLM Comparator: Interactive Analysis of Side-by-Side Evaluation of Large Language Models</li> </ol> </nav> <h1 class="paper-title">LLM Comparator: Interactive Analysis of Side-by-Side Evaluation of Large Language Models</h1> <div class="checkbox-bookmark fas" style="font-size: 24pt;position: absolute; top:10px; right:20px;" data-tippy-content="(un-)bookmark this paper"> &#xf02e; </div> <h4 class="paper-authors pb-2 mt-2"> <span class="fas mr-1">&#xf183;</span> <a href="mailto:minsuk.kahng@gmail.com">Minsuk Kahng</a> - Google, Atlanta, United States </h4> <h4 class="paper-authors pb-2 mt-2"> <span class="fas mr-1">&#xf183;</span> Ian Tenney - Google Research, Seattle, United States </h4> <h4 class="paper-authors pb-2 mt-2"> <span class="fas mr-1">&#xf183;</span> Mahima Pushkarna - Google Research, Cambridge, United States </h4> <h4 class="paper-authors pb-2 mt-2"> <span class="fas mr-1">&#xf183;</span> Michael Xieyang Liu - Google Research, Pittsburgh, United States </h4> <h4 class="paper-authors pb-2 mt-2"> <span class="fas mr-1">&#xf183;</span> James Wexler - Google Research, Cambridge, United States </h4> <h4 class="paper-authors pb-2 mt-2"> <span class="fas mr-1">&#xf183;</span> Emily Reif - Google, Cambridge, United States </h4> <h4 class="paper-authors pb-2 mt-2"> <span class="fas mr-1">&#xf183;</span> Krystal Kallarackal - Google Research, Mountain View, United States </h4> <h4 class="paper-authors pb-2 mt-2"> <span class="fas mr-1">&#xf183;</span> Minsuk Chang - Google Research, Seattle, United States </h4> <h4 class="paper-authors pb-2 mt-2"> <span class="fas mr-1">&#xf183;</span> Michael Terry - Google, Cambridge, United States </h4> <h4 class="paper-authors pb-2 mt-2"> <span class="fas mr-1">&#xf183;</span> Lucas Dixon - Google, Paris, France </h4> <h3 class="session-room mt-4"> <span class="fas mr-1">&#xf108;</span> <a href="room_indianbird.html"> Room: Indian/Bird Key </a> </h3> <h5 class="paper-presentation pb-2"> <span class="format-date">2024-10-18T12:42:00Z</span> <span alt="Change timezone on schedule page" class="timezone tztooltip"> <strong>GMT<span class="selectedTimezone">-0600</span></strong> <span class="tztooltiptext">Change your timezone on the schedule page</span> </span> <br> <span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"> <span class="relative-time">2024-10-18T12:42:00Z</span> <span class="current-time tztooltiptext"></span> </span> </h5> </div> </div> <div class="row my-3"> <div class="col-md-8"> <figure class="figure"> <figcaption class="figure-caption" id="figure-caption">LLM Comparator is a visual analytics tool consisting of multiple views: an interactive table which displays individual prompts and model responses, and a visualization summary which comprises multiple panels, including score distribution, metrics by prompt category, rationale clusters, n-grams, and custom functions.</figcaption> </figure> </div> </div> <div class="row my-3"> <div class="col-md-8"> </div> </div> <div class="row my-3"> <div class="col-md-8"> <h5 class="paper-details-heading">Abstract</h5> <p>Evaluating large language models (LLMs) presents unique challenges. While automatic side-by-side evaluation, also known as LLM-as-a-judge, has become a promising solution, model developers and researchers face difficulties with scalability and interpretability when analyzing these evaluation outcomes. To address these challenges, we introduce LLM Comparator, a new visual analytics tool designed for side-by-side evaluations of LLMs. This tool provides analytical workflows that help users understand when and why one LLM outperforms or underperforms another, and how their responses differ. Through close collaboration with practitioners developing LLMs at Google, we have iteratively designed, developed, and refined the tool. Qualitative feedback from these users highlights that the tool facilitates in-depth analysis of individual examples while enabling users to visually overview and flexibly slice data. This empowers users to identify undesirable patterns, formulate hypotheses about model behavior, and gain insights for model improvement. LLM Comparator has been integrated into Google&#39;s LLM evaluation platforms and open-sourced.</p> </div> </div> <script lang="js">
      const paperID = "v-full-1326"
      $(document).ready(() => {
        tippy('[data-tippy-content]');

        const allBookmarks =
          d3.selectAll('.checkbox-bookmark')
            .on("click", function () {
              const newValue = !d3.select(this).classed('selected');
              API.markSet(API.storeIDs.bookmarked, paperID, newValue);
              d3.select(this).classed('selected', newValue);
            })
        API.markGet(API.storeIDs.bookmarked, paperID).then(is_bookmarked => {
          is_bookmarked = !!is_bookmarked;
          allBookmarks.classed('selected', is_bookmarked);
        })
        API.markSet(API.storeIDs.visited, paperID, true);

      })

    </script> <script src="/static/2024/js/views/timezone.js"></script> </div> </div> <script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" â€“ ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script> </body> </html>