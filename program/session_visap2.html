<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/2.1/auth0-spa-js.production.js"></script><script>
              const auth0_domain = "ieeevis.us.auth0.com";
              const auth0_client_id = "oF5BXUklWOjSjUeg5Tzai2DysHITXYhT";
            </script><script src="/static/2025/js/modules/auth0protect.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2025/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2025/js/data/persistor.js"></script><script src="/static/2025/js/data/api.js"></script><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2025/css/Zilla.css" rel="stylesheet"><link href="/static/2025/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2025/css/main.css"><link rel="stylesheet" href="/static/2025/css/fa_solid.css"><link rel="stylesheet" href="/static/2025/css/lazy_load.css"><link rel="stylesheet" href="/static/2025/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2025 - Session: VIS Arts Program: VISAP Papers"><meta name="twitter:description" content="See the session and its presentations inside."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="See the session and its presentations inside."><meta name="title" property="og:title" content="Virtual IEEE VIS 2025 - Session: VIS Arts Program: VISAP Papers"><meta property="og:type" content="website"><title>IEEE VIS 2025 Content: VIS Arts Program: VISAP Papers</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style="display: none;"><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-8"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item" aria-current="page"><a href="events.html">All events</a></li><li class="breadcrumb-item"><a href="event_a-visap.html">VIS Arts Program</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">VISAP Papers</li></ol></nav><h1 class="session-title">VIS Arts Program: VISAP Papers</h1><h3 class="session-url"><a href="https://ieeevis.org/year/2025/program/event_a-visap.html" target="_blank"><span class="fas mr-1">&#xf57c;</span> https://ieeevis.org/year/2025/program/event_a-visap.html</a></h3><h3 class="session-chair"><span class="fas mr-1">&#xf007;</span> Session chair: Dario Rodighiero </h3><h3 class="session-room mt-4"> Room: Room 1.14 </h3><h3 class="session-date"><span class="fas mr-1">&#xf017;</span><span class="format-date-span-full">2025-11-06T08:30:00+00:00 &ndash; 2025-11-06T09:45:00+00:00</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2025-11-06T08:30:00+00:00 &ndash; 2025-11-06T09:45:00+00:00</span><span class="current-time tztooltiptext"></span></span></h3></div><div class="col-md-1"></div><div class="col-md-3 session-links"><h5 class="session-info my-4"><a href="#list"><span class="fas mr-2">&#xf358;</span> Jump to event listing </a></h5><h5 class="session-info my-4"><a href="https://data.tech.ieeevis.org/storage/v1/object/public/ics/vis2025/visap2.ics"><span class="fas mr-2">&#xf073;</span> Add to Calendar</a></h5></div></div><div class="row my-5 discord-public-link hide-auth-controls"><div class="col-md-8"><p><span class="fas mx-1">&#xf086;</span><a href="https://discord.com/channels/1422883912660549696/1430945285051519147" target="_blank">Discord link</a></p></div></div><div class="row my-5"><div class="col-md-8"><p>Recordings will be made available after the session.</p></div></div><hr><div class="row my-4"><div class="col-md-8"><h2 class="room_session_descriptor d-block py-2"><a name="list">Presentations in this session:</a></h2></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;a-visap-1036&#39;, &#39;session_id&#39;: &#39;visap2&#39;, &#39;title&#39;: &#39;Psychomare: A Psychoanalytic and XR-Based Artistic Exploration into Nightmare Visualization&#39;, &#39;contributors&#39;: [&#39;Jiayang Huang&#39;], &#39;paper_type&#39;: &#39;VISAP&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T08:30:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T08:30:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T08:42:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Jiayang Huang&#39;, &#39;email&#39;: &#39;jarryyyhuang@gmail.com&#39;, &#39;affiliation&#39;: &#39;Hong Kong University of Science and Technology (Guangzhou)&#39;}, {&#39;name&#39;: &#39;Joshua Nijiati Alimujiang&#39;, &#39;email&#39;: &#39;anijiati587@connect.hkust-gz.edu.cn&#39;, &#39;affiliation&#39;: &#39;Hong Kong University of Science and Technology (Guangzhou)&#39;}, {&#39;name&#39;: &#39;Kang Zhang&#39;, &#39;email&#39;: &#39;kzhangcma@hkust-gz.edu.cn&#39;, &#39;affiliation&#39;: &#39;Hong Kong University of Science and Technology (Guangzhou)&#39;}, {&#39;name&#39;: &#39;David Yip&#39;, &#39;email&#39;: &#39;daveyip@hkust-gz.edu.cn&#39;, &#39;affiliation&#39;: &#39;The Hong Kong University of Science and Technology (Guangzhou)&#39;}], &#39;abstract&#39;: &#39;Psychomare is an artistic research project that explores the visualization of nightmares through a psychoanalytic and XR-based performance methodology. By treating dreams as symbolic data and nightmares as distortions of subjective recognition, the project translates psychological fear into tangible visual forms. Utilizing AI-driven imagery, embodied dance performance, and virtual production technologies, Psychomare creates an immersive dreamscape where the dancer confronts surreal nightmare entities derived from personal and collective dream memories. Drawing on Lacanian theory, the work proposes that nightmares emerge from a misrecognition of the self—a mirrored distortion of unconscious desires and fears projected onto dream imagery. This symbolic misrecognition becomes the conceptual core of the project, guiding its aesthetic and choreographic strategies. Feedback from the dancer, audience, and a psychoanalyst reveals strong emotional resonance and aesthetic depth, suggesting that the visualization of nightmares can foster self-reflection, emotional confrontation, and collective empathy. This project offers a new model for integrating immersive art, psychoanalytic theory, and technological mediation as a path of collective care.&#39;, &#39;uid&#39;: &#39;efe038da-ab5b-4531-9235-89a36836d893&#39;, &#39;keywords&#39;: [&#39;Nightmares&#39;, &#39;XR Performance&#39;, &#39;Psychoanalytic Art Practice&#39;, &#39;Dream Visualization&#39;, &#39;Collective Emotion.&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_efe038da-ab5b-4531-9235-89a36836d893.html"> Psychomare: A Psychoanalytic and XR-Based Artistic Exploration into Nightmare Visualization <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Jiayang Huang, Joshua Nijiati Alimujiang, Kang Zhang, David Yip </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Jiayang Huang </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T08:30:00.000Z &ndash; 2025-11-06T08:42:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;a-visap-1076&#39;, &#39;session_id&#39;: &#39;visap2&#39;, &#39;title&#39;: &#39;You Only Have Seven Seconds: From Intimate Whispers to Shared Worlds in Participatory Data-Driven Cinematic Art&#39;, &#39;contributors&#39;: [&#39;Weidi Zhang&#39;], &#39;paper_type&#39;: &#39;VISAP&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T08:42:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T08:42:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T08:54:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;weidi zhang&#39;, &#39;email&#39;: &#39;zhangweidilydia@gmail.com&#39;, &#39;affiliation&#39;: &#39;university of california, Santa Barbara&#39;}, {&#39;name&#39;: &#39;Lijiaozi Cheng&#39;, &#39;email&#39;: &#39;lijiaozi.cheng@gmail.com&#39;, &#39;affiliation&#39;: &#39;The University of Sheffield&#39;}, {&#39;name&#39;: &#39;Paul Schmidt&#39;, &#39;email&#39;: &#39;paulschmidt786@gmail.com&#39;, &#39;affiliation&#39;: &#39;Zurich University of the Arts&#39;}, {&#39;name&#39;: &#39;Jieliang Luo&#39;, &#39;email&#39;: &#39;rodgerljl@msn.com&#39;, &#39;affiliation&#39;: &#39;Minus AI&#39;}], &#39;abstract&#39;: &#39;You Only Have Seven Seconds is a cinematic artistic visualization derived from an interactive AI art installation (ReCollection) that explores how machine intelligence can reassemble collective human memory through language input. Motivated by the artist’s personal response to her grandmother’s cognitive decline and informed by current research in Critical Dementia Studies that advocates for reimagining—rather than repairing—memory, the project collects and curates whispered, seven-second recollections and machine-generated image data from installation participants. These selected datasets are transformed into a generative visualization presented as\na cinematic art using custom-designed AI systems and experimental visualization strategies. This paper introduces the conceptual foundations and technical development of this project, with emphasis on data collection, experimental visualization, narrative construction, sound design, and intelligent system integration. Through the design of artificial memory, You Only Have Seven Seconds constructs a dynamic archive of shared, ephemeral recollections for storytelling.&#39;, &#39;uid&#39;: &#39;10595e17-8ad8-4932-b661-e5d6764c8082&#39;, &#39;keywords&#39;: [&#39;Generative Design&#39;, &#39;Experimental Data Visualization&#39;, &#39;Computer Animation&#39;, &#39;AI Art.&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_10595e17-8ad8-4932-b661-e5d6764c8082.html"> You Only Have Seven Seconds: From Intimate Whispers to Shared Worlds in Participatory Data-Driven Cinematic Art <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: weidi zhang, Lijiaozi Cheng, Paul Schmidt, Jieliang Luo </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Weidi Zhang </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T08:42:00.000Z &ndash; 2025-11-06T08:54:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;a-visap-1049&#39;, &#39;session_id&#39;: &#39;visap2&#39;, &#39;title&#39;: &#39;Tides of Memory: Digital Echoes of Netizen Remembrance&#39;, &#39;contributors&#39;: [&#39;Lingyu Peng&#39;], &#39;paper_type&#39;: &#39;VISAP&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T08:54:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T08:54:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T09:06:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Lingyu Peng&#39;, &#39;email&#39;: &#39;lingyupeng6@163.com&#39;, &#39;affiliation&#39;: &#39;Harbin Institute of Technology&#39;}, {&#39;name&#39;: &#39;Chang Ge&#39;, &#39;email&#39;: &#39;2634641504@qq.com&#39;, &#39;affiliation&#39;: &#39;Harbin institute of technology (Shenzhen)&#39;}, {&#39;name&#39;: &#39;Liying Long&#39;, &#39;email&#39;: &#39;582546102@qq.com&#39;, &#39;affiliation&#39;: &#39;Harbin Institute of Technology, Shenzhen&#39;}, {&#39;name&#39;: &#39;xin Li&#39;, &#39;email&#39;: &#39;li1179327296@163.com&#39;, &#39;affiliation&#39;: &#39;Future Design School&#39;}, {&#39;name&#39;: &#39;Xiao Hu&#39;, &#39;email&#39;: &#39;1140084087@qq.com&#39;, &#39;affiliation&#39;: &#39;Harbin Institute of Technology&#39;}, {&#39;name&#39;: &#39;Pengda Lu&#39;, &#39;email&#39;: &#39;867103556@qq.com&#39;, &#39;affiliation&#39;: &#39;Harbin Institute of Technology&#39;}, {&#39;name&#39;: &#39;Qingchuan Li&#39;, &#39;email&#39;: &#39;liqingchuan@hit.edu.cn&#39;, &#39;affiliation&#39;: &#39;Harbin Institute of Technology&#39;}, {&#39;name&#39;: &#39;Jiangyue Wu&#39;, &#39;email&#39;: &#39;wu.jiangyue@outlook.com&#39;, &#39;affiliation&#39;: &#39;Harbin Institute of Technology&#39;}], &#39;abstract&#39;: &#39;This artwork presents an interdisciplinary interaction installation that visualizes collective online mourning behavior in China. By focusing on commemorative content posted on Sina Weibo following the deaths of seven prominent Chinese authors, the artwork employs data scraping, natural language processing, and 3D modeling to transform fragmented textual expressions into immersive digital monuments. Through the analysis of word frequencies, topic models, and user engagement metrics, the system constructs a semantic-visual landscape that reflects both authorial legacies and collective memory. This research contributes to the fields of digital humanities, visualization design, and digital memorial architecture by proposing a novel approach for preserving and reactivating collective memory in the digital age.&#39;, &#39;uid&#39;: &#39;fbac208d-6896-420b-8276-ab913bb0e617&#39;, &#39;keywords&#39;: [&#39;Online mourning&#39;, &#39;Collective memory&#39;, &#39;Artistic Data Visualization&#39;, &#39;Text visualization&#39;, &#39;Interaction installation&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_fbac208d-6896-420b-8276-ab913bb0e617.html"> Tides of Memory: Digital Echoes of Netizen Remembrance <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Lingyu Peng, Chang Ge, Liying Long, xin Li, Xiao Hu, Pengda Lu, Qingchuan Li, Jiangyue Wu </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Lingyu Peng </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T08:54:00.000Z &ndash; 2025-11-06T09:06:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;a-visap-1116&#39;, &#39;session_id&#39;: &#39;visap2&#39;, &#39;title&#39;: &#39;Simulacra Naturae: Generative Ecosystem driven by Agent-Based Simulations and Brain Organoid Collective Intelligence&#39;, &#39;contributors&#39;: [&#39;Iason Paterakis&#39;], &#39;paper_type&#39;: &#39;VISAP&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T09:06:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T09:06:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T09:18:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Nefeli Manoudaki&#39;, &#39;email&#39;: &#39;nefeli@ucsb.edu&#39;, &#39;affiliation&#39;: &#39;University of California, Santa Barbara&#39;}, {&#39;name&#39;: &#39;Mert Toka&#39;, &#39;email&#39;: &#39;merttoka@ucsb.edu&#39;, &#39;affiliation&#39;: &#39;University of California Santa Barbara&#39;}, {&#39;name&#39;: &#39;Iason Paterakis&#39;, &#39;email&#39;: &#39;iason@ucsb.edu&#39;, &#39;affiliation&#39;: &#39;University of California, Santa Barbara&#39;}, {&#39;name&#39;: &#39;Diarmid Flatley&#39;, &#39;email&#39;: &#39;diarmid@ucsb.edu&#39;, &#39;affiliation&#39;: &#39;University of California Santa Barbara&#39;}], &#39;abstract&#39;: &#39;Simulacra Naturae is a data-driven media installation that explores collective care through the entanglement of biological computation, material ecologies, and generative systems. The work translates pre-recorded neural activity from brain organoids, lab-grown three-dimensional clusters of neurons, into a multi-sensory environment composed of generative visuals, spatial audio, living plants, and fabricated clay artifacts. These biosignals, streamed through a real-time system, modulate emergent agent behaviors inspired by natural systems such as termite colonies and slime molds. Rather than using biosignals as direct control inputs, Simulacra Naturae treats organoid activity as a co-creative force, allowing neural rhythms to guide the growth, form, and atmosphere of a generative ecosystem. The installation features computationally fabricated clay prints embedded with solenoids, adding physical sound resonances to the generative surround composition. The spatial environment, filled with live tropical plants and a floor-level projection layer featuring real-time generative AI visuals, invites participants into a sensory field shaped by nonhuman cognition. By grounding abstract data in living materials and embodied experience, Simulacra Naturae reimagines visualization as a practice of care, one that decentralizes human agency and opens new spaces for ethics, empathy, and ecological attunement within hybrid computational systems.&#39;, &#39;uid&#39;: &#39;470f58d3-7a7a-47fd-baf3-82d155ac725b&#39;, &#39;keywords&#39;: [&#39;Artificial life&#39;, &#39;symbiosis&#39;, &#39;brain organoids&#39;, &#39;collective intelligence&#39;, &#39;generative ecosystem.&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_470f58d3-7a7a-47fd-baf3-82d155ac725b.html"> Simulacra Naturae: Generative Ecosystem driven by Agent-Based Simulations and Brain Organoid Collective Intelligence <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Nefeli Manoudaki, Mert Toka, Iason Paterakis, Diarmid Flatley </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Iason Paterakis </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T09:06:00.000Z &ndash; 2025-11-06T09:18:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;a-visap-1057&#39;, &#39;session_id&#39;: &#39;visap2&#39;, &#39;title&#39;: &#39;Living Library of Trees: Mapping Knowledge Ecology in Arnold Arboretum&#39;, &#39;contributors&#39;: [&#39;Johan Malmstedt&#39;], &#39;paper_type&#39;: &#39;VISAP&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T09:18:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T09:18:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T09:30:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Johan Malmstedt&#39;, &#39;email&#39;: &#39;johan.malmstedt@gmail.com&#39;, &#39;affiliation&#39;: &#39;GRIDH&#39;}, {&#39;name&#39;: &#39;Dario Rodighiero&#39;, &#39;email&#39;: &#39;d.rodighiero@rug.nl&#39;, &#39;affiliation&#39;: &#39;University of Groningen&#39;}, {&#39;name&#39;: &#39;Giacomo Nanni&#39;, &#39;email&#39;: &#39;gn.nann@gmail.com&#39;, &#39;affiliation&#39;: &#39;metaLAB (at) Berlin&#39;}], &#39;abstract&#39;: &#39;As biodiversity loss and climate change accelerate, botanical gar-\ndens serve as vital infrastructures for research, education, and con-\nservation. This project focuses on the Arnold Arboretum of Har-\nvard University, a 281-acre living museum founded in 1872 in\nBoston, understood as a hybrid site where scientific inquiry, envi-\nronmental stewardship, and interspecies encounters meet. Drawing\non more than a century of curatorial data, the research combines\nhistorical analysis with computational methods to visualize the in-\ntertwined biographies of plants and people. The resulting digital\nplatform reveals patterns of care and scientific observation, along\nwith the ethical, infrastructural, and collective dimensions embed-\nded in botanical data. Using techniques from artificial intelligence,\ngeospatial mapping, and information design, the project frames the\narboretum as a system of shared agency—an active archive of more-\nthan-human affinities that records the layered memory of curatorial\nlabor, the situated nature of knowledge production, and the poten-\ntial of design to bridge archival record and future care.&#39;, &#39;uid&#39;: &#39;2dfe369c-3743-4695-aeba-b0bc4de4429d&#39;, &#39;keywords&#39;: [&#39;Index Terms: botanical data&#39;, &#39;deep learning&#39;, &#39;digital archives&#39;, &#39;ethnobotany&#39;, &#39;historical visualization&#39;, &#39;interspecies relations&#39;, &#39;science\nand technology studies (STS)&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_2dfe369c-3743-4695-aeba-b0bc4de4429d.html"> Living Library of Trees: Mapping Knowledge Ecology in Arnold Arboretum <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Johan Malmstedt, Dario Rodighiero, Giacomo Nanni </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Johan Malmstedt </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T09:18:00.000Z &ndash; 2025-11-06T09:30:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;a-visap-1124&#39;, &#39;session_id&#39;: &#39;visap2&#39;, &#39;title&#39;: &#39;The Knowledge Cosmos: An Immersive Platform for Interdisciplinary Research Discovery&#39;, &#39;contributors&#39;: [&#39;Alec McGail&#39;, &#39;Rifaa Tajani&#39;, &#39;Nikita Sridhar&#39;], &#39;paper_type&#39;: &#39;VISAP&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T09:30:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T09:30:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T09:42:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Alec McGail&#39;, &#39;email&#39;: &#39;amcgail2@gmail.com&#39;, &#39;affiliation&#39;: &#39;Independent Academic&#39;}, {&#39;name&#39;: &#39;Rifaa Tajani&#39;, &#39;email&#39;: &#39;rifaa_tajani@mde.harvard.edu&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Nikita Sridhar&#39;, &#39;email&#39;: &#39;nikitasridhar14@gmail.com&#39;, &#39;affiliation&#39;: &#39;Independent Academic&#39;}, {&#39;name&#39;: &#39;Jiabao Li&#39;, &#39;email&#39;: &#39;stephlijiabao@gmail.com&#39;, &#39;affiliation&#39;: &#39;University of Texas at Austin&#39;}], &#39;abstract&#39;: &#39;As the volume of scientific literature continues to expand exponentially, traditional research tools struggle to keep pace—often reinforcing disciplinary silos and limiting opportunities for discovery. The Knowledge Cosmos re-imagines research exploration through an interactive, 3D visualization platform that treats science not as a static repository, but as a navigable universe. By spatializing 17 million academic papers based on semantic similarity, the platform enables users to explore the structure of knowledge intuitively, uncover interdisciplinary connections, and identify underexplored intellectual gaps. Drawing on the principles of play, immersion, and serendipity, The Knowledge Cosmos democratizes the bird’s eye view of research and encourages curiosity-driven inquiry across a wide range of users including students, educators, independent thinkers, and lifelong learners. This paper outlines the conceptual foundations, design, and technological infrastructure of the platform, shares insights from preliminary usability testing, and discusses future directions to scale its potential as a catalyst for interdisciplinary exploration and knowledge creation.&#39;, &#39;uid&#39;: &#39;79767fe9-582a-4d94-8cd6-2af68466de1d&#39;, &#39;keywords&#39;: [&#39;Large-scale data visualization&#39;, &#39;Science and technology visualization&#39;, &#39;User-centered design and evaluation&#39;, &#39;Knowledge visualization and concept mapping&#39;, &#39;Interdisciplinary research&#39;, &#39;3D and spatial interaction&#39;, &#39;Visual encoding and design&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_79767fe9-582a-4d94-8cd6-2af68466de1d.html"> The Knowledge Cosmos: An Immersive Platform for Interdisciplinary Research Discovery <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Alec McGail, Rifaa Tajani, Nikita Sridhar, Jiabao Li </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Alec McGail, Rifaa Tajani, Nikita Sridhar </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T09:30:00.000Z &ndash; 2025-11-06T09:42:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row my-5"><div class="col-md-8"><p>You may want to also jump to the parent event to see related presentations: <a href="event_a-visap.html">VIS Arts Program</a></p></div></div><script src="/static/2025/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script><script>

$(document).ready(function() {
    setInterval(updateSessionStatus, 30 * 1000);
    updateSessionStatus(true)
})

function updateSessionStatus(onFirstLoad) {
    // We need to write the session timings into the page to calculate current/next session.
    // See blueprint_2025.py
    startTime = '2025-11-06T08:30:00+00:00'
    endTime = '2025-11-06T09:45:00+00:00'

    // We take a 8 minute grace period to the start of a session
    const sessionStart = moment(startTime).tz(current_timezone).subtract(8, 'minutes');
    const sessionEnd = moment(endTime).tz(current_timezone);

    const sessionIsCurrent = moment().tz(current_timezone).isBetween(sessionStart, sessionEnd);
    const sessionIsFuture = moment().tz(current_timezone).isBefore(sessionStart);
    const sessionIsPast = moment().tz(current_timezone).isAfter(sessionStart);

    const classesToHide = ['.future_session_alert', '.current_session_alert', '.past_session_alert', '.room_session_stream']
    classesToHide.forEach((c) => { $(c).hide();});
    if (sessionIsCurrent) {
        $('.current_session_alert').show();
    } else if (sessionIsFuture) {
        $('.future_session_alert').show();
    } else {
        // Session is in the future
        $('#zoom_alert').hide();
        $('.past_session_alert').show();
        $('.room_session_stream').show();
    }

    // Update youtube link for older sessions
    // EDIT - We don't need this when the conference isn't live
    if(sessionIsPast){
        const roomidjson = "1_14-"+moment(startTime).format('ddd').toLowerCase()+".json"
        // console.log("this session was in:" , roomidjson)

        return fetch("https://virtual-data.ieeevis.org/"+roomidjson, {cache: "no-store"})
        .then(response => response.json())
        .then(data => {
            //console.log(data)
            // console.log('youtube_url: ' + data.youtube_url)
            //$("ytold").attr("href",data.youtube_url)

            // clear link element to avoid multiple appends
            document.getElementById("ytold").innerHTML = '';

            var a = document.createElement('a'); 
            var link = document.createTextNode(data.youtube_url);  
            a.appendChild(link); 
            a.title = "YouTube Link"; 
            a.href = data.youtube_url; 
            
            document.getElementById("ytold").appendChild(a);
        })
        .catch(error => {
            console.log("err: ", error);
        })
    }
    

}

</script></body></html>