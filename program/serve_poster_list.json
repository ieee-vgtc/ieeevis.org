{"a-biomedchallenge-3267":{"abstract":"The complexity of protein-protein interaction (PPI) networks often leads to visual clutter and limited interpretability. To overcome these problems, we present ProtEGOnist, a novel, interactive visualization approach designed to explore PPI networks with a focus on drug-protein associations. ProtEGOnist addresses the challenges by introducing the concept of ego-graphs to represent local PPI neighborhoods around proteins of interest. These ego-graphs are aggregated into an ego-graph network, where edges between ego-graphs encoded their similarity using the Jaccard index. Our proposed visualization design offers an overview of drug-associated proteins, radar charts to compare protein functions, and detailed ego-graph subnetworks for interactive exploration. Our aim was to reduce visual complexity while enabling detailed exploration, facilitating the discovery of meaningful patterns in PPI networks. A web-based prototype of ProtEGOnist is available for interactive use.","author_affiliations":["Nicolas Brich: University of T\u00fcbingen","Theresa Harbig: University of T\u00fcbingen","Mathias Witte Paz: University of T\u00fcbingen","Simon Tim Hackl: University of T\u00fcbingen","Caroline Jachmann: University of T\u00fcbingen","Marco Sch\u00e4fer: University of T\u00fcbingen","Michael Krone: University of T\u00fcbingen","Kay Nieselt: University of T\u00fcbingen"],"authors":["Nicolas Brich","Theresa Harbig","Mathias Witte Paz","Simon Tim Hackl","Caroline Jachmann","Marco Sch\u00e4fer","Michael Krone","Kay Nieselt"],"discord_channel":"","event":"Bio+MedVis Challenge Papers","event_prefix":"a-biomedchallenge","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"mathias-alexander.witte-paz@uni-tuebingen.de","presenting_author_name":"Mathias Witte Paz","title":"ProtEGOnist \u2013 Exploration of protein-protein interactions using ego-graph networks","uid":"a-biomedchallenge-3267"},"a-biomedchallenge-5794":{"abstract":"We present a visual analytics framework, PepProEx, for unraveling peptide and protein interactions. In the framework, users can understand holistic trends, discover patterns, and get insights from the peptide/protein intensity data. Our framework provides multiple linked views to navigate intricate tissue/cancer-related dynamics. We enable researchers to shift effortlessly from an overview of the input data to granular statistical insights.","author_affiliations":["Vikash Prasad: University of Oklahoma","Ji Hwan Park: University of Oklahoma"],"authors":["Vikash Prasad","Ji Hwan Park"],"discord_channel":"","event":"Bio+MedVis Challenge Papers","event_prefix":"a-biomedchallenge","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"vikash.k.prasad-1@ou.edu","presenting_author_name":"Vikash Prasad","title":"PepProEx - Peptide and Protein Exploration Framework","uid":"a-biomedchallenge-5794"},"a-biomedchallenge-7741":{"abstract":"CytoCave is an immersive interactive online visualization platform based on the NeuroCave connectome visualization application, but modified and optimized for general -omics network visual- ization. CytoCave leverages existing features of NeuroCave, in- cluding the side-by-side viewports designed for freeform explo- ration of node-link diagrams under various transformations or co- ordinate system embeddings, as well its immersive capabili- ties. However, CytoCave introduces a range of new features that facilitate the exploration of multi-omics networks using di- mensionality reduction projections of high-dimensional biological data with cluster membership highlighting, and includes scalabil- ity upgrades to support visualizing and interacting with large scale proteomics and multi-omics datasets. The CytoCave project source code, which includes the web application JavaScript and the data processing pipeline Jupyter notebook, is available on GitHub at https://github.com/iMammal/CytoCave. In this paper, we describe how to use CytoCave to facilitate the following proteomics and drug discovery tasks. CytoCave enables users: (Task 1) to select a protein and analyze drugs that target them, or, similarly, (Task 2) to select a drug and visualize the proteins that are strongly associated with the drug response. Additionally, CytoCave re-designs the traditional 2D force-directed layout visu- alization of protein interaction networks, providing an interactive interface that allows users to pan, rotate, and zoom in and out of the network, and to switch layouts and color coding templates from a variety of pre-calculated options, with optional pop-up annotations on mouse hovers and edge display / edge hiding on mouse clicks.","author_affiliations":["Morris Chukhman: University of Illinois at Chicago","Amira Kefi: University of Illinois","Olusola A. Ajilore: University of Illinois, Chicago (UIC)","Alex Leow: University of Illinois, Chicago (UIC)","Angus G. Forbes: Purdue University"],"authors":["Morris Chukhman","Amira Kefi","Olusola A. Ajilore","Alex Leow","Angus G. Forbes"],"discord_channel":"","event":"Bio+MedVis Challenge Papers","event_prefix":"a-biomedchallenge","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"morrisc@gmail.com","presenting_author_name":"Morris Chukhman","title":"CytoCave: An Interactive Visualization Tool for Exploring Protein and Drug Interaction Networks","uid":"a-biomedchallenge-7741"},"a-ldav-posters-1078":{"abstract":"\"This ongoing project aims to provide topological analysis tools to explore hydrodynamics instabilities observed through x-ray acquired during experimental campaigns on the National Ignition Facility (NIF). Topological Data Analysis (TDA) techniques will be evaluated to aid the segmentation of bubbles produced by fluid mixing during the development of Rayleigh-Taylor instabilities. The focus of this work is to evaluate topological tools and provide scientists from different laboratories with ready-to-use visualization topological pipelines to better understand experimental hydrodynamic instabilities.\"","author_affiliations":["Fabien Vivodtzev: CEA","Alexis Casner: CEA","Laurent Masse: CEA","Luke Ceurvorst: Laboratory of Laser Energetics","Shahab Khan: Lawrence Livermore National Laboratory","Vladimir Smalyuk: Lawrence Livermore National Laboratory"],"authors":["Fabien Vivodtzev, Alexis Casner, Laurent Masse, Luke Ceurvorst, Shahab Khan, Vladimir Smalyuk"],"discord_channel":"","event":"LDAV Posters","event_prefix":"a-ldav-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"vivodtzev@gmail.com","presenting_author_name":"Fabien Vivodtzev","title":"Topological Data Analysis of 3D Ablative Rayleigh-Taylor Instability Dataset for Automatic Segmentation","uid":"a-ldav-posters-1078"},"a-ldav-posters-5109":{"abstract":"\"We present an implementation of bidirectional steering of an in situ blood flow simulation through dynamically re-configuring simulation parameters without stopping the simulation. The interactive functions include dynamically inserting and removing different types of cells at user-specified regions, as well as changing flow boundary conditions. We also present preliminary results for blood flow in deformable vessel walls. The in situ blood flow simulation framework is implemented using open source packages. The work can potentially enhance the simulation workflow for parameter space exploration, as well as overcome the bottleneck of input/output performance in large scale simulations\"","author_affiliations":["Nazariy Tishchenko: Argonne National Lab","Nicola Ferrier: Argonne National Laboratory","Joseph Insley: Argonne National Laboratory","Victor A. Mateevitsi: Argonne National Laboratory","Michael E. Papka: Argonne National Laboratory","Silvio Rizzi: Argonne National Laboratory","Jifu Tan: Northern Illinois University"],"authors":["Nazariy Tishchenko, Nicola Ferrier, Joseph Insley, Victor A. Mateevitsi, Michael E. Papka, Silvio Rizzi, Jifu Tan"],"discord_channel":"","event":"LDAV Posters","event_prefix":"a-ldav-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"insley@anl.gov","presenting_author_name":"Joseph Insley","title":"Interactive Blood Flow Simulation With Deformable Cells and Walls","uid":"a-ldav-posters-5109"},"a-scivis-contest-1001":{"abstract":"","author_affiliations":[],"authors":[],"discord_channel":"","event":"SciVis Contest","event_prefix":"a-scivis-contest","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"hjschulz@cs.au.dk|mhograefer@cs.au.dk","presenting_author_name":"Hans-J\u00f6rg Schulz","title":"Immersive Exploration of Brain Simulation Data","uid":"a-scivis-contest-1001"},"a-scivis-contest-1005":{"abstract":"","author_affiliations":[],"authors":[],"discord_channel":"","event":"SciVis Contest","event_prefix":"a-scivis-contest","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"sonnet.xu@gmail.com|Tommy.Dang@ttu.edu","presenting_author_name":"Sonnet Xu","title":"PlastiVis: An Interactive Visualization Tool for Synaptic Networks","uid":"a-scivis-contest-1005"},"a-scivis-contest-1007":{"abstract":"","author_affiliations":[],"authors":[],"discord_channel":"","event":"SciVis Contest","event_prefix":"a-scivis-contest","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"li1023@cnic.cn|hanxiaoyang@cnic.cn","presenting_author_name":"Yue Li","title":"NeuroViz: Visual Analytics of Neural Behavior in Temporal Plasticity Changes","uid":"a-scivis-contest-1007"},"a-scivis-contest-1010":{"abstract":"","author_affiliations":[],"authors":[],"discord_channel":"","event":"SciVis Contest","event_prefix":"a-scivis-contest","has_image":false,"has_poster_pdf":false,"has_summary_pdf":true,"presenting_author_email":"felix.fleisch@uni-jena.de|kai.lawonn@uni-jena.de","presenting_author_name":"Felix Fleisch","title":"An Interactive Visualization for Neuronal Network Simulations of Plasticity Changes in the Human Brain","uid":"a-scivis-contest-1010"},"a-scivis-contest-1011":{"abstract":"","author_affiliations":[],"authors":[],"discord_channel":"","event":"SciVis Contest","event_prefix":"a-scivis-contest","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"morrisc@gmail.com","presenting_author_name":"Morris Chukhman","title":"Exploring Synaptic Plasticity with NeuroCavePlus","uid":"a-scivis-contest-1011"},"a-scivis-contest-1012":{"abstract":"","author_affiliations":[],"authors":[],"discord_channel":"","event":"SciVis Contest","event_prefix":"a-scivis-contest","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"thomas.j.marrinan@gmail.com","presenting_author_name":"Thomas Marrinan","title":"VisAnywhere: Developing Multi-platform Scientific Visualization Applications","uid":"a-scivis-contest-1012"},"a-vast-challenge-1015":{"abstract":"To solve the VAST Challenge 2023 MC3, our team employed a large language model, ChatGPT, to explore the potential of AI-guided visual analytics for the detection of anomalies within a knowledge graph in the context of illegal fishing and marine trade. We employed a systematic and iterative approach, guided by GPT augmentation, that enabled problem understanding, data processing, solution explo- ration, code writing, and results analysis. By generating and analyz- ing various graphs, we identified anomalies related to revenue and product services. Further analyses unveiled potential illegal fishing activities and identified instances warranting additional investigation. Overall, our work highlights both the strengths and limitations of ChatGPT in aiding the visual analytics process and emphasizes the importance of human judgment in refining AI-generated outputs.","author_affiliations":["Ava Zhao: Phillips Exeter Academy","Zhanqi Su: Carmel High School","William C Fei: Purdue University","Na Zhuo: Purdue University","Hao Wang: Purdue University","Tianzhou Yu: The Chinese University of Hong Kong","Zuotian Li: Purdue University","Zhenyu Cheryl Qian: Purdue University","Yingjie Victor Chen: Purdue University"],"authors":["Ava Zhao","Zhanqi Su","William C Fei","Na Zhuo","Hao Wang","Tianzhou Yu","Zuotian Li","Zhenyu Cheryl Qian","Yingjie Victor Chen"],"discord_channel":"","event":"VAST Challenge","event_prefix":"a-vast-challenge","has_image":false,"has_poster_pdf":true,"has_summary_pdf":false,"presenting_author_email":"li4007@purdue.edu","presenting_author_name":"Zuotian Li","title":"Purdue-Chen-MC3","uid":"a-vast-challenge-1015"},"a-vast-challenge-1017":{"abstract":"Undertaking the visual exploration of a large knowledge graph in the domain of illegal fishery activities, FishHook offers an interactive visual analytics solution for scrutinizing individual entities via four distinct views: the Ego Net view, the Hierarchical Tree view, the Unity Net view, and the Parallel Coordinates view. The system incorporates an anomalous pattern detection mechanism, which is designed to address the challenges detailed in the 2023 IEEE VAST Challenge MC1. This integrated solution not only demonstrates robustness and scalability but also provides a powerful tool for comprehending large-scale knowledge graph datasets.","author_affiliations":["Jingfu Wu: Southern University of Science and Technology","Diyun Lu: Southern University of Science and Technology","Lei Chen: Southern University of Science and Technology","Ningyi Peng: Southern University of Science and Technology","Fan Yang: SUSTech","Xinyu Tang: Southern University of Science and Technology","Yuxin Ma: Southern University of Science and Technology"],"authors":["Jingfu Wu","Diyun Lu","Lei Chen","Ningyi Peng","Fan Yang","Xinyu Tang","Yuxin Ma"],"discord_channel":"","event":"VAST Challenge","event_prefix":"a-vast-challenge","has_image":false,"has_poster_pdf":true,"has_summary_pdf":false,"presenting_author_email":"wujingf25@163.com","presenting_author_name":"Jingfu Wu","title":"FishHook: A Visual Analytics System for Tracing Suspicious Entities in the Fisheries Domain using Knowledge Graphs","uid":"a-vast-challenge-1017"},"v-vis-posters-1027":{"abstract":"Forensic investigation is a complex and collaborative procedure involving multiple experts working together to finally report critical findings to legal authorities. We propose a new report generation workflow and present a novel multi-device documentation system using mixed-reality visualisation, voice and gesture interaction. Our initial findings suggest that this workflow not only enhances the thoroughness of captured data but also streamlines report generation which leads to less time and costs associated with performing autopsies. Additionally, this method offers significant potential for educational applications.","author_affiliations":["Vahid Pooryousef: Monash University","Lonni Besan\u00e7on: Link\u00f6ping University","Maxime Cordeil: The University of Queensland","Richard Bassed: Monash University","Tim Dwyer: Monash University"],"authors":["Vahid Pooryousef","Lonni Besan\u00e7on","Maxime Cordeil","Richard Bassed","Tim Dwyer"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"vahid.pooryousef@monash.edu","presenting_author_name":"Vahid Pooryousef","title":"Multi-Device Forensic Autopsy Documentation and Report Generation Using Mixed Reality","uid":"v-vis-posters-1027"},"v-vis-posters-1028":{"abstract":"There has been an explosion in interest in machine learning (ML) in recent years due to its applications to science and engineering. However, as ML techniques have advanced, tools for explaining and visualizing novel ML algorithms have lagged behind. Animation has been shown to be a powerful tool for making engaging visualizations of systems that dynamically change over time, which makes it well suited to the task of communicating ML algorithms. However, the current approach to animating ML algorithms is to handcraft applications that highlight specific algorithms or use complex generalized animation software. We developed ManimML, an open-source Python library for easily generating animations of ML algorithms directly from code. We sought to leverage ML practitioners' preexisting knowledge of programming rather than requiring them to learn complex animation software.  ManimML has a familiar syntax for specifying neural networks that mimics popular deep learning frameworks like Pytorch. A user can take a preexisting neural network architecture and easily write a specification for an animation in ManimML, which will then automatically compose animations for different components of the system into a final animation of the entire neural network. ManimML is open source and available at https://github.com/helblazer811/ManimML.","author_affiliations":["Alec Fisher Helbling: Georgia Institute of Technology","Duen Horng Chau: Georgia Tech"],"authors":["Alec Fisher Helbling","Duen Horng Chau"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"alechelbling1@gmail.com","presenting_author_name":"Alec Helbling","title":"ManimML: Communicating Machine Learning Architectures with Animation","uid":"v-vis-posters-1028"},"v-vis-posters-1029":{"abstract":"The Net Promoter Score (NPS\u00ae) is a metric used to gauge how well an organization's product or service is perceived by their customers. A NPS\u00ae survey is usually accompanied by various ancillary questions to help explain the score and provide deeper insights about the respondents. Sifting through such surveys for thousands of respondents, especially when free-text feedback questions are present, can be a monumental task for small teams. Furthermore, the small team needs to process the feedback quickly and generate reports for high-level discussions by leadership to effect changes in the organization. To overcome these challenges, we have built an interactive dashboard tool with Microsoft Power BI (PowerBI) that contains clear and concise visualizations. We achieved this by applying advance NLP analytics in our normalization steps, thus allowing the summarization of feedback from hundreds of respondents to correlate our findings with the NPS\u00ae. We generated a custom hierarchical cluster heat map as well as a keyword relationship network (wordnet) visual in PowerBI that were instrumental in summarizing a lot of detail into singular visual representations. The tool has since been used multiple times to empower our leadership at BD to make informed decisions about culture and organizational changes in a matter of days instead of weeks/months.","author_affiliations":["Joel Low: Becton Dickinson","Hemen Patel: Becton Dickinson","Siddharth Goyal: Becton Dickinson"],"authors":["Joel Low","Hemen Patel","Siddharth Goyal"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"joel.low@bd.com","presenting_author_name":"Joel Low","title":"Insights into Net Promoter Score (NPS\u00ae) Surveys with Microsoft Power BI and Advance Analytics","uid":"v-vis-posters-1029"},"v-vis-posters-1030":{"abstract":"\"Dynamic network visualization is a rapidly evolving field and computing a node-link layout for these graphs is one of the most studied problems in this discipline. Benchmark datasets and quality criteria are lacking in order to enable comparative evaluations of the layouts produced by different dynamic network visualization techniques. This paper proposes a collection of both discrete time and event-based dynamic quality criteria for evaluating dynamic graph layouts. Furthermore, we present and discuss datasets, generated from real data, which we include in a benchmark set for future researchers to use in their evaluations.\"","author_affiliations":["Velitchko Andreev Filipov: Institute of Visual Computing and Human-Centered Technology","Alessio Arleo: TU Wien","Tatiana von Landesberger: University of Cologne","Daniel Archambault: Newcastle University"],"authors":["Velitchko Andreev Filipov","Alessio Arleo","Tatiana von Landesberger","Daniel Archambault"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"alessio.arleo@tuwien.ac.at","presenting_author_name":"Alessio Arleo","title":"Back to the Graphs: A Collection of Datasets and Quality Criteria for Temporal Networks Layout and Visualization","uid":"v-vis-posters-1030"},"v-vis-posters-1032":{"abstract":"Digital twin visualization requires virtual device representations which often demand significant design effort. Introducing AI-generated content (AIGC) can reduce designer's workload, but its impact on professional users' information perception must be evaluated. This paper evaluates the effectiveness of different device representation methods on professional user acceptance in digital twin visualization. Photography, 3D modeling, and AI-generated device representations are compared concerning accuracy, aesthetics, and clarity, and their influence on users' information reading. Feedback from 31 professional users reveals that AI-generated device representations outperform traditional 3D modeling in accuracy, clarity, and aesthetics without affecting user information perception. This paper presents an empirical study on the evaluation of AIGC in digital twin visualization, highlighting the potential of AIGC in relevant visualization applications.","author_affiliations":["Jiachun Du: Alibaba Cloud","Wei Zhao: Alibaba Cloud","Hanyue Duan: Alibaba Cloud","Xiaofan Liu: Alibaba Cloud"],"authors":["Jiachun Du","Wei Zhao","Hanyue Duan","Xiaofan Liu"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"jiachun.djc@alibaba-inc.com","presenting_author_name":"Jiachun Du","title":"Evaluating the Effectiveness of AI-Generated Device Representations in Digital Twin Visualizations","uid":"v-vis-posters-1032"},"v-vis-posters-1035":{"abstract":"Learning and understanding dance is difficult for people who are blind or have low vision (BLV) due to its inherent visual nature. While there is a rich history of visual representation of dance, and researchers are exploring novel representations, the typically visually-dominant representations limit access to BLV people and thus compromise learning and understanding of dance movement. This work presents an overview of an initial design space for \u201cAccessible DanceVis\u201d, located at the intersection of visualization and accessibility, and exploring the use of non-visual modalities. It is hoped this will stimulate the Vis community to consider how they may contribute to supporting BLV people in dance and this important community activity.","author_affiliations":["Madhuka Thisuri De Silva: Monash University","Matthew Butler: Monash University","Leona M Holloway: Monash University","Jim Smiley: Monash University","Sarah Goodwin: Monash University"],"authors":["Madhuka Thisuri De Silva","Matthew Butler","Leona M Holloway","Jim Smiley","Sarah Goodwin"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"madhuka.desilva@monash.edu","presenting_author_name":"Madhuka De Silva","title":"Design Space Exploration of Accessible DanceVis","uid":"v-vis-posters-1035"},"v-vis-posters-1036":{"abstract":"Twitter is one of the popular social media platforms where people share news or reactions towards an event or topic using short text messages called \"tweets\". Emotion analysis in these tweets can play a vital role in understanding peoples\u2019 feelings towards the underlying event or topic. In this work, we present our visual analytics tool, called TECVis, that focuses on providing comparison views of peoples' emotion feelings in tweets towards an event or topic. The comparison is done based on geolocations or timestamps. TECVis provides several interaction and filtering options for navigation and better exploration of underlying tweet data for emotion feelings comparison.","author_affiliations":["Ilya Nemtsov: San Francisco State University","MST Jasmine Jahan: School","Chuting Yan: San Francisco State University","Shah Rukh Humayoun: San Francisco State University"],"authors":["Ilya Nemtsov","MST Jasmine Jahan","Chuting Yan","Shah Rukh Humayoun"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"humayoun@sfsu.edu","presenting_author_name":"Shah Rukh Humayoun","title":"TECVis: A Visual Analytics Tool to Compare People\u2019s Emotion Feelings","uid":"v-vis-posters-1036"},"v-vis-posters-1039":{"abstract":"Due to the tediousness and labor intensive cost, manga artists always attempt to find an automatic way to convert color photographs to manga backgrounds. However, existing bitonal image generation methods usually rely on low-level features and their outcomes often vary in quality, making manual inspections and adjustments of the results necessary. In this paper, we propose a novel method for generating bitonal manga backgrounds from color photographs with respect to semantics. Our goal is to preserve the visual richness in the original photograph by not only utilizing rich set of screen patterns but also preserving the distinguishability of different semantics. Several results are presented to demonstrate the effectiveness and convenience of the proposed method.","author_affiliations":["Minshan XIE: The Chinese University of Hong Kong","Tien-Tsin Wong: The Chinese University of Hong Kong"],"authors":["Minshan XIE","Tien-Tsin Wong"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"ttwong@cse.cuhk.edu.hk","presenting_author_name":"Prof Tien-Tsin Wong","title":"Semantic-Aware Image Screening","uid":"v-vis-posters-1039"},"v-vis-posters-1040":{"abstract":"When researchers are about to start a new project or have just entered a new research field, choosing a proper research topic is always challenging. To help them have an overall understanding of the research trend in real-time and find out the research topic they are interested in, we developed the Research Trend Visualization toolkit (RTVis) to analyze and visualize the research paper information. RTVis consists of a field theme river, a co-occurrence network, a specialized citation bar chart, and a word frequency race diagram, showing the field change through time, cooperating relationship among authors, paper citation numbers in different venues, and the most common words in the abstract part respectively. Moreover, RTVis is open source and easy to deploy. The demo of our toolkit and code with detailed documentation are both available online.","author_affiliations":["Xingyu Shen: Duke Kunshan University","Yueqian Lin: Duke Kunshan University","Zhixian Zhang: Duke Kunshan University","Xin Tong: Duke Kunshan University"],"authors":["Xingyu Shen","Yueqian Lin","Zhixian Zhang","Xin Tong"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"k_speech@duke.edu","presenting_author_name":"Xingyu Shen, Yueqian Lin, Zhixian Zhang","title":"RTVis: Research Trend Visualization Toolkit","uid":"v-vis-posters-1040"},"v-vis-posters-1042":{"abstract":"Practitioners can detect human sex trafficking (HT) in online escort websites by analyzing both the text and connections between metadata (i.e. contact information) throughout time of suspicious clusters of connected ads. Previous attempts at visualizing these graphs have suffered from the hairball effect, as certain portions of the graph are densely connected. Given a group of ads with shared metadata, how can we interactively visualize connections between metadata and how they change over time? TrafficBoard combines graph summarization techniques and interactivity to enable practitioners to investigate suspicious metadata and their connections throughout time, as well as their geographic spread.","author_affiliations":["Catalina Vajiac: Carnegie Mellon University","Duen Horng Chau: Georgia Tech","Andreas Olligschlaeger: i3 LLC","Pratheeksha Nair: McGill University","Meng-Chieh Lee: Carnegie Mellon University","Mirela Teixeira Cazzolato: University of Sao Paulo","Reihaneh Rabbany: McGill University, Mila","Cara Jones: Marinus Analytics","Christos Faloutsos: Carnegie Mellon University"],"authors":["Catalina Vajiac","Duen Horng Chau","Andreas Olligschlaeger","Pratheeksha Nair","Meng-Chieh Lee","Mirela Teixeira Cazzolato","Reihaneh Rabbany","Cara Jones","Christos Faloutsos"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"cvajiac@cs.cmu.edu","presenting_author_name":"Catalina Vajiac","title":"TrafficBoard: Digital Spatio-Temporal Pinboard for Human Trafficking Detection","uid":"v-vis-posters-1042"},"v-vis-posters-1045":{"abstract":"Exploratory Data Analysis (EDA) is a necessary yet laborious task when examining new datasets. To facilitate it, natural language interfaces (NLIs) can help users explore data through questions. However, existing NLIs lack explanations and visualizations of the analysis process used to uncover the answer. To address this, we introduce Urania, an interactive system that visualizes data analysis pipelines for resolving input questions. It first leverages a novel algorithm to break down questions into analysis pipelines, and then presents pipelines as datamations, with animated operations and data changes. Our experiments show that our algorithm outperforms existing methods in terms of accuracy, and that Urania can help people explore datasets better.","author_affiliations":["Yi Guo: Tongji University","Nan Cao: Tongji College of Design and Innovation","Xiaoyu Qi: Tongji University","Haoyang Li: Renmin University of China","Danqing Shi: Finnish Center for Artificial Intelligence","Jing Zhang: Renmin University of China","Qing Chen: Intelligent Big Data Visualization Lab"],"authors":["Yi Guo","Nan Cao","Xiaoyu Qi","Haoyang Li","Danqing Shi","Jing Zhang","Qing Chen"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"yii.gguo@gmail.com","presenting_author_name":"YI GUO","title":"Enhancing Natural Language-Based Data Exploration with Analysis Pipeline Illustration","uid":"v-vis-posters-1045"},"v-vis-posters-1046":{"abstract":"\"The number of edges which cross in a graph drawing is an important measure of readability. Fewer edge crossings results in a drawing which is easier for humans to understand. Graph drawing researchers typically refer to the \"\"crossing number\"\" of a graph; that is, the minimum number of edge crossings when the graph is embedded on a 2D plane. This integer naturally depends on the structure and size of the graph. An integer measure of the \"\"crossiness\"\" of a graph drawing is, however, not useful when comparing graph drawings of different size or structure. Here we present the challenges of devising a normalised \"\"edge crossings\"\" metric scaled in the [0,1] range. A natural definition for this metric is the number of edge crossings in the drawing, divided by the number of possible crossings which could occur. This paper improves upon an existing metric which uses this idea, by giving a tighter upper bound on the maximum possible crossings. We also present the distributions of our new metric for 16,768 graphs, obtained from various random generators and repositories, across 3 layout algorithms.\"","author_affiliations":["Gavin J. Mooney: Monash University","Helen C. Purchase: Monash University","Michael Wybrow: Monash University"],"authors":["Gavin J. Mooney","Helen C. Purchase","Michael Wybrow"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"gavin.mooney@monash.edu","presenting_author_name":"Gavin J. Mooney","title":"A Normalised Metric for Edge Crossings","uid":"v-vis-posters-1046"},"v-vis-posters-1050":{"abstract":"Immersive analytics is gaining attention across various industries owing to its superior ability to enable intuitive data analysis in a large space with effective data interaction. However, generating an immersive analytical environment is an exhaustive task that requires extensive time and effort. Despite the introduction of various immersive visualization authoring toolkits in the past, there are still significant programming hurdles that hinder domain experts from effectively integrating immersive analytics into their workflow, particularly when faced with dynamically changing data or tasks. To reduce these technical barriers, we introduce a novel immersive analytics authoring framework called XROps, which enables immersive visualization development through visual programming that does not require complex coding. XROps allows for entirely dynamic unified immersive analytics authoring, which can alter the visualization framework according to user needs on-the-fly with immediate feedback. We assessed the usability of XROps through a user study.","author_affiliations":["Suemin Jeon: Korea University","JunYoung Choi: Korea University","Haejin Jeong: Korea University","Won-Ki Jeong: Korea University"],"authors":["Suemin Jeon","JunYoung Choi","Haejin Jeong","Won-Ki Jeong"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"orangeblush@korea.ac.kr","presenting_author_name":"Suemin Jeon","title":"Breaking Down the Technical Barrier: Visual Programming Driven Dynamic Immersive Analytics using XROps","uid":"v-vis-posters-1050"},"v-vis-posters-1051":{"abstract":"Visualisation design requires critical thought: to understand important facets, investigate design suitability and explore alternatives.  But, especially for learners, it can be difficult to structure a critical reflection of creative solutions. We introduce the Critical Design Survey (CDS): structured method that facilitates visualisation design analysis through reflective and critical thought. Applying the CDS helps someone to structure critical thought, provides a unified method that can be readily taught, learners can actively engage with the process and directly use it to write a critical-thinking report of their design ideas. The CDS contains three steps: Step 1, summarise and write down the essence of the idea. Step 2, perform an in-depth critique (we define 30 questions structured in six perspectives). Step 3, synthesise the ideas, implications, and decide on the next steps. We present the CDS, describe our design process (critical thinking workshops, talk aloud, and student use), and describe our use in teaching visualisation to undergraduate and postgraduate students.","author_affiliations":["Jonathan C Roberts: Bangor University","Hanan Alnjar: Basrah University","Aron E. Owen: Bangor University","Panagiotis D. Ritsos: Bangor University"],"authors":["Jonathan C Roberts","Hanan Alnjar","Aron E. Owen","Panagiotis D. Ritsos"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"j.c.roberts@bangor.ac.uk","presenting_author_name":"Jonathan C. Roberts","title":"A method for Critical and Creative Visualisation Design-Thinking","uid":"v-vis-posters-1051"},"v-vis-posters-1052":{"abstract":"The recent advancements in machine learning have motivated researchers to generate classification models dealing with hundreds of classes such as in the case of image datasets. However, visualization of classification models with high number of classes and inter-model comparison in such classification problems are two areas that have not received much attention in the literature, despite the ever-increasing use of classification models to address problems with very large class categories. In this paper, we present our interactive visual analytics tool, called Circles, that allows a visual inter-model comparison of numerous classification models with 1K classes in one view. To mitigate the tricky issue of visual clutter, we chose a concentric radial line layout for our inter-model comparison task. Our prototype shows the results of 9 models with 1K classes in a single view; however, up to 20 models' results can be displayed in this way.","author_affiliations":["Nina Mir: San Francisco State University","Ragaad Al-Tarawneh: INTEL Corporation","Shah Rukh Humayoun: San Francisco State University"],"authors":["Nina Mir","Ragaad Al-Tarawneh","Shah Rukh Humayoun"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"humayoun@sfsu.edu","presenting_author_name":"Shah Rukh Humayoun","title":"Circles: Inter-Model Comparison of Multi-Classification Problems with High Number of Classes","uid":"v-vis-posters-1052"},"v-vis-posters-1053":{"abstract":"\"The study of information visualization (infovis) has provided techniques and heuristics for effectively conveying patterns in large or complex datasets to an audience. A similar set of insights is needed to guide information flow in the opposite direction: to collect a large or complex set of data from an audience. Knowledge elicitation \u2013 the collection of descriptions or assessments from domain experts \u2013 plays a critical role in making estimates about rare or future events and scoping research problems. Existing knowledge elicitation methodologies focus on the elicitation process, however, rather than how specific features of the data capture interfaces affect the quality of the knowledge elicited. A case study from Australian Defence capability analysis suggests that a new area of research inquiry, Visual Knowledge Elicitation (VKE), would enable more effective knowledge elicitation.\"","author_affiliations":["Lydia C Byrne: Defence Science and Technology Group"],"authors":["Lydia C Byrne"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"lydia.byrne@defence.gov.au","presenting_author_name":"Lydia Byrne","title":"The Need for Visual Knowledge Elicitation","uid":"v-vis-posters-1053"},"v-vis-posters-1056":{"abstract":"This study builds on past research bridging spatial visualization, psychology, and information visualization to holistically inform visualization design. We expand on exploring the effects of chosen discipline in combination with cognitive abilities on visual tasks through estimation of Pearson's correlation coefficient. We measure spatial visualization and visual task performance between psychologists and math & computer scientists. Accuracy and response times varied with domain and across spatial visualization levels.","author_affiliations":["Sara Tandon: King's College London","Alfie Abdul-Rahman: King's College London","Rita Borgo: Kings College London"],"authors":["Sara Tandon","Alfie Abdul-Rahman","Rita Borgo"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"sara.tandon@kcl.ac.uk","presenting_author_name":"Sara Tandon","title":"Effects of Spatial Abilities and Domain on Estimation of Pearson's Correlation Coefficient","uid":"v-vis-posters-1056"},"v-vis-posters-1058":{"abstract":"In the light of recent advances in embodied data visualizations, we aim to shed light on agency in the context of data visualization. To do so, we introduce Data Agency and Data-Agent Interplay as potential terms and research focus. Furthermore, we exemplify the former in the context of human-robot interaction, and identify future challenges and research questions.","author_affiliations":["Sarah Victoria Sch\u00f6mbs: The University of Melbourne","Jorge Goncalves: University of Melbourne","Wafa Johal: University of Melbourne"],"authors":["Sarah Victoria Sch\u00f6mbs","Jorge Goncalves","Wafa Johal"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"sschombs@student.unimelb.edu.au","presenting_author_name":"Sarah Sch\u00f6mbs","title":"Exploring Data Agency and Autonomous Agents as Embodied Data Visualizations","uid":"v-vis-posters-1058"},"v-vis-posters-1059":{"abstract":"Visualization is a powerful tool for presenting complex data, but challenges of inspiration and ideation can hinder the creative process of designing compelling visualizations. We developed VisDice, a novel tool for stimulating creative thought and inspiring alternative design ideas to address this. By introducing randomness, VisDice prompts designers to explore uncharted territories and consider unconventional visualization solutions. This paper investigates VisDice's role in enhancing the creative process, drawing from psychological theories of inspiration. We explore how VisDice stimulates innovative thinking, leading to visually compelling designs. Our findings contribute to understanding the psychology behind creativity in visualization, offering practical insights for designers seeking to enhance their practices. Embracing the possibilities offered by VisDice unlocks new avenues for designing impactful visualizations.","author_affiliations":["Aron E. Owen: Bangor University","Jonathan C Roberts: Bangor University"],"authors":["Aron E. Owen","Jonathan C Roberts"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"aron.e.owen@bangor.ac.uk","presenting_author_name":"Aron E. Owen","title":"Inspire and Create: Unveiling the Potential of VisDice in Visualization Design","uid":"v-vis-posters-1059"},"v-vis-posters-1060":{"abstract":"This work investigates the current use of visualisation techniques and displays involved in running activities. We analysed 87 papers from 55 HCI and Visualisation venues and identified six categories that describe current running analytics visualisations. From this data, we created an interactive visualisation of the current techniques, in order to provide insights into the in-situ running analytics design space, and help identify current gaps and challenges in developing running data visualisations. Our initial inquiry reveals the emerging trend of immersive technologies for decision-making while running, and the opportunity to study how people analyse data while running.","author_affiliations":["Ang Li: University of Queensland","Stephen Viller: University of Queensland","Gianluca Demartini: University of Queensland","Maxime Cordeil: The University of Queensland"],"authors":["Ang Li","Stephen Viller","Gianluca Demartini","Maxime Cordeil"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"ang.li1@uq.edu.au","presenting_author_name":"Ang Li","title":"A Visual Survey of In-Situ Running Analytics","uid":"v-vis-posters-1060"},"v-vis-posters-1061":{"abstract":"Regression experts consistently recommend plotting residuals for model diagnosis, despite the availability of many numerical hypothesis test procedures designed to use residuals to assess problems with a model fit. Here we provide evidence for why this is good advice using data from a visual inference experiment. We show how conventional tests are too sensitive, which means that too often the conclusion would be that the model fit is inadequate. The experiment uses the lineup protocol which puts a residual plot in the context of null plots. This helps generate reliable and consistent reading of residual plots for better model diagnosis. The lineup protocol also detects a range of departures from good residuals simultaneously.","author_affiliations":["Weihao Li: Monash University","Di Cook: Monash University","Emi Tanaka: Australian National University","Susan R Vanderplas: University of Nebraska, Lincoln"],"authors":["Weihao Li","Di Cook","Emi Tanaka","Susan R Vanderplas"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"weihao.li@monash.edu","presenting_author_name":"Weihao Li","title":"A Plot is Worth a Thousand Tests: Assessing Residual Diagnostics with the Lineup Protocol","uid":"v-vis-posters-1061"},"v-vis-posters-1062":{"abstract":"Refreshable tactile displays (RTDs) are predicted to soon become a viable option for the provision of accessible graphics for people who are blind or have low vision (BLV). This new technology for the tactile display of braille and graphics, usually using raised pins, makes it easier to generate and access a large number of graphics. However, it differs from existing tactile graphics in terms of scale, height and fidelity. Here, we share the perspectives of four key stakeholders -- blind touch readers, vision specialist teachers, accessible format producers and assistive technology providers -- to explore the potential uses, advantages and needs relating to the introduction of RTDs. We also provide advice on what role the data visualisation community can take to help ensure that people who are BLV are best able to benefit from the introduction of affordable RTDs.","author_affiliations":["Leona M Holloway: Monash University","Peter Cracknell: Quantum RLV","Kate Stephens: blind consumer","Melissa Fanshawe: University of Southern Queensland","Samuel Reinders: Monash University","Kim Marriott: Monash University","Matthew Butler: Monash University"],"authors":["Leona M Holloway","Peter Cracknell","Kate Stephens","Melissa Fanshawe","Samuel Reinders","Kim Marriott","Matthew Butler"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"leona.holloway@monash.edu","presenting_author_name":"Leona Holloway","title":"Refreshable Tactile Displays for Accessible Data Visualisation","uid":"v-vis-posters-1062"},"v-vis-posters-1063":{"abstract":"We present DUVis, a visual analytics application developed to support the analysis and appraisal, of the transdiciplinary project D\u0175r Uisce, from internal project managers and external stakeholders. DUVis provides a number of visualizations and additional features to facilitate data exploration of a project\u2019s progress. It presents a map of stakeholders\u2019 activities, and their engagement with each other, as well as outputs, workpackages, their completion status and potential impact. We present our preliminary design and provide a blueprint for further development.","author_affiliations":["Alexander Mark Farrell Rigby: Bangor University","Peter W. S. Butcher: Bangor University","Roberta Bellini: Trinity Collage Dublin","Paul Coughlan: Trinity College Dublin","Aonghus McNabola: Trinity Collage Dublin","Panagiotis D. Ritsos: Bangor University"],"authors":["Alexander Mark Farrell Rigby","Peter W. S. Butcher","Roberta Bellini","Paul Coughlan","Aonghus McNabola","Panagiotis D. Ritsos"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"p.ritsos@bangor.ac.uk","presenting_author_name":"Dr Panagiotis D. Ritsos","title":"DUVis: A visual analytics tool for supporting a trans-disciplinary project","uid":"v-vis-posters-1063"},"v-vis-posters-1064":{"abstract":"With the introduction of the Visualization for Communication workshop (VisComm) at IEEE VIS and in light of the COVID-19 pandemic, there has been renewed interest in studying visualization as a medium of communication. However the characteristics and definition of this line of study tend to vary from paper to paper and person to person. In this work, we examine the 37 papers accepted to VisComm from 2018 through 2022. Using grounded theory we identify nuances in how VisComm defines visualization, common themes in the work in this area, and a noticeable gap in DEI practices.","author_affiliations":["Vedanshi Chetan Shah: Northeastern University","Ab Mosca: Northeastern University"],"authors":["Vedanshi Chetan Shah","Ab Mosca"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"shah.ve@northeastern.edu","presenting_author_name":"Vedanshi Shah","title":"What is Visualization for Communication? Analyzing Four Years of VisComm Papers","uid":"v-vis-posters-1064"},"v-vis-posters-1065":{"abstract":"In this paper, we provide an overview of our attempts to harness data physicalizations as pedagogical tools for enhancing the understanding of visual channels.  We first elaborate the research goals that we have crafted for the physicalization prototype, shedding light on the key principles that guided our design choices. Then we detail the materials and datasets we employed for nine channels on our physicalization prototype. A preliminary pilot study is followed to validate its effectiveness. In the end, we present our upcoming research initiatives, including a comparative study for assessing the usability of the physicalization system. In general, the main purpose of our work is to stimulate a wider engagement among visualization educators and researchers, encouraging them to delve into the potentialities of data physicalization as an innovative addition to contemporary teaching methodologies..","author_affiliations":["Siqi Xie: Xi'an Jiaotong-Liverpool University","yu liu: Xi'an Jiaotong-Liverpool University","Lingyun Yu: Xi'an Jiaotong-Liverpool University"],"authors":["Siqi Xie","yu liu","Lingyun Yu"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"Yu.Liu02@xjtlu.edu.cn","presenting_author_name":"Yu Liu","title":"TangibleChannel: An Innovative Data Physicalization System for Visual Channel Education","uid":"v-vis-posters-1065"},"v-vis-posters-1067":{"abstract":"We designed an interactive augmented reality (AR) visualization artwork, titled \u201cTime Walk,\u201d to transport the visitors through different times, conveying a profound sense of collective celebration and companionship. Through our design of digital overlays, which are the timeline, trail flowers, and balloons, the artwork transforms the physical space into a dynamic and visually captivating vicinity. Visitors can actively participate and explore the artwork, witnessing the visual representation of an institution's history and the presence of other visitors. By blending real and virtual elements, we proposed a unique and interactive way for people to engage with history and connect with fellow visitors from the past. The user study involved eight participants who rated the design elements positively, expressing a strong sense of celebration and connection with others.","author_affiliations":["Wai Tong: The Hong Kong University of Science and Technology","Linping Yuan: The Hong Kong University of Science and Technology","Zikai Wen: The Hong Kong University of Science and Technology (Guangzhou)","Huamin Qu: The Hong Kong University of Science and Technology"],"authors":["Wai Tong","Linping Yuan","Zikai Wen","Huamin Qu"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"wtong@connect.ust.hk","presenting_author_name":"Wai Tong","title":"Time Walk: Blending Presence and History through AR Visualization","uid":"v-vis-posters-1067"},"v-vis-posters-1068":{"abstract":"Data Videos have emerged as a popular narrative visualization storytelling form for public data communication. The climax of a data video critically presents the most crucial information to the audience. Nonetheless, building an impactful climax requires lots of guidance. The first step is understanding and visualizing the climax as a narrative stage. We draw inspiration from the mathematical theory of the Golden Ratio. Through an iterative coding process, we first analyzed the Rising-Climax of 63 data videos based on the Freytag pyramid structure. Then, we observed the statistics result between the Rising-Climax and the Golden Ratio. The result showed the potential coherence between the Golden Ratio point for data videos and the Rising-Climax point of data videos. We further conducted a case analysis to demonstrate how applying the Golden Ratio to the Rising-Climax sequence in data videos can enhance its construction.","author_affiliations":["Xian Xu: The Hong Kong University of Science and Technology","David Yip: The Hong Kong University of Science and Technology","Huamin Qu: The Hong Kong University of Science and Technology"],"authors":["Xian Xu","David Yip","Huamin Qu"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"xian.xu@connect.ust.hk","presenting_author_name":"Xian Xu","title":"The Golden Ratio in Narrative Structure: Visualizing the Rising-Climax in Data Videos","uid":"v-vis-posters-1068"},"v-vis-posters-1069":{"abstract":"Landslides and geohazards are serious threats to public safety and infrastructure, but public awareness is limited. Situated visualizations can engage audiences, but Augmented Reality (AR) interactions can be challenging. In collaboration with experts, we designed LandSAR, an immersive system that combines AR, terrain models, and tangible interfaces. Users can physically interact with terrain models to learn about landslide risks and perceive geographical properties. LandSAR includes an AR-based landslide simulation to educate users about prevention, precautions, and climate change implications. Evaluation results suggest that LandSAR enhances users' experience, making it promising for disaster management, environmental education, and public outreach initiatives.","author_affiliations":["Haobo Li: The Hong Kong University of Science and Technology","Kentaro Takahira: Department of Computer Science and Engineering, The Hong Kong University of Science and Technology","Kam Kwai Wong: The Hong Kong University of Science and Technology","Leni Yang: The Hong Kong University of Science and Technology","Wai Tong: The Hong Kong University of Science and Technology","Huamin Qu: The Hong Kong University of Science and Technology"],"authors":["Haobo Li","Kentaro Takahira","Kam Kwai Wong","Leni Yang","Wai Tong","Huamin Qu"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"hliem@connect.ust.hk","presenting_author_name":"Haobo Li","title":"Landslide visualization situated on tangible terrain models","uid":"v-vis-posters-1069"},"v-vis-posters-1070":{"abstract":"Upon completion of the design and training phases, the deployment of a deep learning model onto specific hardware is imperative prior to its practical implementation. To augment the model's performance, deployers must engage in targeted optimizations aimed at reducing the model's inference latency. Auto-scheduling, an automated technique that generates a range of optimization options, emerges as a viable solution for large-scale auto-deployment. Nevertheless, the low-level code produced by the auto-scheduling method exhibits a striking resemblance to hardware coding, thereby potentially impeding human comprehension and obstructing future manual optimization endeavors. In this ongoing study, we endeavor to develop an enhanced visualization that effectively caters to the extensive profiling metrics associated with auto-scheduling and sheds light on the intricate scheduling process, thereby enabling further improvements in latency optimization through the application of insights derived from the schedule.","author_affiliations":["Laixin Xie: ShanghaiTech University","Chenyang Zhang: University of Illinois at Urbana-Champaign","Ruofei Ma: ShanghaiTech University","Xing Jiang: Netease Games","Xingxing Xing: Netease Games","Wei Wan: Netease Games UX Center","Quan Li: ShanghaiTech University"],"authors":["Laixin Xie","Chenyang Zhang","Ruofei Ma","Xing Jiang","Xingxing Xing","Wei Wan","Quan Li"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"xielx@shanghaitech.edu.cn","presenting_author_name":"Laixin Xie","title":"Understanding Auto-Scheduling Optimizations for Model Deployment via Visualizations","uid":"v-vis-posters-1070"},"v-vis-posters-1071":{"abstract":"In this study, we conducted a comprehensive analysis of diverse geo-infographics available on the internet, closely examining the specifics of their visual elements. As a result, we formulated a design space that incorporates five key design dimensions: basic map representations, map projections, visual encoding channels, highlighting techniques, and label placement. Through the systematic review and exploration of a multitude of visual design strategies, we aim to provide an overview of visual elements that can be used for crafting compelling geo-infographics. Moreover, this work serves as a stepping stone towards the development of an intelligently assisted generation system tailored for the creation of sophisticated geo-infographics.","author_affiliations":["xinyuan zhang: Xi'an Jiaotong-Liverpool University","yu liu: Xi'an Jiaotong-Liverpool University","Lingyun Yu: Xi'an Jiaotong-Liverpool University"],"authors":["xinyuan zhang","yu liu","Lingyun Yu"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"Yu.Liu02@xjtlu.edu.cn","presenting_author_name":"Yu Liu","title":"Dissecting Geo-Infographics: A Study on Visualizing Geographic Data","uid":"v-vis-posters-1071"},"v-vis-posters-1072":{"abstract":"Diffusion-based generative models\u2019 impressive ability to create convincing images has captured global attention. However, their complex internal structures and operations often make them difficult for non-experts to understand. We present Diffusion Explainer, the first interactive visualization tool that explains how Stable Diffusion transforms text prompts into images. Diffusion Explainer tightly integrates a visual overview of Stable Diffusion\u2019s complex components with detailed explanations of their underlying operations, enabling users to fluidly transition between multiple levels of abstraction through animations and interactive elements. By comparing the evolutions of image representations guided by two related text prompts over refinement timesteps, users can discover the impact of prompts on image generation. Diffusion Explainer runs locally in users\u2019 web browsers without the need for installation or specialized hardware, broadening the public\u2019s education access to modern AI techniques. Our open-sourced tool is available at: https://poloclub.github.io/diffusion-explainer/.","author_affiliations":["Seongmin Lee: Georgia Institute of Technology","Benjamin Hoover: IBM Research AI","Hendrik Strobelt: IBM Research AI","Zijie J. Wang: Georgia Tech","ShengYun Peng: Georgia Institute of Technology","Austin P Wright: Georgia Institute of Technology","Kevin Li: Georgia Institute of Technology","Haekyu Park: Georgia Institute of Technology","Haoyang Yang: Georgia Institute of Technology","Duen Horng Chau: Georgia Tech"],"authors":["Seongmin Lee","Benjamin Hoover","Hendrik Strobelt","Zijie J. Wang","ShengYun Peng","Austin P Wright","Kevin Li","Haekyu Park","Haoyang Yang","Duen Horng Chau"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"seongmin@gatech.edu","presenting_author_name":"Seongmin Lee","title":"Diffusion Explainer: Visual Explanation for Text-to-image Stable Diffusion","uid":"v-vis-posters-1072"},"v-vis-posters-1073":{"abstract":"AI and machine learning models are increasingly integrated into analytical workflows. These models can assist or replace many human-intensive tasks but also alter human-intensive interactions within redesigned workflows. In the context of orthomosaic image segmentation and classification, machine learning is shown to automate key tasks while requiring new interactions and selections from analysts. This work overviews the changing analyst views and interactions needed to leverage emerging machine learning models in orthomosaic analysis workflows.","author_affiliations":["Grace Minai: Grand Valley State University","Denton Bobeldyk: Grand Valley State University","Jonathan P. Leidig: Grand Valley State University"],"authors":["Grace Minai","Denton Bobeldyk","Jonathan P. Leidig"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"leidijon@gvsu.edu","presenting_author_name":"Jonathan Leidig","title":"Incorporating ML in Interaction-Intensive Workflows","uid":"v-vis-posters-1073"},"v-vis-posters-1074":{"abstract":"Management of invasive (target) weed species requires time intensive analyses to test whether potential biocontrol agents will suitably control the target species without affecting important native or horticultural (non-target) species. Native or useful plant species closely related to the target species are prioritised over more distant-ly related species as they are more likely to be ecologically, anatomically, and biochemically similar to the target species and, therefore, at greater risk of being affected by candidate biocontrol agents that have co-evolved. A variety of other factors, such as shared biogeographical ranges, ecological niche overlap and functional trait similarities with the target species also contribute to the risk profile of non-target species in testing. Existing tools for the visualisation of data in an evolutionary context do not provide the functionality required for risk analysis in biocontrol research. We have developed a prototype visualisation tool using the R Shiny package that visualises phylogenetic trees together with a heatmap of metrics and ecological trait data for target and non-target plant species to show the distribution of relevant factors in an evolutionary context. We aim to empower biocontrol researchers to summarise and visualise multiple sources of information, thereby speeding up their test list designs and providing a standard that is comparable to consultation with a phylogenetics expert.","author_affiliations":["Lauren Stevens: CSIRO","Louise Ord: CSIRO","Nunzio Knerr: CSIRO","Ben Gooden: CSIRO","Alexander Schmidt-Lebuhn: CSIRO"],"authors":["Lauren Stevens","Louise Ord","Nunzio Knerr","Ben Gooden","Alexander Schmidt-Lebuhn"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"lauren.stevens@csiro.au","presenting_author_name":"Lauren Stevens","title":"A Prototype Visualisation Tool for Biocontrol Researchers.","uid":"v-vis-posters-1074"},"v-vis-posters-1077":{"abstract":"\"As the metaverse world gradually expands, it is becoming an important concern how realistically we can express digital humans that represent us in the metaverse world. In various industries and research fields, methods for the hyper-realistic expression of digital humans are being actively researched. In this paper, we present a novel face visualization system designed to capture and depict dynamic changes in complexion for creating hyper-realistic digital humans. While complexion is often overlooked as a minor detail, it\u2019s actually an important part of what makes a digital human recognizable as a person. Facial expressions, emotions, and bio-signals collaboratively influence facial blood flow, resulting in noticeable variations in facial color. By integrating real-time reflection of these intricate components and visualizing them on the digital human\u2019s face, we successfully infuse vitality and realism into the digital human representation\"","author_affiliations":["younghee kim: Electronics and Telecommunications Research Institute","Woo Jin Jeon: Electronics and Telecommunications Research Institute","Kwanghyun Shim: Electronics and Telecommunications Research Institute"],"authors":["younghee kim","Woo Jin Jeon","Kwanghyun Shim"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"yheekim@etri.re.kr","presenting_author_name":"YoungHee Kim","title":"Visualization of Complexion for Photo-Realistic Facial Expressions","uid":"v-vis-posters-1077"},"v-vis-posters-1078":{"abstract":"\"When reconstructing a space into a 3D volume using imagery, there exist various techniques for comparing the original 3D volume model with the reconstructed one. However, these methods lack the ability to provide an accurate numerical representation of the error between the two volume models. Additionally, existing visualization methods tend to emphasize errors in the x and y directions rather than the depth direction. To address these limitations, this paper presents a novel error measurement method and visualization approach that utilize the 3D vertices of the depth map. The proposed method ensures a consistent error measurement irrespective of the camera's viewpoint and enables accurate visualization of errors occurring in the x and y directions within the restored volume model. The effectiveness of our methods is demonstrated through experimental evaluations.\"","author_affiliations":["Man Hee Lee: Electronics and Telecommunications Research Institute","Chang Joon Park: Electronics and Telecommunications Research Institute"],"authors":["Man Hee Lee","Chang Joon Park"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"mheelee@etri.re.kr","presenting_author_name":"Man Hee Lee","title":"Error Measurement and Visualization in 3D Volume Data","uid":"v-vis-posters-1078"},"v-vis-posters-1079":{"abstract":"With the growth of data sizes, visualizing them becomes more complex. Desktop displays are insufficient for presenting and collaborating on complex data visualizations. Large displays could provide the necessary space to demo or present complex data visualizations. However, designing and developing visualizations for such displays pose distinct challenges. Identifying these challenges is essential for researchers, designers, and developers in the field of data visualization. In this study, we aim to gain insights into the challenges encountered by designers and developers when creating data visualizations for large displays. We conducted a series of semi-structured interviews with experts who had experience in large displays and, through affinity diagramming, categorized the challenges.","author_affiliations":["Mahsa Sinaei: Carleton University","Pak Kwan: University of Cincinnati","Matthew Klich: University of Cincinnati","Jillian Aurisano: University of Cincinnati","Fateme Rajabiyazdi: Carleton University"],"authors":["Mahsa Sinaei","Pak Kwan","Matthew Klich","Jillian Aurisano","Fateme Rajabiyazdi"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"fateme.rajabiyazdi@carleton.ca","presenting_author_name":"Fateme Rajabiyazdi","title":"Identifying Challenges in Designing, Developing and Evaluating Data Visualizations for Large Displays","uid":"v-vis-posters-1079"},"v-vis-posters-1080":{"abstract":"Nosocomial infections (or healthcare-associated infections) can greatly affect public health. The prevention and control of nosocomial infections rely on effective training of medical personnel on the correct use of personal prevention equipment (PPE). We introduce a virtual reality (VR) method that simulates the real environment of a hospital and supports repeated immersive practice of PPE donning and doffing. A VR prototype is created and receives positive feedback from a domain expert. The effectiveness of our method will be evaluated in a comparative user study.","author_affiliations":["Mengjie Fan: Peking University","Shaoxing Zhang: Peking University Third Hospital","Xintian Zhao: Peking University Third Hospital","Xingyao Yu: University of Stuttgart","Liang Zhou: Peking University"],"authors":["Mengjie Fan","Shaoxing Zhang","Xintian Zhao","Xingyao Yu","Liang Zhou"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"mengjiefan@bjmu.edu.cn","presenting_author_name":"Mengjie Fan","title":"Virtual Reality Training for Nosocomial Infections Prevention","uid":"v-vis-posters-1080"},"v-vis-posters-1082":{"abstract":"Multiplayer Online Battle Arenas (MOBAs) have gained a significant player base worldwide, generating over two billion US dollars in annual game revenue. However, the presence of griefers, who deliberately irritate and harass other players within the game, can have a detrimental impact on players' experience, compromising game fairness and potentially leading to the emergence of gray industries. Unfortunately, the absence of a standardized criterion, and the lack of high-quality labeled and annotated data has made it challenging to detect the presence of griefers. Given the complexity of the multi-variant spatiotemporal data for MOBA games, game developers heavily rely on manual review of entire game video recordings to label and annotate griefers, which is a time-consuming process. To alleviate this issue, we have collaborated with a team of game specialists to develop an interactive visual analysis interface, called GrieferLens. It overviews players' behavior analysis and synthesizes their key match events. By presenting multiple views of information, GrieferLens can help the game design team efficiently recognize and label griefers in MOBA games and build up a foundation for creating a more enjoyable and fair gameplay environment.","author_affiliations":["Zixin Chen: The Hong Kong University of Science and Technology","Shiyi Liu: ShanghaiTech University","Zhihua Jin: Hong Kong University of Science and Technology","Gaoping Huang: Tencent","Yang Chao: Tencent","ZHENCHUAN YANG: Tencent","Quan Li: ShanghaiTech University","Huamin Qu: The Hong Kong University of Science and Technology"],"authors":["Zixin Chen","Shiyi Liu","Zhihua Jin","Gaoping Huang","Yang Chao","ZHENCHUAN YANG","Quan Li","Huamin Qu"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"liushy@shanghaitech.edu.cn","presenting_author_name":"LIU Shiyi","title":"Towards an Exploratory Visual Analytics System for Griefer Identification in MOBA Games","uid":"v-vis-posters-1082"},"v-vis-posters-1083":{"abstract":"Visualizations are widely used to compare aggregate statistics between subsets of data. However, aggregation can often obscure patterns or trends and produce misleading views of the data. One example of this risk is Simpson's Paradox, a phenomenon that can commonly occur in interactive data visualizations that enable ad hoc grouping and filtering. We explore the potential of counterfactuals---widely used in causal inference---to help counter the risks of invalid conclusions due to Simpson's Paradox in data visualization.","author_affiliations":["Arran Zeyu Wang: University of North Carolina-Chapel Hill","David Borland: UNC-Chapel Hill","David Gotz: University of North Carolina"],"authors":["Arran Zeyu Wang","David Borland","David Gotz"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"zeyuwang@cs.unc.edu","presenting_author_name":"Arran Zeyu Wang","title":"Countering Simpson\u2019s Paradox with Counterfactuals","uid":"v-vis-posters-1083"},"v-vis-posters-1085":{"abstract":"Social Media platforms (e.g., Twitter, Facebook, etc.) are used heavily by public to provide news, opinions, and reactions towards events or topics. Integrating such data with the event or topic factual data could provide a more comprehensive understanding of the underlying event or topic. Targeting this, we present our visual analytics tool, called VC-FaT, that integrates peoples' tweet data regarding crimes in San Francisco city with the city factual crime data. VC-FaT provides a number of interactive visualizations using both data sources for better understanding and exploration of crime activities happened in the city during a period of five years.","author_affiliations":["snehal patil: San Francisco State University","Shah Rukh Humayoun: San Francisco State University"],"authors":["snehal patil","Shah Rukh Humayoun"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"humayoun@sfsu.edu","presenting_author_name":"Shah Rukh Humayoun","title":"A Visual Analytic Environment to Co-locate Peoples\u2019 Tweets with City Factual Data","uid":"v-vis-posters-1085"},"v-vis-posters-1086":{"abstract":"Visualizing event timelines for collaborative text writing is instrumental for navigating and understanding this type of data, as the size and complexity of both text and timelines increase. They are often employed by applications such as code repositories and collaborative text editors. In this poster, we present a visualization approach to explore historical records from the writing of legislative texts, which were discussed and voted on by assemblies of representatives. Focusing on event timelines from text documents that involve multiple people and different topics, we allow for exploring the history of text changes and tracking the provenance of given text sections, while highlighting the connections between all elements involved.","author_affiliations":["Gabriel Dias Cantareira: King's College London","Yiwen Xing: King's College London","Nicholas Cole: University of Oxford","Rita Borgo: Kings College London","Alfie Abdul-Rahman: King's College London"],"authors":["Gabriel Dias Cantareira","Yiwen Xing","Nicholas Cole","Rita Borgo","Alfie Abdul-Rahman"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"gabriel.dias_cantareira@kcl.ac.uk","presenting_author_name":"Gabriel Dias Cantareira","title":"Hierarchical Timeline Exploration for Collaborative Text Writing","uid":"v-vis-posters-1086"},"v-vis-posters-1087":{"abstract":"\"We introduce the concept of a meta design study as a structured approach to extract information from design study papers for the development of generalized tools in specific problem areas or domains. We explore the potential of meta design studies for creating domain-oriented visualization recommendation (VisRec) strategies. To demonstrate this concept, we present RSVP, a system derived from a meta design study conducted on Visual Parameter Space Analysis (VPSA). We outline the individual steps of the meta-design study, highlight key concepts of the resulting VisRec strategy, and present a non-obtrusive implementation of this approach in RSVP.\"","author_affiliations":["Manfred Klaffenboeck: TU Wien","Torsten M\u00f6ller: University of Vienna","Michael Gleicher: University of Wisconsin - Madison","Michael Wimmer: TU Wien"],"authors":["Manfred Klaffenboeck","Torsten M\u00f6ller","Michael Gleicher","Michael Wimmer"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"Manfred Klaffenboeck","presenting_author_name":"Manfred Klaffenboeck","title":"Meta Design Studies : A Structured Approach for Deriving Domain-Orientied Visualization Recommendation Strategies","uid":"v-vis-posters-1087"},"v-vis-posters-1088":{"abstract":"For visualisation applications, Immersive Virtual Reality (VR) environments can present information in an arbitrarily large space, overcoming the traditional constraints of screen space or even physical space limitations. However, interacting with distant objects within the virtual space presents an interaction and usability challenge. Current research primarily focuses on evaluating the feasibility of techniques, which may involve compromises in interaction accuracy or necessitate adjustments to the relative position or scale of target objects. We thus introduce a novel interaction method that enables precise remote interactions without requiring changes to the relative position and scale of the user's point of view in the virtual environment. Additionally, we have developed several variations of our approach and designed a controlled experiment to assess the subjective ranking of these representations and performance differences across multiple scenarios.","author_affiliations":["Shaozhang Dai: Monash University","Tim Dwyer: Monash University","Barrett Ens: Monash University","Lonni Besan\u00e7on: Link\u00f6ping University"],"authors":["Shaozhang Dai","Tim Dwyer","Barrett Ens","Lonni Besan\u00e7on"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"shaozhang.dai1@monash.edu","presenting_author_name":"Shaozhang Dai","title":"Reaching for Data: precise embodied selection-at-a-distance for immersive visualisation","uid":"v-vis-posters-1088"},"v-vis-posters-1089":{"abstract":"This work presents a preliminary design space for immersive data storytelling that is informed by multi-disciplinary views and current practice. We interviewed experts across multiple disciplines,including museum designers, architectures, and game designers, to understand how they communicate stories through real and virtual immersive mediums. We used the interviews to inform the dimensions of the design space and analysed a systematic selection of publicly available immersive stories. Our design spaces consists of 13 dimensions across 7 categories. We present insights into this design space as common practice or areas for future research","author_affiliations":["Radhika Jain: University of South Australia","Kadek Ananta Satriadi: Monash University","Ross Smith: University of South Australia","Andrew Cunningham: University of South Australia"],"authors":["Radhika Jain","Kadek Ananta Satriadi","Ross Smith","Andrew Cunningham"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"radhika.jain@mymail.unisa.edu.au","presenting_author_name":"Radhika Pankaj Jain","title":"A Preliminary Design Space for Immersive Data Storytelling","uid":"v-vis-posters-1089"},"v-vis-posters-1090":{"abstract":"Data visualization is useful for data-driven decision making but it is sensitive to perceptual and cognitive biases, which may lead to distorted conclusions and actions. Since data presentations are commonly shown in temporally sequential order, this study aims at identifying how chart sequences affect data perception and interpretation. We conducted an online survey with two stories in chart sequences which had two charts of either positive or negative polarity. The interplay of chart sequences and their accompanying stories seemed to have an impact on data perception. Certain conditions led to statistically significant perceptual differences. This study can be extended for future research aimed at developing guidelines for effective business presentations or data storytelling.","author_affiliations":["Watcharich Sriswasdi: Chulalongkorn University","Prawit Banjong: Chulalongkorn University","Puripant Ruchikachorn: Chulalongkorn University"],"authors":["Watcharich Sriswasdi","Prawit Banjong","Puripant Ruchikachorn"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"puripant@cbs.chula.ac.th","presenting_author_name":"Puripant Ruchikachorn","title":"Good News or Bad News First: Bias from Visualization Sequences","uid":"v-vis-posters-1090"},"v-vis-posters-1091":{"abstract":"Visual exploration of multi-classification models with large number of classes would help machine learning experts in identifying the root cause of a problem that occurs during learning phase such as miss-classification of instances. Most of the previous visual analytics solutions targeted only a few classes. In this paper, we present our interactive visual analytics tool, called MultiCaM-Vis, that provides overview+detail style parallel coordinate views and a Chord diagram for exploration and inspection of class-level miss-classification of instances. We also present results of a preliminary user study with 12 participants.","author_affiliations":["Syed Ahsan Ali Dilawer: University of Kaiserslautern","Shah Rukh Humayoun: San Francisco State University"],"authors":["Syed Ahsan Ali Dilawer","Shah Rukh Humayoun"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"humayoun@sfsu.edu","presenting_author_name":"Shah Rukh Humayoun","title":"MultiCaM-Vis: Visual Exploration of Multi-Classification Model with High Number of Classes","uid":"v-vis-posters-1091"},"v-vis-posters-1093":{"abstract":"In this study, we investigate the intersection of narrative theory and data visualisation in the realm of news media. We present a comprehensive exploration of the narrative construction mechanisms and the efficacy of visualisation techniques in conveying news stories. A novel method is introduced to extract and visualize narratives from large corpora of news articles. We compare two visualisation techniques applied under different information levels to ascertain the nuanced ways in which narratives shape our comprehension and interpretation of news. Furthermore, we examine how visual aids can enhance or distort these narratives. The results of this research could offer fresh insights into how we decode and engage with the dense information landscape prevalent in modern news media.","author_affiliations":["Songhai Fan: Monash University","Ying Yang: Monash University","Sarah Goodwin: Monash University","Helen C. Purchase: Monash University","Tim Dwyer: Monash University","Simon D Angus: Monash University"],"authors":["Songhai Fan","Ying Yang","Sarah Goodwin","Helen C. Purchase","Tim Dwyer","Simon D Angus"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"songhai.fan@monash.edu","presenting_author_name":"Songhai Fan","title":"Understanding the Narrative: An Exploration of Narrative Structure and Visualisation Techniques in News Media","uid":"v-vis-posters-1093"},"v-vis-posters-1094":{"abstract":"Debate is a crucial process where participants exchange diverse perspectives and information, culminating in a reasoned conclusion. The task of understanding and analyzing the arguments that emerge during this process can be complex and challenging. To mitigate these challenges, we propose a visualization interface that intuitively illustrates the relationship between contentious sections and key debate points within a debate. The co-occurrence matrix identifies controversial sections, while the speech section graph highlights the primary contentious keywords in their respective contexts. Furthermore, the bar chart displays the frequency of arguments from both pros and cons positions within a contentious section. The circle packing provides a hierarchical representation of issues within a topic, showcasing and comparing the topical keywords between significant pros and cons groups. Through this system, we anticipate that users will be able to visualize the structure and flow of the argument at a glance, thereby facilitating a more comprehensive understanding of the entire debate.","author_affiliations":["Kwanghyuk Moon: Ajou University","Hyoji Ha: Sogang University","Kyungwon Lee: Ajou university"],"authors":["Kwanghyuk Moon","Hyoji Ha","Kyungwon Lee"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"moonspl@ajou.ac.kr","presenting_author_name":"Kwanghyuk Moon","title":"Towards Better Understanding: Proposing Effective Visualization Methods for Analyzing Argument in Debate","uid":"v-vis-posters-1094"},"v-vis-posters-1095":{"abstract":"Uncertainty visualisation is needed to communicate the risk associated with estimates and facilitate decision-making. The best visual encoding of uncertainty information relies on accurate estimation and appropriate depiction. While there is a reasonable amount of research into estimating uncertainty, effective visual representations of uncertainty are not as well researched. We believe this is primarily driven by a lack of consensus on how to assess the information depicted in a visualisation.  We present a work-in-progress taxonomy that can be used to evaluate the information in a graphic.","author_affiliations":["Harriet Mason: Monash University","Di Cook: Monash University","Emi Tanaka: Australian National University","Sarah Goodwin: Monash University","Ursula Laa: University of Natural Resources and Life Sciences"],"authors":["Harriet Mason","Di Cook","Emi Tanaka","Sarah Goodwin","Ursula Laa"],"discord_channel":"","event":"VIS Posters","event_prefix":"v-vis-posters","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"harriet.mason1@monash.edu","presenting_author_name":"Harriet Mason","title":"Plotting Apples, Oranges, and Distributions","uid":"v-vis-posters-1095"},"w-cityvis-1013":{"abstract":"The process of geospatial data aggregation provides a means for abstracting the complexity of urban systems to not just better understand them, but also protect the privacy of the individuals within them. However, level of aggregation and the arbitrary sizes, shapes, and arrangements of areal units may lead to statistical and visual bias that affects the reliability and validity of findings derived from the analysis of areally aggregated urban data. This bias and resulting analytical uncertainty \u2013 known as the Modifiable Areal Unit Problem (MAUP) \u2013 has implications for public policy implementation and allocation of critical resources in both urban and rural areas. Despite a wealth of geographic research on MAUP and development of advanced statistical approaches to quantifying its effects, many of these insights and techniques remain largely inaccessible and subsequently unadopted by GIS professionals working on city planning applications. This paper introduces a simple vector-to-raster choropleth mapping workflow that enables a broad range of urban analysts to visually assess the scalar effects of the modifiable areal unit problem.","author_affiliations":["Jonathan K Nelson: University of Wisconsin-Madison"],"authors":["Jonathan K Nelson"],"discord_channel":"","event":"CityVis","event_prefix":"w-cityvis","has_image":false,"has_poster_pdf":false,"has_summary_pdf":false,"presenting_author_email":"jknelson3@wisc.edu","presenting_author_name":"Jonathan Nelson","title":"Visualizing Scalar Effects of Urban Data Aggregation","uid":"w-cityvis-1013"},"w-cityvis-1014":{"abstract":"Sustainable mobility is crucial in our current era. Our proposed interactive web application provides a user-friendly way to evaluate public transport networks and analyze how well connected a user defined location is. The current implementation comprises data from all Austrian public transport systems but can be extended with data from any provider. We made the code available on github: github.com/jku-vds-lab/publictransport. The tool can be tested in the deployed version: publictransport.jku-vds-lab.at.","author_affiliations":["Markus Trainer: Johannes Kepler University Linz","Christina Humer: Johannes Kepler University Linz","Patrick Adelberger: Johannes Kepler University Linz","Marc Streit: Johannes Kepler University Linz"],"authors":["Markus Trainer","Christina Humer","Patrick Adelberger","Marc Streit"],"discord_channel":"","event":"CityVis","event_prefix":"w-cityvis","has_image":false,"has_poster_pdf":true,"has_summary_pdf":false,"presenting_author_email":"markustrainer000@gmail.com","presenting_author_name":"Markus Trainer","title":"How Far Can Public Transport Take You?","uid":"w-cityvis-1014"},"w-cityvis-1017":{"abstract":"In this study, we explore, through co-creation, how Australian cities might incorporate a people-centred data governance ecosystem. We use CLDs (1) during interviews to elicit perspectives from various stakeholders in cities regarding the current state of data governance and (2) during workshops for solution ideation. In this work we focus on the multiplicity of perspectives regarding DG in Australian cities. We aim to co-create a conceptual model of the status quo of data governance and explore solutions to achieve people-centred DG. An interactive visualisation of the model will showcase the diversity of perspectives, delineate the power dynamics underpinning data governance in Australian cities in an accessible manner, and portray people-centred solutions.","author_affiliations":["Jessica Bou Nassar: Monash University","Sarah Goodwin: Monash University","Lyn Bartram: Simon Fraser University","Darren Sharp: Monash University","misita anwar: Monash University"],"authors":["Jessica Bou Nassar","Sarah Goodwin","Lyn Bartram","Darren Sharp","misita anwar"],"discord_channel":"","event":"CityVis","event_prefix":"w-cityvis","has_image":false,"has_poster_pdf":false,"has_summary_pdf":false,"presenting_author_email":"jessica.bounassar@monash.edu","presenting_author_name":"Jessica Bou Nassar","title":"The Use of Causal Loop Diagrams to Explore People-Centred Data Governance in Australian Cities","uid":"w-cityvis-1017"},"w-energyvis-1001":{"abstract":"Electrical grids are geographical and topological structures whose voltage states are challenging to represent accurately and efficiently for visual analysis. The current common practice is to use colored contour maps, yet these can misrepresent the data. We examine the suitability of four alternative visualization methods for depicting voltage data in a geographically dense distribution system\u2014Voronoi polygons, H3 tessellations, S2 tessellations, and a network-weighted contour map. We find that Voronoi tessellations and network-weighted contour maps more accurately represent the statistical distribution of the data than regular contour maps.","author_affiliations":[],"authors":["Isaiah Lyons-Galante","Morteza Karimzadeh","Sam Molnar","Graham Johnson","Kenny Gruchalla"],"discord_channel":"","event":"EnergyVis papers","event_prefix":"w-energyvis","has_image":false,"has_poster_pdf":true,"has_summary_pdf":false,"presenting_author_email":"isaiah.lyons-galante@colorado.edu","presenting_author_name":"Isaiah Lyons-Galante","title":"Alternatives to Contour Visualizations for Power Systems Data","uid":"w-energyvis-1001"},"w-energyvis-1005":{"abstract":"Immersive experiences can increase engagement and improve data understanding. We explore the use of virtual reality to visualise the complexities of electric networks and facilitate a greater understand- ing of net zero initiatives. We propose that an abstract metaphorical immersive experience can provide an intuitive overview of the complex components of energy networks and how they behave over time in response to fluctuating supply and demand in order to achieve stability and sustainability. This work aims to enable a variety of stakeholders to better understand and associate the complexities in the systems and be aware of the connections over time and space. Using the Monash University electric network system as a case study, we explore the network dynamics and fluctuations over time. The virtual reality experience allows users to view campus electricity assets and local and remote energy sources, as well as witness the dynamics of the network. Thus, the complexities of the energy system and its impact on sustainability can be more readily understood.","author_affiliations":[],"authors":["Amal Alshardy","Sarah Goodwin","Andres Santos-Torres","Ariel Liebman"],"discord_channel":"","event":"EnergyVis papers","event_prefix":"w-energyvis","has_image":false,"has_poster_pdf":true,"has_summary_pdf":false,"presenting_author_email":"ahshardy@uqu.edu.sa","presenting_author_name":"Mrs Amal Hussain Alshardy","title":"Virtual Reality for Enhancing Engagement with Net Zero Transitions","uid":"w-energyvis-1005"},"w-energyvis-1008":{"abstract":"This paper introduces an interactive visualisation that combines a spatial element to the single line diagram (SLD). SLDs are conceptual maps of the power network used by power engineers to understand the connectivity between assets of the network, study power flow, and maintain grid stability and security. Enabling users with varying degrees of electrical knowledge to understand the geographical aspect of the SLD was the key design goal. Developed through an iterative process, the visualisation intuitively transitions from an SLD view to a map view. Evaluation of the visualisation during, and following development revealed that the prototype was well-liked and that having a spatial element to the SLD was useful in understanding the geographical relationships in the power network. The evaluation also helped identify stakeholders with an interest in the hybrid view and showed the prototype\u2019s potential utility in communicating technical data to electrical non-technical users.","author_affiliations":[],"authors":["Merry Hoang","Sarah Goodwin","Michael Wybrow","Ying Yang"],"discord_channel":"","event":"EnergyVis papers","event_prefix":"w-energyvis","has_image":false,"has_poster_pdf":true,"has_summary_pdf":false,"presenting_author_email":"sarah.goodwin@monash.edu","presenting_author_name":"Sarah Goodwin","title":"Exploring the Benefits of Geography on Power Network Diagrams","uid":"w-energyvis-1008"},"w-vahc-2982":{"abstract":"Combining clinical and omics data can improve both daily clinical routines and research to gain more insights into complex medical procedures. We present the results of our first phase in a multi-year collaboration with analysts and physicians aiming at improved inter-disciplinary biomarker identification. We also outline our user-centered approach along its challenges, describe the intermediate technical artifacts that serve as a basis for summative and formative evaluation for the second project phase. Finally, we sketch the road ahead and how we intend to combine visualization research with user-centered design through problem-based prioritization.","author_affiliations":[],"authors":["Markus H\u00f6hn","Hendrik L\u00fccke-Tieke","Jan Burmeister","J\u00f6rn Kohlhammer"],"discord_channel":"","event":"VAHC","event_prefix":"w-vahc","has_image":false,"has_poster_pdf":false,"has_summary_pdf":true,"presenting_author_email":"markus.hoehn@igd.fraunhofer.de","presenting_author_name":"Markus H\u00f6hn","title":"Towards medhub: A Self-Service Platform for Analysts and Physicians","uid":"w-vahc-2982"},"w-vahc-3479":{"abstract":"Metastatic hormone-producing tumors have characteristics of both tumors and endocrine disorders with many time-series parameters. Therefore, making treatment decisions is often challenging. Data visualization methods have recently been developed to visualize time series, single or multiple pieces of information, and complex patient information. We focused on metastatic pheochromocytoma and paraganglioma and summarized the clinical needs and dashboard data visualization ideas for precision medicine.","author_affiliations":[],"authors":["Masaki Uchihara","Akiyo Tanabe","Hiroshi Kajio"],"discord_channel":"","event":"VAHC","event_prefix":"w-vahc","has_image":false,"has_poster_pdf":true,"has_summary_pdf":true,"presenting_author_email":"muchihara@hosp.ncgm.go.jp","presenting_author_name":"Masaki Uchihara","title":"Clinical Issues and Suggestions: Dashboard Visualization of the Trajectory of Patients with Malignant Hormone-Producing Tumors for Precision Medicine","uid":"w-vahc-3479"},"w-vahc-4703":{"abstract":"Electronic health records (EHRs), serving as patient-centered repositories for medical data, offer the opportunity for researchers to uncover concealed patterns using machine learning (ML). However, in real-world medical settings, clinicians often face the task of selecting pertinent feature dimensions from a range of potential medical metrics and then deducing potential labels from vague diagnostic descriptions, prior to the modeling phase. This complexity presents challenges in obtaining reliable training/testing data and conducting thorough analysis. Consequently, these hurdles hinder the practical application of ML for automated modeling and comprehensible interpretation of influencing factors. To tackle these challenges, we introduce a visual analytics approach designed to navigate the feature and label space within EHRs, while also streamlining the modeling process through automated ML algorithms and techniques for improved interpretability.","author_affiliations":[],"authors":["He Wang","Yang Ouyang","Quan Li"],"discord_channel":"","event":"VAHC","event_prefix":"w-vahc","has_image":false,"has_poster_pdf":false,"has_summary_pdf":true,"presenting_author_email":"wanghe1@shanghaitech.edu.cn","presenting_author_name":"He Wang","title":"A Visual Analytics Approach to Exploring the Feature and Label Space Based on Semi-structured Electronic Medical Records","uid":"w-vahc-4703"},"w-vahc-6912":{"abstract":"Mental health care and monitoring are important. Advancements in smart home sensing technology also make tracking people\u2019s activities easy in the home, enabling the monitoring of mental health more effectively. Some related works have demonstrated the possibilities of mental health monitoring using sensor data collected in smart homes.  However, there is a lack of prior research on how to effectively utilize smart home data visualization to help people understand how their everyday behaviors are related to their mental health status. This poster presents a case study on data visualization for mental health monitoring in a smart home environment. Our web-based application allows users to browse their self-reported mental health states and home activities and visualize the correlation between mental health states and home activities.","author_affiliations":[],"authors":["Youngji Koh","Chanhee Lee","Yunhee Ku","Uichin Lee"],"discord_channel":"","event":"VAHC","event_prefix":"w-vahc","has_image":false,"has_poster_pdf":false,"has_summary_pdf":true,"presenting_author_email":"youngji@kaist.ac.kr","presenting_author_name":"Youngji Koh","title":"Data Visualization for Mental Health Monitoring in Smart Home Environment: A Case Study","uid":"w-vahc-6912"},"w-vahc-9996":{"abstract":"This demo paper introduces the final version of a cohort analysis module for the support of treating patients with inflammatory bowel disease (IBD). It is not trivial to correctly diagnose the specific IBD in patients, and wrongly treated patients have to endure the disease effects for a long time, with large costs for the individuals and the healthcare systems. The goal of this work is complementing the examination of individual patients with interactive analyses of cohorts and populations with similar disease patterns to support learning from such similarities for future treatments. We report on additional data and functionality compared to 2021 and discuss an evaluation with eight IBD experts.","author_affiliations":[],"authors":["David Sessler","Salmah Ahmad","J\u00f6rn Kohlhammer"],"discord_channel":"","event":"VAHC","event_prefix":"w-vahc","has_image":false,"has_poster_pdf":false,"has_summary_pdf":true,"presenting_author_email":"joern.kohlhammer@igd.fraunhofer.de","presenting_author_name":"J\u00f6rn Kohlhammer","title":"Demo: Cohort Visualization and Analysis of Patients with Inflammatory Bowel Disease","uid":"w-vahc-9996"}}
