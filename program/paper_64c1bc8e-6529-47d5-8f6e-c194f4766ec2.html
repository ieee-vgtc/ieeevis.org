<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/2.1/auth0-spa-js.production.js"></script><script>
              const auth0_domain = "ieeevis.us.auth0.com";
              const auth0_client_id = "oF5BXUklWOjSjUeg5Tzai2DysHITXYhT";
            </script><script src="/static/2025/js/modules/auth0protect.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2025/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2025/js/data/persistor.js"></script><script src="/static/2025/js/data/api.js"></script><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2025/css/Zilla.css" rel="stylesheet"><link href="/static/2025/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2025/css/main.css"><link rel="stylesheet" href="/static/2025/css/fa_solid.css"><link rel="stylesheet" href="/static/2025/css/lazy_load.css"><link rel="stylesheet" href="/static/2025/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2025 - Paper: Texture Semantics is Robust to Scaling"><meta name="twitter:description" content="Studies of visual semantics for information visualization aim to understand observers’ expectations about the meaning of visual features (e.g., color, texture) because visualizations that align with those expectations are easier to interpret. Previous work on visual semantics focused primarily on color, with the implicit assumption that color semantics is unaffected by changes in the size of the visualization (given sufficient perceptual discriminability across sizes). Changing size from small scale (e.g., small figures in a paper) to large scale (e.g., large figures in a slide presentation) is straightforward for visualizations that have solid colored regions, but can be more complicated for visualizations with heterogeneous textures because there are multiple ways to scale textures—zooming or repeating texture elements. Previous work suggested that original textures were more perceptually similar to repeat-scaled rather than zoom-scaled textures. Here, we found that texture semantics was preserved after both types of enlargement, suggesting that texture semantics is robust to scaling, at least for geometric textures in which elements are visible at all scales."><meta name="twitter:image" content="https://cdn.tech.ieeevis.org/vis2025/v-short/1227.png"><meta name="image" property="og:image" content="https://cdn.tech.ieeevis.org/vis2025/v-short/1227.png"><meta name="description" property="og:description" content="Studies of visual semantics for information visualization aim to understand observers’ expectations about the meaning of visual features (e.g., color, texture) because visualizations that align with those expectations are easier to interpret. Previous work on visual semantics focused primarily on color, with the implicit assumption that color semantics is unaffected by changes in the size of the visualization (given sufficient perceptual discriminability across sizes). Changing size from small scale (e.g., small figures in a paper) to large scale (e.g., large figures in a slide presentation) is straightforward for visualizations that have solid colored regions, but can be more complicated for visualizations with heterogeneous textures because there are multiple ways to scale textures—zooming or repeating texture elements. Previous work suggested that original textures were more perceptually similar to repeat-scaled rather than zoom-scaled textures. Here, we found that texture semantics was preserved after both types of enlargement, suggesting that texture semantics is robust to scaling, at least for geometric textures in which elements are visible at all scales."><meta name="title" property="og:title" content="Virtual IEEE VIS 2025 - Paper: Texture Semantics is Robust to Scaling"><meta property="og:type" content="website"><title>IEEE VIS 2025 Content: Texture Semantics is Robust to Scaling</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style="display: none;"><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-12"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="event_v-short.html">VIS Short Papers</a></li><li class="breadcrumb-item"><a href="session_short7.html">Perception &amp; Semantics</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">Texture Semantics is Robust to Scaling</li></ol></nav><h1 class="paper-title">Texture Semantics is Robust to Scaling</h1><div class="checkbox-bookmark fas" style="font-size: 24pt;position: absolute; top:10px; right:20px;" data-tippy-content="(un-)bookmark this paper"> &#xf02e; </div><h4 class="paper-authors pb-2 mt-2"><span class="fas mr-1">&#xf183;</span> Zoe S. Howard - </h4><h4 class="paper-authors pb-2 mt-2"><span class="fas mr-1">&#xf183;</span> Karen B. Schloss - </h4><div class="row my-3"><div class="col-md-8"><figure class="figure"><img class="figure-img img-fluid" src="https://cdn.tech.ieeevis.org/vis2025/v-short/1227.png" alt="Image not found" aria-describedby="figure-caption"></figure></div></div><h5 class="paper-link pb-2"><a href="https://osf.io/preprints/osf/4uadx_v1" target="_blank"><span class="fas mr-1" title="This paper has an author's preprint available online.">&#xf09c;</span> Download preprint PDF </a></h5><h5 class="paper-link pb-2"><a href="https://data.tech.ieeevis.org/storage/v1/object/sign/vis2025/pdf-files/v-short/1227-doc.pdf?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1cmwiOiJ2aXMyMDI1L3BkZi1maWxlcy92LXNob3J0LzEyMjctZG9jLnBkZiIsImlhdCI6MTc2MDk0NjU2NSwiZXhwIjoxNzkyNDgyNTY1fQ.JmYrtOadvstpBJ62cBZyvrjV5bY_UT6U0jv2eRbDCrM" target="_blank"><span class="fas mr-1">&#xf15c;</span> Download camera-ready PDF </a></h5><h5 class="paper-link pb-2"><a href="https://osf.io/s7ghe/?view_only=66b92b5dd3e74ee3a231e9b4c9e786a6" target="_blank"><span class="fas mr-1" title="This paper has additional material, like demos or experimental data, available online.">&#xf0c6;</span> Download Supplemental Material </a></h5><h3 class="session-room mt-4"> Room: Room 1.14 </h3><h5 class="paper-presentation pb-2"><span class="format-date">2025-11-06T15:39:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2025-11-06T15:39:00.000Z</span><span class="current-time tztooltiptext"></span></span></h5></div></div><div class="row my-3"><div class="col-md-8"></div></div><div class="row my-3"><div class="col-md-8"><h5 class="paper-details-heading">Keywords</h5><p>information visualization, perceptual semantics, visual reasoning, texture perception, visual communication</p><h5 class="paper-details-heading">Abstract</h5><p>Studies of visual semantics for information visualization aim to understand observers’ expectations about the meaning of visual features (e.g., color, texture) because visualizations that align with those expectations are easier to interpret. Previous work on visual semantics focused primarily on color, with the implicit assumption that color semantics is unaffected by changes in the size of the visualization (given sufficient perceptual discriminability across sizes). Changing size from small scale (e.g., small figures in a paper) to large scale (e.g., large figures in a slide presentation) is straightforward for visualizations that have solid colored regions, but can be more complicated for visualizations with heterogeneous textures because there are multiple ways to scale textures—zooming or repeating texture elements. Previous work suggested that original textures were more perceptually similar to repeat-scaled rather than zoom-scaled textures. Here, we found that texture semantics was preserved after both types of enlargement, suggesting that texture semantics is robust to scaling, at least for geometric textures in which elements are visible at all scales.</p></div></div><script lang="js">
      const paperID = "64c1bc8e-6529-47d5-8f6e-c194f4766ec2"
      $(document).ready(() => {
        tippy('[data-tippy-content]');

        const allBookmarks =
          d3.selectAll('.checkbox-bookmark')
            .on("click", function () {
              const newValue = !d3.select(this).classed('selected');
              API.markSet(API.storeIDs.bookmarked, paperID, newValue);
              d3.select(this).classed('selected', newValue);
            })
        API.markGet(API.storeIDs.bookmarked, paperID).then(is_bookmarked => {
          is_bookmarked = !!is_bookmarked;
          allBookmarks.classed('selected', is_bookmarked);
        })
        API.markSet(API.storeIDs.visited, paperID, true);

      })

    </script><script src="/static/2025/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script></body></html>