<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/2.1/auth0-spa-js.production.js"></script><script>
              const auth0_domain = "ieeevis.us.auth0.com";
              const auth0_client_id = "oF5BXUklWOjSjUeg5Tzai2DysHITXYhT";
            </script><script src="/static/2025/js/modules/auth0protect.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2025/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2025/js/data/persistor.js"></script><script src="/static/2025/js/data/api.js"></script><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2025/css/Zilla.css" rel="stylesheet"><link href="/static/2025/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2025/css/main.css"><link rel="stylesheet" href="/static/2025/css/fa_solid.css"><link rel="stylesheet" href="/static/2025/css/lazy_load.css"><link rel="stylesheet" href="/static/2025/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2025 - Session: VIS Full Papers: Visualization Literacy"><meta name="twitter:description" content="See the session and its presentations inside."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="See the session and its presentations inside."><meta name="title" property="og:title" content="Virtual IEEE VIS 2025 - Session: VIS Full Papers: Visualization Literacy"><meta property="og:type" content="website"><title>IEEE VIS 2025 Content: VIS Full Papers: Visualization Literacy</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style="display: none;"><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-8"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item" aria-current="page"><a href="events.html">All events</a></li><li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">Visualization Literacy</li></ol></nav><h1 class="session-title">VIS Full Papers: Visualization Literacy</h1><h3 class="session-url"><a href="https://ieeevis.org/year/2025/program/event_v-full.html" target="_blank"><span class="fas mr-1">&#xf57c;</span> https://ieeevis.org/year/2025/program/event_v-full.html</a></h3><h3 class="session-chair"><span class="fas mr-1">&#xf007;</span> Session chair: Michelle Borkin </h3><h3 class="session-room mt-4"> Room: Room 0.11 + 0.12 </h3><h3 class="session-date"><span class="fas mr-1">&#xf017;</span><span class="format-date-span-full">2025-11-07T08:30:00+00:00 &ndash; 2025-11-07T09:45:00+00:00</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2025-11-07T08:30:00+00:00 &ndash; 2025-11-07T09:45:00+00:00</span><span class="current-time tztooltiptext"></span></span></h3></div><div class="col-md-1"></div><div class="col-md-3 session-links"><h5 class="session-info my-4"><a href="#list"><span class="fas mr-2">&#xf358;</span> Jump to event listing </a></h5><h5 class="session-info my-4"><a href="https://data.tech.ieeevis.org/storage/v1/object/public/ics/vis2025/full35.ics"><span class="fas mr-2">&#xf073;</span> Add to Calendar</a></h5></div></div><div class="row my-5 discord-public-link hide-auth-controls"><div class="col-md-8"><p><span class="fas mx-1">&#xf086;</span><a href="https://discord.com/channels/1422883912660549696/1430944972428935199" target="_blank">Discord link</a></p></div></div><div class="row my-5"><div class="col-md-8"><p>Recordings will be made available after the session.</p></div></div><hr><div class="row my-4"><div class="col-md-8"><h2 class="room_session_descriptor d-block py-2"><a name="list">Presentations in this session:</a></h2></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1406&#39;, &#39;session_id&#39;: &#39;full35&#39;, &#39;title&#39;: &#39;An Autoethnography on Visualization Literacy: A Wicked Measurement Problem&#39;, &#39;contributors&#39;: [&#39;Lily W. Ge&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-07T08:30:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-07T08:30:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-07T08:42:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Lily W. Ge&#39;, &#39;email&#39;: &#39;wanqian.ge@northwestern.edu&#39;, &#39;affiliation&#39;: &#39;Northwestern University&#39;}, {&#39;name&#39;: &#39;Anne-Flore Cabouat&#39;, &#39;email&#39;: &#39;acabouat@gmail.com&#39;, &#39;affiliation&#39;: &#39;Université Paris-Saclay, Inria, Institut Polytechnique de Paris, CNRS, LISN, i3&#39;}, {&#39;name&#39;: &#39;Karen Bonilla&#39;, &#39;email&#39;: &#39;kbonilla@wpi.edu&#39;, &#39;affiliation&#39;: &#39;Worcester Polytechnic Institute&#39;}, {&#39;name&#39;: &#39;Yuan Cui&#39;, &#39;email&#39;: &#39;yuancui2025@u.northwestern.edu&#39;, &#39;affiliation&#39;: &#39;Northwestern University&#39;}, {&#39;name&#39;: &#39;Yiren Ding&#39;, &#39;email&#39;: &#39;yding5@wpi.edu&#39;, &#39;affiliation&#39;: &#39;Worcester Polytechnic Institute&#39;}, {&#39;name&#39;: &#39;Noëlle Rakotondravony&#39;, &#39;email&#39;: &#39;ntrakotondravony@wpi.edu&#39;, &#39;affiliation&#39;: &#39;Worcester Polytechnic Institute&#39;}, {&#39;name&#39;: &#39;Mackenzie Creamer&#39;, &#39;email&#39;: &#39;18mcreamer@gmail.com&#39;, &#39;affiliation&#39;: &#39;Northeastern University&#39;}, {&#39;name&#39;: &#39;Jasmine Otto&#39;, &#39;email&#39;: &#39;jtotto@ucsc.edu&#39;, &#39;affiliation&#39;: &#39;UC Santa Cruz&#39;}, {&#39;name&#39;: &#39;Maryam Hedayati&#39;, &#39;email&#39;: &#39;maryam.hedayati@u.northwestern.edu&#39;, &#39;affiliation&#39;: &#39;Northwestern University&#39;}, {&#39;name&#39;: &#39;Bum Chul Kwon&#39;, &#39;email&#39;: &#39;bumchul.kwon@us.ibm.com&#39;, &#39;affiliation&#39;: &#39;IBM Research&#39;}, {&#39;name&#39;: &#39;Angela Locoro&#39;, &#39;email&#39;: &#39;angela.locoro@unibs.it&#39;, &#39;affiliation&#39;: &#39;Università degli Studi di Brescia&#39;}, {&#39;name&#39;: &#39;Lane Harrison&#39;, &#39;email&#39;: &#39;ltharrison@wpi.edu&#39;, &#39;affiliation&#39;: &#39;Worcester Polytechnic Institute&#39;}, {&#39;name&#39;: &#39;Petra Isenberg&#39;, &#39;email&#39;: &#39;petra.isenberg@inria.fr&#39;, &#39;affiliation&#39;: &#39;Université Paris-Saclay, CNRS, Inria, LISN&#39;}, {&#39;name&#39;: &#39;Michael Correll&#39;, &#39;email&#39;: &#39;m.correll@northeastern.edu&#39;, &#39;affiliation&#39;: &#39;Northeastern University&#39;}, {&#39;name&#39;: &#39;Matthew Kay&#39;, &#39;email&#39;: &#39;matthew.kay@u.northwestern.edu&#39;, &#39;affiliation&#39;: &#39;Northwestern University&#39;}], &#39;abstract&#39;: &#39;We contribute an autoethnographic reflection on the complexity of defining and measuring visualization literacy (i.e., the ability to interpret and construct visualizations) to expose our tacit thoughts that often exist in-between polished works and remain unreported in individual research papers. Our work is inspired by the growing number of empirical studies in visualization research that rely on visualization literacy as a basis for developing effective data representations or educational interventions. Researchers have already made various efforts to assess this construct, yet it is often hard to pinpoint either what we want to measure or what we are effectively measuring. In this autoethnography, we gather insights from 14 internal interviews with researchers who are users or designers of visualization literacy tests. We aim to identify what makes visualization literacy assessment a wicked problem. We further reflect on the fluidity of visualization literacy and discuss how this property may lead to misalignment between what the construct is and how measurements of it are used or designed. We also examine potential threats to measurement validity from conceptual, operational, and methodological perspectives. Based on our experiences and reflections, we propose several calls to action aimed at tackling the wicked problem of visualization literacy measurement, such as by broadening test scopes and modalities, improving test ecological validity, making it easier to use tests, seeking interdisciplinary collaboration, and drawing from continued dialogue on visualization literacy to expect and be more comfortable with its fluidity.&#39;, &#39;uid&#39;: &#39;7c5cabc5-b76c-4eba-be3a-c6fcfd508888&#39;, &#39;keywords&#39;: [&#39;Visualization literacy&#39;, &#39;autoethnography&#39;, &#39;measurement&#39;, &#39;validity&#39;], &#39;preprint_link&#39;: &#39;https://osf.io/dfr4p_v2&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: &#39;We provided detailed supplemental materials for our autoethnography, including the interview protocol with the semi-structured questions and the full Miro board that we used during analysis.&#39;, &#39;open_access_supplemental_link&#39;: &#39;https://osf.io/xwr4c/&#39;} <h3 class="session-list-title"><a href="paper_7c5cabc5-b76c-4eba-be3a-c6fcfd508888.html"> An Autoethnography on Visualization Literacy: A Wicked Measurement Problem <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Lily W. Ge, Anne-Flore Cabouat, Karen Bonilla, Yuan Cui, Yiren Ding, Noëlle Rakotondravony, Mackenzie Creamer, Jasmine Otto, Maryam Hedayati, Bum Chul Kwon, Angela Locoro, Lane Harrison, Petra Isenberg, Michael Correll, Matthew Kay </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Lily W. Ge </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-07T08:30:00.000Z &ndash; 2025-11-07T08:42:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1490&#39;, &#39;session_id&#39;: &#39;full35&#39;, &#39;title&#39;: &#39;Tell Me Without Telling Me: Two-Way Prediction of Visualization Literacy and Visual Attention&#39;, &#39;contributors&#39;: [&#39;Minsuk Chang&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-07T08:42:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-07T08:42:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-07T08:54:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Minsuk Chang&#39;, &#39;email&#39;: &#39;minsuk@gatech.edu&#39;, &#39;affiliation&#39;: &#39;Georgia Institute of Technology&#39;}, {&#39;name&#39;: &#39;Yao Wang&#39;, &#39;email&#39;: &#39;yao.wang@vis.uni-stuttgart.de&#39;, &#39;affiliation&#39;: &#39;University of Stuttgart&#39;}, {&#39;name&#39;: &#39;Huichen Wang&#39;, &#39;email&#39;: &#39;wwill@cs.washington.edu&#39;, &#39;affiliation&#39;: &#39;University of Washington&#39;}, {&#39;name&#39;: &#39;Yuanhong Zhou&#39;, &#39;email&#39;: &#39;zhouyuanhong0510@gmail.com&#39;, &#39;affiliation&#39;: &#39;Georgia Institute of Technology&#39;}, {&#39;name&#39;: &#39;Andreas Bulling&#39;, &#39;email&#39;: &#39;andreas.bulling@vis.uni-stuttgart.de&#39;, &#39;affiliation&#39;: &#39;University of Stuttgart&#39;}, {&#39;name&#39;: &#39;Cindy Xiong Bearfield&#39;, &#39;email&#39;: &#39;cxiong@gatech.edu&#39;, &#39;affiliation&#39;: &#39;Georgia Tech&#39;}], &#39;abstract&#39;: &#34;Accounting for individual differences can improve the effectiveness of visualization design. While the role of visual attention in visualization interpretation is well recognized, existing work often overlooks how this behavior varies based on visual literacy levels. Based on data from a 235-participant user study covering three visualization tests (mini-VLAT, CALVI, and SGL), we show that distinct attention patterns in visual data exploration can correlate with participants&#39; literacy levels: While experts (high-scorers) generally show a strong attentional focus, novices (low-scorers) focus less and explore more. We then propose two computational models leveraging these insights: Lit2Sal -- a novel visual saliency model that predicts observer attention given their visualization literacy level, and Sal2Lit -- a model to predict visual literacy from human visual attention data. Our quantitative and qualitative evaluation demonstrates that Lit2Sal outperforms state-of-the-art saliency models with literacy-aware considerations. Sal2Lit predicts literacy with 86% accuracy using a single attention map, providing a time-efficient supplement to literacy assessment that only takes less than a minute. Taken together, our unique approach to consider individual differences in salience models and visual attention in literacy assessments paves the way for new directions in personalized visual data communication to enhance understanding.&#34;, &#39;uid&#39;: &#39;22ccb527-7a1d-49e1-81b8-9e4f335089e1&#39;, &#39;keywords&#39;: [&#39;Visualization Literacy Assessment&#39;, &#39;Visual Attention and Saliency&#39;, &#39;Visual Saliency Models&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2508.03713&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://osf.io/2crb9/&#39;} <h3 class="session-list-title"><a href="paper_22ccb527-7a1d-49e1-81b8-9e4f335089e1.html"> Tell Me Without Telling Me: Two-Way Prediction of Visualization Literacy and Visual Attention <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Minsuk Chang, Yao Wang, Huichen Wang, Yuanhong Zhou, Andreas Bulling, Cindy Xiong Bearfield </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Minsuk Chang </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-07T08:42:00.000Z &ndash; 2025-11-07T08:54:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1863&#39;, &#39;session_id&#39;: &#39;full35&#39;, &#39;title&#39;: &#39;Enhancing Data Visualization Literacy: A Comparative Study of Learning Materials in Schools&#39;, &#39;contributors&#39;: [&#39;Magdalena Boucher&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-07T08:54:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-07T08:54:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-07T09:06:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Magdalena Boucher&#39;, &#39;email&#39;: &#39;magdalena.boucher@fhstp.ac.at&#39;, &#39;affiliation&#39;: &#39;St. Pölten University of Applied Sciences&#39;}, {&#39;name&#39;: &#39;Magdalena Kejstova&#39;, &#39;email&#39;: &#39;makej@mail.muni.cz&#39;, &#39;affiliation&#39;: &#39;Masaryk University&#39;}, {&#39;name&#39;: &#39;Christina Stoiber&#39;, &#39;email&#39;: &#39;christina.stoiber@fhstp.ac.at&#39;, &#39;affiliation&#39;: &#39;St. Poelten University of Applied Sciences&#39;}, {&#39;name&#39;: &#39;Martin Kandlhofer&#39;, &#39;email&#39;: &#39;martin.kandlhofer@ocg.at&#39;, &#39;affiliation&#39;: &#39;Austrian Computer Society&#39;}, {&#39;name&#39;: &#39;Alena Boucher&#39;, &#39;email&#39;: &#39;leniproduction@gmail.com&#39;, &#39;affiliation&#39;: &#39;Austrian Computer Society&#39;}, {&#39;name&#39;: &#39;Simone Kriglstein&#39;, &#39;email&#39;: &#39;simone.kriglstein@univie.ac.at&#39;, &#39;affiliation&#39;: &#39;Masaryk University&#39;}, {&#39;name&#39;: &#39;Shelley Buchinger&#39;, &#39;email&#39;: &#39;shelley.buchinger@brg9.at&#39;, &#39;affiliation&#39;: &#39;Erich Fried Realgymnasium&#39;}, {&#39;name&#39;: &#39;Wolfgang Aigner&#39;, &#39;email&#39;: &#39;wolfgang.aigner@fhstp.ac.at&#39;, &#39;affiliation&#39;: &#39;St. Poelten University of Applied Sciences&#39;}], &#39;abstract&#39;: &#39;Interpreting data visualizations is an essential skill in today’s education, yet students often struggle with understanding unfamiliar formats. This study investigates how four learning materials – textbook, comic, video, and game – affect middle- and high school students’ ability to interpret line charts, area charts, stacked area charts, and stream graphs. We conducted a comparative classroom study with 68 students, using pre- and post-tests, worksheet activities, and group discussions to assess learning outcomes and understanding. Our results show statistically significant improvement in students’ understanding of stacked area charts and streamgraphs, while no significant differences between the learning materials were found. This suggests that more factors than initially anticipated – such as engagement, motivation and active learning strategies – influence the learning outcome. The analysis of the worksheets revealed that while students could infer surface-level insights from charts, over 70% struggled to identify underlying patterns or relationships. Additionally, a common challenge across all learning materials was reading fatigue, which often led students to skim content, disengage, or misinterpret key information. These findings highlight the need for educational tools and approaches that foster deeper understanding of unfamiliar visualizations, reduce cognitive load, and encourage active engagement.&#39;, &#39;uid&#39;: &#39;851f1b42-91da-4dcc-a08e-c6d8e564d251&#39;, &#39;keywords&#39;: [&#39;visualization education&#39;, &#39;schools&#39;, &#39;learning materials&#39;, &#39;visualization literacy&#39;], &#39;preprint_link&#39;: &#39;https://phaidra.fhstp.ac.at/detail/o:7302&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://phaidra.fhstp.ac.at/detail/o:7304&#39;} <h3 class="session-list-title"><a href="paper_851f1b42-91da-4dcc-a08e-c6d8e564d251.html"> Enhancing Data Visualization Literacy: A Comparative Study of Learning Materials in Schools <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Magdalena Boucher, Magdalena Kejstova, Christina Stoiber, Martin Kandlhofer, Alena Boucher, Simone Kriglstein, Shelley Buchinger, Wolfgang Aigner </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Magdalena Boucher </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-07T08:54:00.000Z &ndash; 2025-11-07T09:06:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1997&#39;, &#39;session_id&#39;: &#39;full35&#39;, &#39;title&#39;: &#39;Charts-of-Thought: Enhancing LLM Visualization Literacy Through Structured Data Extraction&#39;, &#39;contributors&#39;: [&#39;Amit Kumar Das&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-07T09:06:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-07T09:06:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-07T09:18:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Amit Kumar Das&#39;, &#39;email&#39;: &#39;amitkumar.das@stonybrook.edu&#39;, &#39;affiliation&#39;: &#39;Stony Brook University&#39;}, {&#39;name&#39;: &#39;Mohammad Tarun&#39;, &#39;email&#39;: &#39;md.tarun005@gmail.com&#39;, &#39;affiliation&#39;: &#39;East West University&#39;}, {&#39;name&#39;: &#39;Klaus Mueller&#39;, &#39;email&#39;: &#39;mueller@cs.sunysb.edu&#39;, &#39;affiliation&#39;: &#39;Stony Brook University&#39;}], &#39;abstract&#39;: &#39;This paper evaluates the visualization literacy of modern Large Language Models (LLMs) and introduces a novel prompting technique called Charts-of-Thought. We tested three state-of-the-art LLMs (Claude-3.7-sonnet, GPT-4.5-preview, and Gemini-2.0-pro) on the Visualization Literacy Assessment Test (VLAT) using standard prompts and our structured approach. The Charts-of-Thought method guides LLMs through a systematic data extraction, verification, and analysis process before answering visualization questions. Our results show Claude-3.7-sonnet achieved a score of 50.17 using this method, far exceeding the human baseline of 28.82. This approach improved performance across all models, with score increases of 21.8% for GPT-4.5, 9.4% for Gemini-2.0, and 13.5% for Claude-3.7 compared to standard prompting. The performance gains were consistent across original and modified VLAT charts, with Claude correctly answering 100% of questions for several chart types that previously challenged LLMs. Our study reveals that modern multimodal LLMs can surpass human performance on visualization literacy tasks when given the proper analytical framework. These findings establish a new benchmark for LLM visualization literacy and demonstrate the importance of structured prompting strategies for complex visual interpretation tasks. Beyond improving LLM visualization literacy, Charts-of-Thought could also enhance the accessibility of visualizations, potentially benefiting individuals with visual impairments or lower visualization literacy.&#39;, &#39;uid&#39;: &#39;fcafb37e-70f2-4d68-b9a4-e92902d9d2bd&#39;, &#39;keywords&#39;: [&#39;Visualization Literacy&#39;, &#39;Large Language Models&#39;, &#39;Charts-of-Thoughts&#39;, &#39;Data Extraction&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2508.04842&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: &#39;We provide comprehensive supplementary materials including all source code, experimental data, prompts, and detailed results to ensure full reproducibility. All materials are publicly accessible through both the submission system and a dedicated GitHub repository (https://github.com/vhcailab/Charts-of-Thought), enabling researchers to replicate our Charts-of-Thought prompting methodology and build upon our structured approach to enhancing LLM visualization literacy.&#39;, &#39;open_access_supplemental_link&#39;: &#39;https://github.com/vhcailab/Charts-of-Thought&#39;} <h3 class="session-list-title"><a href="paper_fcafb37e-70f2-4d68-b9a4-e92902d9d2bd.html"> Charts-of-Thought: Enhancing LLM Visualization Literacy Through Structured Data Extraction <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Amit Kumar Das, Mohammad Tarun, Klaus Mueller </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Amit Kumar Das </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-07T09:06:00.000Z &ndash; 2025-11-07T09:18:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-07-0543.R2&#39;, &#39;session_id&#39;: &#39;full35&#39;, &#39;title&#39;: &#39;Do LLMs Have Visualization Literacy? An Evaluation on Modified Visualizations to Test Generalization in Data Interpretation&#39;, &#39;contributors&#39;: [&#39;Christian Seto&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-07T09:18:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-07T09:18:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-07T09:30:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Jiayi Hong&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Christian Seto&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Arlen Fan&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Ross Maciejewski&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;In this article, we assess the visualization literacy of two prominent Large Language Models (LLMs): OpenAI’s Generative Pretrained Transformers (GPT), the backend of ChatGPT, and Google’s Gemini, previously known as Bard, to establish benchmarks for assessing their visualization capabilities. While LLMs have shown promise in generating chart descriptions, captions, and design suggestions, their potential for evaluating visualizations remains under-explored. Collecting data from humans for evaluations has been a bottleneck for visualization research in terms of both time and money, and if LLMs were able to serve, even in some limited role, as evaluators, they could be a significant resource. To investigate the feasibility of using LLMs in the visualization evaluation process, we explore the extent to which LLMs possess visualization literacy—a crucial factor for their effective utility in the field. We conducted a series of experiments using a modified 53-item Visualization Literacy Assessment Test (VLAT) for and . Our findings indicate that the LLMs we explored currently fail to achieve the same levels of visualization literacy when compared to data from the general public reported in VLAT, and LLMs heavily relied on their pre-existing knowledge to answer questions instead of utilizing the information provided by the visualization when answering questions.&#39;, &#39;uid&#39;: &#39;2e99a9c7-1244-48c4-a5fa-7b3f3df0aa71&#39;, &#39;keywords&#39;: [&#39;Data visualization&#39;, &#39;Visualization&#39;, &#39;Costs&#39;, &#39;Data models&#39;, &#39;Benchmark testing&#39;, &#39;Codes&#39;, &#39;Training&#39;, &#39;Data mining&#39;, &#39;Computational modeling&#39;, &#39;Cognition&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2501.16277v1&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2025.3536358&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: &#39;Our Github repository (https://github.com/VADERASU/llm4viz-experiments) contains detailed instructions on how we generated our charts for testing as well as how we ran our experiments with detailed links for each experiment, thus making our work highly replicatable.&#39;, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_2e99a9c7-1244-48c4-a5fa-7b3f3df0aa71.html"> Do LLMs Have Visualization Literacy? An Evaluation on Modified Visualizations to Test Generalization in Data Interpretation <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Jiayi Hong, Christian Seto, Arlen Fan, Ross Maciejewski </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Christian Seto </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-07T09:18:00.000Z &ndash; 2025-11-07T09:30:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2023-07-0405.R2&#39;, &#39;session_id&#39;: &#39;full35&#39;, &#39;title&#39;: &#39;Iguanodon: A Code-Breaking Game for Improving Visualization Construction Literacy&#39;, &#39;contributors&#39;: [&#39;Patrick Adelberger&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-07T09:30:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-07T09:30:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-07T09:42:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Patrick Adelberger&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Oleg Lesota&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Klaus Eckelt&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Markus Schedl&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Marc Streit&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#34;In today&#39;s data-rich environment, visualization literacy—the ability to understand and communicate information through charts—is increasingly important. However, constructing effective charts can be challenging due to the numerous design choices involved. Off-the-shelf systems and libraries produce charts with carefully selected defaults that users may not be aware of, making it hard to increase their visualization literacy with those systems. In addition, traditional ways of improving visualization literacy, such as textbooks and tutorials, can be burdensome as they require sifting through a plethora of resources. To address this challenge, we designed Iguanodon, an easy-to-use game application that complements the traditional methods of improving visualization construction literacy. In our game application, users interactively choose whether to apply design choices, which we assign to sub-tasks that must be optimized to create an effective chart. The application offers multiple game variations to help users learn how different design choices should be applied to construct effective charts. Furthermore, our approach easily adapts to different visualization design guidelines. We describe the application&#39;s design and present the results of a user study with 37 participants. Our findings indicate that our game-based approach supports users in improving their visualization literacy.&#34;, &#39;uid&#39;: &#39;78f54a18-4ae6-4d52-9b39-50df068a510c&#39;, &#39;keywords&#39;: [&#39;Data visualization&#39;, &#39;Games&#39;, &#39;Visualization&#39;, &#39;Guidelines&#39;, &#39;Tutorials&#39;, &#39;Design methodology&#39;, &#39;Bars&#39;, &#39;Topology&#39;, &#39;Reviews&#39;, &#39;Recommender systems&#39;], &#39;preprint_link&#39;: &#39;https://osf.io/preprints/osf/xung4_v1&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2024.3468948&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_78f54a18-4ae6-4d52-9b39-50df068a510c.html"> Iguanodon: A Code-Breaking Game for Improving Visualization Construction Literacy <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Patrick Adelberger, Oleg Lesota, Klaus Eckelt, Markus Schedl, Marc Streit </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Patrick Adelberger </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-07T09:30:00.000Z &ndash; 2025-11-07T09:42:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row my-5"><div class="col-md-8"><p>You may want to also jump to the parent event to see related presentations: <a href="event_v-full.html">VIS Full Papers</a></p></div></div><script src="/static/2025/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script><script>

$(document).ready(function() {
    setInterval(updateSessionStatus, 30 * 1000);
    updateSessionStatus(true)
})

function updateSessionStatus(onFirstLoad) {
    // We need to write the session timings into the page to calculate current/next session.
    // See blueprint_2025.py
    startTime = '2025-11-07T08:30:00+00:00'
    endTime = '2025-11-07T09:45:00+00:00'

    // We take a 8 minute grace period to the start of a session
    const sessionStart = moment(startTime).tz(current_timezone).subtract(8, 'minutes');
    const sessionEnd = moment(endTime).tz(current_timezone);

    const sessionIsCurrent = moment().tz(current_timezone).isBetween(sessionStart, sessionEnd);
    const sessionIsFuture = moment().tz(current_timezone).isBefore(sessionStart);
    const sessionIsPast = moment().tz(current_timezone).isAfter(sessionStart);

    const classesToHide = ['.future_session_alert', '.current_session_alert', '.past_session_alert', '.room_session_stream']
    classesToHide.forEach((c) => { $(c).hide();});
    if (sessionIsCurrent) {
        $('.current_session_alert').show();
    } else if (sessionIsFuture) {
        $('.future_session_alert').show();
    } else {
        // Session is in the future
        $('#zoom_alert').hide();
        $('.past_session_alert').show();
        $('.room_session_stream').show();
    }

    // Update youtube link for older sessions
    // EDIT - We don't need this when the conference isn't live
    if(sessionIsPast){
        const roomidjson = "0_11_0_12-"+moment(startTime).format('ddd').toLowerCase()+".json"
        // console.log("this session was in:" , roomidjson)

        return fetch("https://virtual-data.ieeevis.org/"+roomidjson, {cache: "no-store"})
        .then(response => response.json())
        .then(data => {
            //console.log(data)
            // console.log('youtube_url: ' + data.youtube_url)
            //$("ytold").attr("href",data.youtube_url)

            // clear link element to avoid multiple appends
            document.getElementById("ytold").innerHTML = '';

            var a = document.createElement('a'); 
            var link = document.createTextNode(data.youtube_url);  
            a.appendChild(link); 
            a.title = "YouTube Link"; 
            a.href = data.youtube_url; 
            
            document.getElementById("ytold").appendChild(a);
        })
        .catch(error => {
            console.log("err: ", error);
        })
    }
    

}

</script></body></html>