<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/2.1/auth0-spa-js.production.js"></script><script>
              const auth0_domain = "ieeevis.us.auth0.com";
              const auth0_client_id = "oF5BXUklWOjSjUeg5Tzai2DysHITXYhT";
            </script><script src="/static/2025/js/modules/auth0protect.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2025/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2025/js/data/persistor.js"></script><script src="/static/2025/js/data/api.js"></script><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2025/css/Zilla.css" rel="stylesheet"><link href="/static/2025/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2025/css/main.css"><link rel="stylesheet" href="/static/2025/css/fa_solid.css"><link rel="stylesheet" href="/static/2025/css/lazy_load.css"><link rel="stylesheet" href="/static/2025/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2025 - Session: VIS Full Papers: Graphs and Networks"><meta name="twitter:description" content="See the session and its presentations inside."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="See the session and its presentations inside."><meta name="title" property="og:title" content="Virtual IEEE VIS 2025 - Session: VIS Full Papers: Graphs and Networks"><meta property="og:type" content="website"><title>IEEE VIS 2025 Content: VIS Full Papers: Graphs and Networks</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style="display: none;"><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-8"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item" aria-current="page"><a href="events.html">All events</a></li><li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">Graphs and Networks</li></ol></nav><h1 class="session-title">VIS Full Papers: Graphs and Networks</h1><h3 class="session-url"><a href="https://ieeevis.org/year/2025/program/event_v-full.html" target="_blank"><span class="fas mr-1">&#xf57c;</span> https://ieeevis.org/year/2025/program/event_v-full.html</a></h3><h3 class="session-chair"><span class="fas mr-1">&#xf007;</span> Session chair: Fabian Beck </h3><h3 class="session-room mt-4"> Room: Room 1.14 </h3><h3 class="session-date"><span class="fas mr-1">&#xf017;</span><span class="format-date-span-full">2025-11-05T14:45:00+00:00 &ndash; 2025-11-05T16:00:00+00:00</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2025-11-05T14:45:00+00:00 &ndash; 2025-11-05T16:00:00+00:00</span><span class="current-time tztooltiptext"></span></span></h3></div><div class="col-md-1"></div><div class="col-md-3 session-links"><h5 class="session-info my-4"><a href="#list"><span class="fas mr-2">&#xf358;</span> Jump to event listing </a></h5><h5 class="session-info my-4"><a href="https://data.tech.ieeevis.org/storage/v1/object/public/ics/vis2025/full17.ics"><span class="fas mr-2">&#xf073;</span> Add to Calendar</a></h5></div></div><div class="row my-5 discord-public-link hide-auth-controls"><div class="col-md-8"><p><span class="fas mx-1">&#xf086;</span><a href="https://discord.com/channels/1422883912660549696/1430945410309951666" target="_blank">Discord link</a></p></div></div><div class="row my-5"><div class="col-md-8"><p>Recordings will be made available after the session.</p></div></div><hr><div class="row my-4"><div class="col-md-8"><h2 class="room_session_descriptor d-block py-2"><a name="list">Presentations in this session:</a></h2></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1567&#39;, &#39;session_id&#39;: &#39;full17&#39;, &#39;title&#39;: &#39;Envisage: Towards Expressive Visual Graph Querying&#39;, &#39;contributors&#39;: [&#39;Xiaolin Wen&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T14:45:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T14:45:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T14:57:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Xiaolin Wen&#39;, &#39;email&#39;: &#39;xiaolin004@e.ntu.edu.sg&#39;, &#39;affiliation&#39;: &#39;Nanyang Technological University&#39;}, {&#39;name&#39;: &#39;Qishuang Fu&#39;, &#39;email&#39;: &#39;qishuang.fu@monash.edu&#39;, &#39;affiliation&#39;: &#39;Monash University&#39;}, {&#39;name&#39;: &#39;Shuangyue Han&#39;, &#39;email&#39;: &#39;shuangyu001@e.ntu.edu.sg&#39;, &#39;affiliation&#39;: &#39;Nanyang Technological University&#39;}, {&#39;name&#39;: &#39;Yichen Guo&#39;, &#39;email&#39;: &#39;yguo017@e.ntu.edu.sg&#39;, &#39;affiliation&#39;: &#39;Nanyang Technological University&#39;}, {&#39;name&#39;: &#39;Joseph Liu&#39;, &#39;email&#39;: &#39;joseph.liu@monash.edu&#39;, &#39;affiliation&#39;: &#39;Monash University&#39;}, {&#39;name&#39;: &#39;Yong WANG&#39;, &#39;email&#39;: &#39;yong-wang@ntu.edu.sg&#39;, &#39;affiliation&#39;: &#39;Nanyang Technological University&#39;}], &#39;abstract&#39;: &#34;Graph querying is the process of retrieving information from graph data using specialized languages (e.g., Cypher), often requiring programming expertise. Visual Graph Querying (VGQ) streamlines this process by enabling users to construct and execute queries via an interactive interface without resorting to complex coding. However, current VGQ tools only allow users to construct simple and specific query graphs, limiting users&#39; ability to interactively express their query intent, especially for underspecified query intent. To address these limitations, we propose Envisage, an interactive visual graph querying system to enhance the expressiveness of VGQ in complex query scenarios by supporting intuitive graph structure construction and flexible parameterized rule specification. Specifically, Envisage comprises four stages: Query Expression allows users to interactively construct graph queries through intuitive operations; Query Verification enables the validation of constructed queries via rule verification and query instantiation; Progressive Query Execution can progressively execute queries to ensure meaningful querying results; and Result Analysis facilitates result exploration and interpretation. To evaluate Envisage, we conducted two case studies and in-depth user interviews with 14 graph analysts. The results demonstrate its effectiveness and usability in constructing, verifying, and executing complex graph queries.&#34;, &#39;uid&#39;: &#39;ae49090b-23a7-453b-8d5d-eb0ad8893a08&#39;, &#39;keywords&#39;: [&#39;Visual graph querying&#39;, &#39;interactive query construction&#39;, &#39;graph data&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2507.11999&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://github.com/Selvalim/VGQ-front&#39;} <h3 class="session-list-title"><a href="paper_ae49090b-23a7-453b-8d5d-eb0ad8893a08.html"> Envisage: Towards Expressive Visual Graph Querying <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Xiaolin Wen, Qishuang Fu, Shuangyue Han, Yichen Guo, Joseph Liu, Yong WANG </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Xiaolin Wen </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T14:45:00.000Z &ndash; 2025-11-05T14:57:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1698&#39;, &#39;session_id&#39;: &#39;full17&#39;, &#39;title&#39;: &#39;Motif Simplification for BioFabric Network Visualizations: Improving Pattern Recognition and Interpretation&#39;, &#39;contributors&#39;: [&#39;Johannes Fuchs&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T14:57:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T14:57:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:09:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Johannes Fuchs&#39;, &#39;email&#39;: &#39;fuchs@dbvis.inf.uni-konstanz.de&#39;, &#39;affiliation&#39;: &#39;University of Konstanz&#39;}, {&#39;name&#39;: &#39;Cody Dunne&#39;, &#39;email&#39;: &#39;c.dunne@northeastern.edu&#39;, &#39;affiliation&#39;: &#39;Northeastern University&#39;}, {&#39;name&#39;: &#39;Maria-Viktoria Heinle&#39;, &#39;email&#39;: &#39;maria-viktoria.heinle@uni-konstanz.de&#39;, &#39;affiliation&#39;: &#39;University of Konstanz&#39;}, {&#39;name&#39;: &#39;Daniel Keim&#39;, &#39;email&#39;: &#39;keim@uni-konstanz.de&#39;, &#39;affiliation&#39;: &#39;University of Konstanz&#39;}, {&#39;name&#39;: &#39;Sara Di Bartolomeo&#39;, &#39;email&#39;: &#39;dibartolomeo.sara@gmail.com&#39;, &#39;affiliation&#39;: &#39;TU Wien&#39;}], &#39;abstract&#39;: &#39;Detecting and interpreting common patterns in relational data is crucial for understanding complex topological structures across various domains. These patterns, or network motifs, can often be detected algorithmically. However, visual inspection remains vital for exploring and discovering patterns. This paper focuses on presenting motifs within BioFabric network visualizations---a unique technique that opens opportunities for research on scaling to larger networks, design variations, and layout algorithms to better expose motifs. Our goal is to show how highlighting motifs can assist users in identifying and interpreting patterns in BioFabric visualizations. To this end, we leverage existing motif simplification techniques. We replace edges with glyphs representing fundamental motifs such as staircases, cliques, paths, and connector nodes. The results of our controlled experiment and usage scenarios demonstrate that motif simplification for BioFabric is useful for detecting and interpreting network patterns. Our participants were faster and more confident using the simplified view without sacrificing accuracy. The efficacy of our current motif simplification approach depends on which extant layout algorithm is used. We hope our promising findings on user performance will motivate future research on layout algorithms tailored to maximizing motif presentation. Our supplemental material is available at https://osf.io/f8s3g/?view_only=7e2df9109dfd4e6c85b89ed828320843&#39;, &#39;uid&#39;: &#39;e14aa8da-3794-45ba-9dd7-5e0ced3449c7&#39;, &#39;keywords&#39;: [&#39;BioFabric&#39;, &#39;Network Visualization&#39;, &#39;Motif Simplification&#39;, &#39;Glyph Design&#39;, &#39;Quantitative Experiment&#39;], &#39;preprint_link&#39;: &#39;https://osf.io/preprints/osf/5d9q6_v1&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://osf.io/f8s3g/?view_only=7e2df9109dfd4e6c85b89ed828320843&#39;} <h3 class="session-list-title"><a href="paper_e14aa8da-3794-45ba-9dd7-5e0ced3449c7.html"> Motif Simplification for BioFabric Network Visualizations: Improving Pattern Recognition and Interpretation <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Johannes Fuchs, Cody Dunne, Maria-Viktoria Heinle, Daniel Keim, Sara Di Bartolomeo </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Johannes Fuchs </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T14:57:00.000Z &ndash; 2025-11-05T15:09:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-09-0828.R1&#39;, &#39;session_id&#39;: &#39;full17&#39;, &#39;title&#39;: &#39;Bridging Network Science and Vision Science: Mapping Perceptual Mechanisms to Network Visualization Tasks&#39;, &#39;contributors&#39;: [&#39;Sandra Bae&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T15:09:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T15:09:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:21:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;S. Sandra Bae&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Kyle Cave&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Carsten Görg&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Paul Rosen&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Danielle Szafir&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Cindy Xiong Bearfield&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Network visualizations are understudied in graphical perception. As a result, most network visualization designs still largely rely on designer intuition and algorithm optimizations rather than being guided by knowledge of human perception. The lack of perceptual understanding of network visualizations also limits the generalizability of past empirical evaluations, given their focus on performance over causal interpretation. To bridge this gap between perception and network visualization, we introduce a framework highlighting five key perceptual mechanisms used in node-link diagrams and adjacency matrices: attention, visual search, perceptual organization, ensemble coding, and object recognition. Our framework describes the role these perceptual mechanisms play in common network analytical tasks. We use the framework to revisit four past empirical investigations and outline future design experiments that can help produce more perceptually effective network visualizations. We anticipate this connection will afford translational understanding to guide more effective network visualization design and offer hypotheses for perception-aware network visualizations.&#39;, &#39;uid&#39;: &#39;af26160d-884d-4338-b93f-a0ef201cc6c4&#39;, &#39;keywords&#39;: [&#39;Visualization&#39;, &#39;Layout&#39;, &#39;Data visualization&#39;, &#39;Guidelines&#39;, &#39;Electronic mail&#39;, &#39;Clustering algorithms&#39;, &#39;Accuracy&#39;, &#39;Training&#39;, &#39;Taxonomy&#39;, &#39;Surveys&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2025.3541571&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_af26160d-884d-4338-b93f-a0ef201cc6c4.html"> Bridging Network Science and Vision Science: Mapping Perceptual Mechanisms to Network Visualization Tasks <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: S. Sandra Bae, Kyle Cave, Carsten Görg, Paul Rosen, Danielle Szafir, Cindy Xiong Bearfield </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Sandra Bae </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T15:09:00.000Z &ndash; 2025-11-05T15:21:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2023-09-0527GVVST:&#39;, &#39;session_id&#39;: &#39;full17&#39;, &#39;title&#39;: &#39;GVVST: Image-Driven Style Extraction From Graph Visualizations for Visual Style Transfer&#39;, &#39;contributors&#39;: [&#39;Sicheng Song&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T15:21:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T15:21:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:33:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Sicheng Song&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Yipeng Zhang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Yanna Lin&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Huamin Qu&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Changbo Wang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Chenhui Li&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Incorporating automatic style extraction and transfer from existing well-designed graph visualizations can significantly alleviate the designer’s workload. There are many types of graph visualizations. In this paper, our work focuses on node-link diagrams. We present a novel approach to streamline the design process of graph visualizations by automatically extracting visual styles from well-designed examples and applying them to other graphs. Our formative study identifies the key styles that designers consider when crafting visualizations, categorizing them into global and local styles. Leveraging deep learning techniques such as saliency detection models and multi-label classification models, we develop end-to-end pipelines for extracting both global and local styles. Global styles focus on aspects such as color scheme and layout, while local styles are concerned with the finer details of node and edge representations. Through a user study and evaluation experiment, we demonstrate the efficacy and time-saving benefits of our method, highlighting its potential to enhance the graph visualization design process.&#39;, &#39;uid&#39;: &#39;02afa2f8-af68-4eb3-b1e6-9f20791ee73d&#39;, &#39;keywords&#39;: [&#39;Visualization&#39;, &#39;Data visualization&#39;, &#39;Data mining&#39;, &#39;Layout&#39;, &#39;Image color analysis&#39;, &#39;Feature extraction&#39;, &#39;Deep learning&#39;, &#39;Pipelines&#39;, &#39;Bars&#39;, &#39;Image edge detection&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2024.3485701&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_02afa2f8-af68-4eb3-b1e6-9f20791ee73d.html"> GVVST: Image-Driven Style Extraction From Graph Visualizations for Visual Style Transfer <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Sicheng Song, Yipeng Zhang, Yanna Lin, Huamin Qu, Changbo Wang, Chenhui Li </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Sicheng Song </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T15:21:00.000Z &ndash; 2025-11-05T15:33:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-05-0342.R1&#39;, &#39;session_id&#39;: &#39;full17&#39;, &#39;title&#39;: &#39;The Census-Stub Graph Invariant Descriptor&#39;, &#39;contributors&#39;: [&#39;Matt Oddo&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T15:33:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T15:33:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:45:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Matt Oddo&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Stephen Kobourov&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Tamara Munzner&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#34;An ‘invariant descriptor’ captures meaningful structural features of networks, useful where traditional visualizations, like node-link views, face challenges like the ’hairball phenomenon’ (inscrutable overlap of points and lines). Designing invariant descriptors involves balancing abstraction and information retention, as richer data summaries demand more storage and computational resources. Building on prior work, chiefly the BMatrix—a matrix descriptor visualized as the invariant ’network portrait’ heatmap—we introduce BFS-Census, a new algorithm computing our Census data structures: Census-Node, Census-Edge, and Census-Stub. Our experiments show Census-Stub, which focuses on ’stubs’ (half-edges), has orders of magnitude greater discerning power (ability to tell non-isomorphic graphs apart) than any other descriptor in this study, without a difficult trade-off: the substantial increase in resolution doesn&#39;t come at a commensurate cost in storage space or computation power. We also present new visualizations—our Hop-Census polylines and Census-Census trajectories—and evaluate them using real-world graphs, including a sensitivity analysis that shows graph topology change maps to visual Census change.&#34;, &#39;uid&#39;: &#39;41c4a87c-ba18-4af0-9aa1-b97ddd58a669&#39;, &#39;keywords&#39;: [&#39;Visualization&#39;, &#39;Data structures&#39;, &#39;Layout&#39;, &#39;Encoding&#39;, &#39;Topology&#39;, &#39;Vectors&#39;, &#39;Sensitivity analysis&#39;, &#39;Network topology&#39;, &#39;Trajectory&#39;, &#39;Pipelines&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2412.04582&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2024.3513275&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: &#39;Very extensive supplemental material: in addition to source code and benchmark dataset of 81 networks, we have scripts to produce every figure in paper, and thefigures themselves. These include high-resolution images grouped by plot type and by network: full-page collages for each plot type across all 81 networks, and conversely full-page views for each of the featured network showing all plot types for it.&#39;, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_41c4a87c-ba18-4af0-9aa1-b97ddd58a669.html"> The Census-Stub Graph Invariant Descriptor <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Matt Oddo, Stephen Kobourov, Tamara Munzner </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Matt Oddo </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T15:33:00.000Z &ndash; 2025-11-05T15:45:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-02-0125&#39;, &#39;session_id&#39;: &#39;full17&#39;, &#39;title&#39;: &#39;Visual Analytics of Multivariate Networks with Representation Learning and Composite Variable Construction&#39;, &#39;contributors&#39;: [&#39;Takanori Fujiwara&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T15:45:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T15:45:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:57:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Hsiao-Ying Lu&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Takanori Fujiwara&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Ming-Yi Chang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Yang-chih Fu&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Anders Ynnerman&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Kwan-Liu Ma&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Multivariate networks are commonly found in real-world data-driven applications. Uncovering and understanding the relations of interest in multivariate networks is not a trivial task. This paper presents a visual analytics workflow for studying multivariate networks to extract associations between different structural and semantic characteristics of the networks (e.g., what are the combinations of attributes largely relating to the density of a social network?). The workflow consists of a neural-network-based learning phase to classify the data based on the chosen input and output attributes, a dimensionality reduction and optimization phase to produce a simplified set of results for examination, and finally an interpreting phase conducted by the user through an interactive visualization interface. A key part of our design is a composite variable construction step that remodels nonlinear features obtained by neural networks into linear features that are intuitive to interpret. We demonstrate the capabilities of this workflow with multiple case studies on networks derived from social media usage and also evaluate the workflow with qualitative feedback from experts.&#39;, &#39;uid&#39;: &#39;dee3e240-f398-4a18-8460-cb8f4ad56df1&#39;, &#39;keywords&#39;: [&#39;Artificial neural networks&#39;, &#39;Visual analytics&#39;, &#39;Feature extraction&#39;, &#39;Semantics&#39;, &#39;Social networking (online)&#39;, &#39;Data mining&#39;, &#39;Vectors&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2303.09590&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2024.3423728&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: &#39;Our work emphasizes interpretability through a key design feature: a composite variable construction step that transforms complex, nonlinear neural network outputs into intuitive, linear features. This process is clearly documented and fully reproducible. Additionally, our visual analytics interface integrates expert knowledge, enabling users to construct and test hypotheses about combinatorial effects of variables with ease.&#39;, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_dee3e240-f398-4a18-8460-cb8f4ad56df1.html"> Visual Analytics of Multivariate Networks with Representation Learning and Composite Variable Construction <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Hsiao-Ying Lu, Takanori Fujiwara, Ming-Yi Chang, Yang-chih Fu, Anders Ynnerman, Kwan-Liu Ma </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Takanori Fujiwara </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T15:45:00.000Z &ndash; 2025-11-05T15:57:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row my-5"><div class="col-md-8"><p>You may want to also jump to the parent event to see related presentations: <a href="event_v-full.html">VIS Full Papers</a></p></div></div><script src="/static/2025/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script><script>

$(document).ready(function() {
    setInterval(updateSessionStatus, 30 * 1000);
    updateSessionStatus(true)
})

function updateSessionStatus(onFirstLoad) {
    // We need to write the session timings into the page to calculate current/next session.
    // See blueprint_2025.py
    startTime = '2025-11-05T14:45:00+00:00'
    endTime = '2025-11-05T16:00:00+00:00'

    // We take a 8 minute grace period to the start of a session
    const sessionStart = moment(startTime).tz(current_timezone).subtract(8, 'minutes');
    const sessionEnd = moment(endTime).tz(current_timezone);

    const sessionIsCurrent = moment().tz(current_timezone).isBetween(sessionStart, sessionEnd);
    const sessionIsFuture = moment().tz(current_timezone).isBefore(sessionStart);
    const sessionIsPast = moment().tz(current_timezone).isAfter(sessionStart);

    const classesToHide = ['.future_session_alert', '.current_session_alert', '.past_session_alert', '.room_session_stream']
    classesToHide.forEach((c) => { $(c).hide();});
    if (sessionIsCurrent) {
        $('.current_session_alert').show();
    } else if (sessionIsFuture) {
        $('.future_session_alert').show();
    } else {
        // Session is in the future
        $('#zoom_alert').hide();
        $('.past_session_alert').show();
        $('.room_session_stream').show();
    }

    // Update youtube link for older sessions
    // EDIT - We don't need this when the conference isn't live
    if(sessionIsPast){
        const roomidjson = "1_14-"+moment(startTime).format('ddd').toLowerCase()+".json"
        // console.log("this session was in:" , roomidjson)

        return fetch("https://virtual-data.ieeevis.org/"+roomidjson, {cache: "no-store"})
        .then(response => response.json())
        .then(data => {
            //console.log(data)
            // console.log('youtube_url: ' + data.youtube_url)
            //$("ytold").attr("href",data.youtube_url)

            // clear link element to avoid multiple appends
            document.getElementById("ytold").innerHTML = '';

            var a = document.createElement('a'); 
            var link = document.createTextNode(data.youtube_url);  
            a.appendChild(link); 
            a.title = "YouTube Link"; 
            a.href = data.youtube_url; 
            
            document.getElementById("ytold").appendChild(a);
        })
        .catch(error => {
            console.log("err: ", error);
        })
    }
    

}

</script></body></html>