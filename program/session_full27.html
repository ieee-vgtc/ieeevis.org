<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/2.1/auth0-spa-js.production.js"></script><script>
              const auth0_domain = "ieeevis.us.auth0.com";
              const auth0_client_id = "oF5BXUklWOjSjUeg5Tzai2DysHITXYhT";
            </script><script src="/static/2025/js/modules/auth0protect.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2025/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2025/js/data/persistor.js"></script><script src="/static/2025/js/data/api.js"></script><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2025/css/Zilla.css" rel="stylesheet"><link href="/static/2025/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2025/css/main.css"><link rel="stylesheet" href="/static/2025/css/fa_solid.css"><link rel="stylesheet" href="/static/2025/css/lazy_load.css"><link rel="stylesheet" href="/static/2025/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2025 - Session: VIS Full Papers: The Color and the Shape"><meta name="twitter:description" content="See the session and its presentations inside."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="See the session and its presentations inside."><meta name="title" property="og:title" content="Virtual IEEE VIS 2025 - Session: VIS Full Papers: The Color and the Shape"><meta property="og:type" content="website"><title>IEEE VIS 2025 Content: VIS Full Papers: The Color and the Shape</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style="display: none;"><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-8"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item" aria-current="page"><a href="events.html">All events</a></li><li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">The Color and the Shape</li></ol></nav><h1 class="session-title">VIS Full Papers: The Color and the Shape</h1><h3 class="session-url"><a href="https://ieeevis.org/year/2025/program/event_v-full.html" target="_blank"><span class="fas mr-1">&#xf57c;</span> https://ieeevis.org/year/2025/program/event_v-full.html</a></h3><h3 class="session-chair"><span class="fas mr-1">&#xf007;</span> Session chair: Khairi Reda </h3><h3 class="session-room mt-4"> Room: Hall M2 </h3><h3 class="session-date"><span class="fas mr-1">&#xf017;</span><span class="format-date-span-full">2025-11-06T08:30:00+00:00 &ndash; 2025-11-06T09:45:00+00:00</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2025-11-06T08:30:00+00:00 &ndash; 2025-11-06T09:45:00+00:00</span><span class="current-time tztooltiptext"></span></span></h3></div><div class="col-md-1"></div><div class="col-md-3 session-links"><h5 class="session-info my-4"><a href="#list"><span class="fas mr-2">&#xf358;</span> Jump to event listing </a></h5><h5 class="session-info my-4"><a href="https://data.tech.ieeevis.org/storage/v1/object/public/ics/vis2025/full27.ics"><span class="fas mr-2">&#xf073;</span> Add to Calendar</a></h5></div></div><div class="row my-5 discord-public-link hide-auth-controls"><div class="col-md-8"><p><span class="fas mx-1">&#xf086;</span><a href="https://discord.com/channels/1422883912660549696/1430945290818551969" target="_blank">Discord link</a></p></div></div><div class="row my-5"><div class="col-md-8"><p>Recordings will be made available after the session.</p></div></div><hr><div class="row my-4"><div class="col-md-8"><h2 class="room_session_descriptor d-block py-2"><a name="list">Presentations in this session:</a></h2></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1468&#39;, &#39;session_id&#39;: &#39;full27&#39;, &#39;title&#39;: &#39;From Vision to Touch: Bridging Visual and Tactile Principles for Accessible Data Representation&#39;, &#39;contributors&#39;: [&#39;Kim Marriott&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T08:30:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T08:30:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T08:42:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Kim Marriott&#39;, &#39;email&#39;: &#39;kim.marriott@monash.edu&#39;, &#39;affiliation&#39;: &#39;Monash University&#39;}, {&#39;name&#39;: &#39;Matthew Butler&#39;, &#39;email&#39;: &#39;matthew.butler@monash.edu&#39;, &#39;affiliation&#39;: &#39;Monash University&#39;}, {&#39;name&#39;: &#39;Leona Holloway&#39;, &#39;email&#39;: &#39;leona.holloway@monash.edu&#39;, &#39;affiliation&#39;: &#39;Monash University&#39;}, {&#39;name&#39;: &#39;William Jolley&#39;, &#39;email&#39;: &#39;wjolley@bigpond.com&#39;, &#39;affiliation&#39;: &#39;None&#39;}, {&#39;name&#39;: &#39;Bongshin Lee&#39;, &#39;email&#39;: &#39;b.lee@yonsei.ac.kr&#39;, &#39;affiliation&#39;: &#39;Yonsei University&#39;}, {&#39;name&#39;: &#39;Bruce Maguire&#39;, &#39;email&#39;: &#39;bruce.maguire@visionaustralia.org&#39;, &#39;affiliation&#39;: &#39;Vision Australia&#39;}, {&#39;name&#39;: &#39;Danielle Szafir&#39;, &#39;email&#39;: &#39;danielle.szafir@gmail.com&#39;, &#39;affiliation&#39;: &#39;University of North Carolina-Chapel Hill&#39;}], &#39;abstract&#39;: &#39;Tactile graphics are widely used to present maps and statistical diagrams to blind and low vision (BLV) people, with accessibility guidelines recommending their use for graphics where spatial relationships are important. Their use is expected to grow with the advent of commodity refreshable tactile displays. However, in stark contrast to visual information graphics, we lack a clear understanding of the benefits that well-designed tactile information graphics offer over text descriptions for BLV people. To address this gap, we introduce a framework considering the three components of encoding, perception and cognition to examine the known benefits for visual information graphics and explore their applicability to tactile information graphics. This work establishes a preliminary theoretical foundation for the tactile-first design of information graphics and identifies future research avenues.&#39;, &#39;uid&#39;: &#39;544233de-86be-4bc4-ab7e-2e5de7d366b2&#39;, &#39;keywords&#39;: [&#39;Tactile graphic&#39;, &#39;visual perception&#39;, &#39;haptic perception&#39;, &#39;accessible data representation&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_544233de-86be-4bc4-ab7e-2e5de7d366b2.html"> From Vision to Touch: Bridging Visual and Tactile Principles for Accessible Data Representation <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Kim Marriott, Matthew Butler, Leona Holloway, William Jolley, Bongshin Lee, Bruce Maguire, Danielle Szafir </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Kim Marriott </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T08:30:00.000Z &ndash; 2025-11-06T08:42:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1506&#39;, &#39;session_id&#39;: &#39;full27&#39;, &#39;title&#39;: &#39;What is the Color of Serendipity? Investigating the Use of Language Models for Semantically Resonant Color Generation&#39;, &#39;contributors&#39;: [&#39;Shahreen Salim&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T08:42:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T08:42:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T08:54:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Shahreen Salim&#39;, &#39;email&#39;: &#39;ssalimaunti@cs.stonybrook.edu&#39;, &#39;affiliation&#39;: &#39;Stony Brook University&#39;}, {&#39;name&#39;: &#39;Tanzir Pial&#39;, &#39;email&#39;: &#39;tpial@cs.stonybrook.edu&#39;, &#39;affiliation&#39;: &#39;Stony Brook University&#39;}, {&#39;name&#39;: &#39;Klaus Mueller&#39;, &#39;email&#39;: &#39;mueller@cs.sunysb.edu&#39;, &#39;affiliation&#39;: &#39;Stony Brook University&#39;}], &#39;abstract&#39;: &#39;Humans inherently connect certain colors with particular concepts in semantically meaningful ways that facilitate visual communication. These colors are known as semantically resonant colors. For instance, we associate “sky” and “ocean” with shades of blue, and “cherry” with red. In this paper, we investigate how language models, including Word2Vec, RoBERTa, GPT-4o mini and the vision language model CLIP generate and represent nuanced semantically resonant colors for diverse concepts. To achieve this, we utilized a large dataset of color names and concepts, tailored models for the structure of each language model, and developed an interactive web interface, CONCEPT2COLOR, as a use case. Additionally, we conducted experiments and a detailed analysis to assess the ability of these models to generate meaningful colors. Through these experiments, we examined how factors such as model design, training data and context affect the color output. Our findings reveal the capabilities and limitations of language models in processing and generating semantically resonant colors for concepts, thus contributing insights into how they depict semantic color-concept connections. These insights have implications for data visualization, design, and human-computer interaction, where leveraging effective semantic color generation can enhance communication and user experience.&#39;, &#39;uid&#39;: &#39;b00813fe-c0fb-4bdb-8040-b6e338088247&#39;, &#39;keywords&#39;: [&#39;Tabular Data&#39;, &#39;Text/Document Data&#39;, &#39;Datasets&#39;, &#39;Methodologies&#39;, &#39;Software Prototype&#39;, &#39;Domain Agnostic&#39;, &#39;Color Machine Learning Techniques&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_b00813fe-c0fb-4bdb-8040-b6e338088247.html"> What is the Color of Serendipity? Investigating the Use of Language Models for Semantically Resonant Color Generation <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Shahreen Salim, Tanzir Pial, Klaus Mueller </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Shahreen Salim </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T08:42:00.000Z &ndash; 2025-11-06T08:54:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1557&#39;, &#39;session_id&#39;: &#39;full27&#39;, &#39;title&#39;: &#39;Set Size Matters: Capacity-Limited Perception of Grouped Spatial-Frequency Glyphs&#39;, &#39;contributors&#39;: [&#39;Yiran Li&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T08:54:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T08:54:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T09:06:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Yiran Li&#39;, &#39;email&#39;: &#39;yiran.2.li@kcl.ac.uk&#39;, &#39;affiliation&#39;: &#34;King&#39;s College London&#34;}, {&#39;name&#39;: &#39;Shan Shao&#39;, &#39;email&#39;: &#39;shan.shao@kcl.ac.uk&#39;, &#39;affiliation&#39;: &#34;King&#39;s College London&#34;}, {&#39;name&#39;: &#39;Peter Baudains&#39;, &#39;email&#39;: &#39;peter.baudains@kcl.ac.uk&#39;, &#39;affiliation&#39;: &#34;King&#39;s College London&#34;}, {&#39;name&#39;: &#39;Andrew Meso&#39;, &#39;email&#39;: &#39;andrew.meso@kcl.ac.uk&#39;, &#39;affiliation&#39;: &#34;King&#39;s College London&#34;}, {&#39;name&#39;: &#39;Nick Holliman&#39;, &#39;email&#39;: &#39;nickholliman@gmail.com&#39;, &#39;affiliation&#39;: &#34;King&#39;s College London&#34;}, {&#39;name&#39;: &#39;Alfie Abdul-Rahman&#39;, &#39;email&#39;: &#39;alfie.abdulrahman@gmail.com&#39;, &#39;affiliation&#39;: &#34;King&#39;s College London&#34;}, {&#39;name&#39;: &#39;Rita Borgo&#39;, &#39;email&#39;: &#39;rita.borgo@kcl.ac.uk&#39;, &#39;affiliation&#39;: &#39;Kings College London&#39;}], &#39;abstract&#39;: &#39;Recent work suggests that shape can encode quantitative data via a mapping between value and spatial frequency (SF). However, the set-size effect when perceiving multiple SF based items remains unclear. While automatic feature extraction has been found to be less affected by set size (number of items in a group), higher-level processes for making perceptual decisions tend to require increased cognitive demand. To investigate the set-size effect on comparing integrated SF based items, we used a risk-based scenario to assess discrimination performance. Participants were asked to discriminate between pairs of maps containing multiple SF glyphs, in which each glyph represents one of four discrete levels (none, low, medium, high), forming an aggregate “risk strength” per map. The set size was also adjusted across conditions, ranging from small (3 items) to large (7 items). Discrimination sensitivity is modeled with a logistic function and response time with a mixed-effect linear model. Results show that smaller set sizes and lower overall strength enable more precise discrimination, with faster response times for larger differences between maps. Incorporating set size and overall strength into the logistic model, we found that these variables both independently and jointly influence discrimination sensitivity. We suggest these results point towards capacity-limited processes rather than purely automatic ensemble coding. Our findings highlight the importance of set size and overall signal strength when presenting multiple SF glyphs in data visualization.&#39;, &#39;uid&#39;: &#39;1acd711b-69a4-486f-9955-0f6adb58292b&#39;, &#39;keywords&#39;: [&#39;Radial spatial frequency&#39;, &#39;Vizent glyph&#39;, &#39;set size&#39;, &#39;visual discrimination&#39;, &#39;aggregation&#39;, &#39;psychometric function&#39;], &#39;preprint_link&#39;: &#39;https://kclpure.kcl.ac.uk/portal/en/publications/set-size-matters-capacity-limited-perception-of-grouped-spatial-f&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_1acd711b-69a4-486f-9955-0f6adb58292b.html"> Set Size Matters: Capacity-Limited Perception of Grouped Spatial-Frequency Glyphs <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Yiran Li, Shan Shao, Peter Baudains, Andrew Meso, Nick Holliman, Alfie Abdul-Rahman, Rita Borgo </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Yiran Li </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T08:54:00.000Z &ndash; 2025-11-06T09:06:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1682&#39;, &#39;session_id&#39;: &#39;full27&#39;, &#39;title&#39;: &#39;Affective color scales for colormap data visualizations&#39;, &#39;contributors&#39;: [&#39;Halle Braun&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T09:06:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T09:06:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T09:18:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Halle Braun&#39;, &#39;email&#39;: &#39;hbraun5@wisc.edu&#39;, &#39;affiliation&#39;: &#39;University of Wisconsin - Madison&#39;}, {&#39;name&#39;: &#39;Kushin Mukherjee&#39;, &#39;email&#39;: &#39;kushinm11@gmail.com&#39;, &#39;affiliation&#39;: &#39;University of Wisconsin-Madison&#39;}, {&#39;name&#39;: &#39;Seth Gorelik&#39;, &#39;email&#39;: &#39;sgorelik@woodwellclimate.org&#39;, &#39;affiliation&#39;: &#39;Woodwell Climate Research Center&#39;}, {&#39;name&#39;: &#39;Karen Schloss&#39;, &#39;email&#39;: &#39;kschloss@wisc.edu&#39;, &#39;affiliation&#39;: &#39;University of Wisconsin - Madison&#39;}], &#39;abstract&#39;: &#39;Research on affective visualization design has shown that color is an especially powerful feature for influencing the emotional connotation of visualizations. Associations between colors and emotions are largely driven by lightness (e.g., lighter colors are associated with positive emotions, whereas darker colors are associated with negative emotions). Designing visualizations to have all light or all dark colors to convey particular emotions may work well for visualizations in which colors represent categories and spatial channels encode data values. However, this approach poses a problem for visualizations that use color to represent spatial patterns in data (e.g., colormap data visualizations) because lightness contrast is needed to reveal fine details in spatial structure. In this study, we found it is possible to design colormaps that have strong lightness contrast to support spatial vision while communicating clear affective connotation. We also found that affective connotation depended not only on the color scales used to construct the colormaps, but also the frequency with which colors appeared in the map, as determined by the underlying dataset (data-dependence hypothesis). These results emphasize the importance of data-aware design, which accounts for not only the design features that encode data (e.g., colors, shapes, textures), but also how those design features are instantiated in a visualization, given the properties of the data.&#39;, &#39;uid&#39;: &#39;c9fcc45e-0f81-49be-817e-b813e0b61c89&#39;, &#39;keywords&#39;: [&#39;Visual reasoning&#39;, &#39;visual communication&#39;, &#39;color cognition&#39;, &#39;affective science&#39;, &#39;emotion&#39;, &#39;scalar field&#39;, &#39;data-aware design&#39;], &#39;preprint_link&#39;: &#39;https://osf.io/preprints/osf/p3bva_v1&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: &#39;We have posted all of our data and analysis code on GitHub and have documented our code.&#39;, &#39;open_access_supplemental_link&#39;: &#39;https://github.com/SchlossVRL/color_scales_affect&#39;} <h3 class="session-list-title"><a href="paper_c9fcc45e-0f81-49be-817e-b813e0b61c89.html"> Affective color scales for colormap data visualizations <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Halle Braun, Kushin Mukherjee, Seth Gorelik, Karen Schloss </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Halle Braun </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T09:06:00.000Z &ndash; 2025-11-06T09:18:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1755&#39;, &#39;session_id&#39;: &#39;full27&#39;, &#39;title&#39;: &#39;The Hue-Man Factor: An Empirical Evaluation of Visualization Perception and Accessibility Across Color Vision Profiles&#39;, &#39;contributors&#39;: [&#39;Zhuojun Jiang&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T09:18:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T09:18:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T09:30:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Zhuojun Jiang&#39;, &#39;email&#39;: &#39;zjian115@asu.edu&#39;, &#39;affiliation&#39;: &#39;Arizona State University&#39;}, {&#39;name&#39;: &#39;Anjana Arunkumar&#39;, &#39;email&#39;: &#39;aarunku5@asu.edu&#39;, &#39;affiliation&#39;: &#39;Northeastern University&#39;}, {&#39;name&#39;: &#39;Chris Bryan&#39;, &#39;email&#39;: &#39;cbryan16@asu.edu&#39;, &#39;affiliation&#39;: &#39;Arizona State University&#39;}], &#39;abstract&#39;: &#39;Color is a powerful tool in data visualization, but for individuals with color vision deficiencies (CVD), hue can become a barrier rather than an aid. In this paper, we examine how real-world visualizations are perceived across vision profiles through three complementary studies. Study 1 assessed how normal vision participants rated 46 visualizations shown in original and simulated red/green colorblind versions. Study 2 collected matched responses from participants with diagnosed CVD. Study 3 involved in-depth interviews exploring how users interpret, adapt to, and evaluate inaccessible designs. Across studies, we find that simulations capture directional perceptual shifts but fail to reflect the interpretive breakdowns and emotional work described by real CVD users. Factor analysis reveals two dominant perceptual dimensions: functional utility and affective experience. While normal vision participants prioritize functional clarity, CVD users rely more on structural cues and emotional resonance, particularly when color is unreliable. Qualitative insights show that perceptual breakdowns occur not only in high-interference charts but also when redundant encoding or layout scaffolding is missing. We synthesize these findings and offer empirically grounded design recommendations to guide inclusive visualization practices. Our results argue that accessibility must go beyond color correction, embracing structural clarity, redundancy, and real-user validation to ensure inclusive visual communication.&#39;, &#39;uid&#39;: &#39;093872c4-bec7-4c27-bb8e-c89465a4381b&#39;, &#39;keywords&#39;: [&#39;Information Visualization&#39;, &#39;Perception &amp; Cognition&#39;, &#39;Colorblindness&#39;, &#39;Accessibility&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://osf.io/ymucn/&#39;} <h3 class="session-list-title"><a href="paper_093872c4-bec7-4c27-bb8e-c89465a4381b.html"> The Hue-Man Factor: An Empirical Evaluation of Visualization Perception and Accessibility Across Color Vision Profiles <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Zhuojun Jiang, Anjana Arunkumar, Chris Bryan </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Zhuojun Jiang </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T09:18:00.000Z &ndash; 2025-11-06T09:30:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-2006&#39;, &#39;session_id&#39;: &#39;full27&#39;, &#39;title&#39;: &#39;PiCCL: Data-Driven Mark Composition of Bespoke Pictorial Chart&#39;, &#39;contributors&#39;: [&#39;Haoyan Shi&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T09:30:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T09:30:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T09:42:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Haoyan Shi&#39;, &#39;email&#39;: &#39;202315173@mail.sdu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Shandong University&#39;}, {&#39;name&#39;: &#39;Yunhai Wang&#39;, &#39;email&#39;: &#39;cloudseawang@gmail.com&#39;, &#39;affiliation&#39;: &#39;Renmin University of China&#39;}, {&#39;name&#39;: &#39;Junhao Chen&#39;, &#39;email&#39;: &#39;chenjunhao11@ruc.edu.cn&#39;, &#39;affiliation&#39;: &#39;Renmin University of China&#39;}, {&#39;name&#39;: &#39;Chenglong Wang&#39;, &#39;email&#39;: &#39;clwang15uw@gmail.com&#39;, &#39;affiliation&#39;: &#39;Microsoft Research&#39;}, {&#39;name&#39;: &#39;Bongshin Lee&#39;, &#39;email&#39;: &#39;b.lee@yonsei.ac.kr&#39;, &#39;affiliation&#39;: &#39;Yonsei University&#39;}], &#39;abstract&#39;: &#39;We present PiCCL (Pictorial Chart Composition Language), a new language that enables users to easily create pictorial charts using a set of simple operators. To support systematic construction while addressing the main challenge of expressive pictorial chart authoring–manual composition and fine-tuning of visual properties–PiCCL introduces a parametric representation that integrates data-driven chart generation with graphical composition. It also employs a lazy data-binding mechanism that automatically synthesizes charts. PiCCL is grounded in a comprehensive analysis of real-world pictorial chart examples. We describe PiCCL’s design and its implementation as piccl.js, a JavaScript-based library. To evaluate PiCCL, we showcase a gallery that demonstrates its expressiveness and report findings from a user study assessing the usability of piccl.js. We conclude with a discussion of PiCCL’s limitations and potential, as well as future research directions.&#39;, &#39;uid&#39;: &#39;1513daf8-e0da-48f1-b800-f7b0975869ff&#39;, &#39;keywords&#39;: [&#39;pictorial charts&#39;, &#39;data-driven composition&#39;, &#39;chart composition&#39;, &#39;parametric representation&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://osf.io/5eqb7&#39;} <h3 class="session-list-title"><a href="paper_1513daf8-e0da-48f1-b800-f7b0975869ff.html"> PiCCL: Data-Driven Mark Composition of Bespoke Pictorial Chart <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Haoyan Shi, Yunhai Wang, Junhao Chen, Chenglong Wang, Bongshin Lee </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Haoyan Shi </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T09:30:00.000Z &ndash; 2025-11-06T09:42:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row my-5"><div class="col-md-8"><p>You may want to also jump to the parent event to see related presentations: <a href="event_v-full.html">VIS Full Papers</a></p></div></div><script src="/static/2025/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script><script>

$(document).ready(function() {
    setInterval(updateSessionStatus, 30 * 1000);
    updateSessionStatus(true)
})

function updateSessionStatus(onFirstLoad) {
    // We need to write the session timings into the page to calculate current/next session.
    // See blueprint_2025.py
    startTime = '2025-11-06T08:30:00+00:00'
    endTime = '2025-11-06T09:45:00+00:00'

    // We take a 8 minute grace period to the start of a session
    const sessionStart = moment(startTime).tz(current_timezone).subtract(8, 'minutes');
    const sessionEnd = moment(endTime).tz(current_timezone);

    const sessionIsCurrent = moment().tz(current_timezone).isBetween(sessionStart, sessionEnd);
    const sessionIsFuture = moment().tz(current_timezone).isBefore(sessionStart);
    const sessionIsPast = moment().tz(current_timezone).isAfter(sessionStart);

    const classesToHide = ['.future_session_alert', '.current_session_alert', '.past_session_alert', '.room_session_stream']
    classesToHide.forEach((c) => { $(c).hide();});
    if (sessionIsCurrent) {
        $('.current_session_alert').show();
    } else if (sessionIsFuture) {
        $('.future_session_alert').show();
    } else {
        // Session is in the future
        $('#zoom_alert').hide();
        $('.past_session_alert').show();
        $('.room_session_stream').show();
    }

    // Update youtube link for older sessions
    // EDIT - We don't need this when the conference isn't live
    if(sessionIsPast){
        const roomidjson = "m2-"+moment(startTime).format('ddd').toLowerCase()+".json"
        // console.log("this session was in:" , roomidjson)

        return fetch("https://virtual-data.ieeevis.org/"+roomidjson, {cache: "no-store"})
        .then(response => response.json())
        .then(data => {
            //console.log(data)
            // console.log('youtube_url: ' + data.youtube_url)
            //$("ytold").attr("href",data.youtube_url)

            // clear link element to avoid multiple appends
            document.getElementById("ytold").innerHTML = '';

            var a = document.createElement('a'); 
            var link = document.createTextNode(data.youtube_url);  
            a.appendChild(link); 
            a.title = "YouTube Link"; 
            a.href = data.youtube_url; 
            
            document.getElementById("ytold").appendChild(a);
        })
        .catch(error => {
            console.log("err: ", error);
        })
    }
    

}

</script></body></html>