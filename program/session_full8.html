<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/2.1/auth0-spa-js.production.js"></script><script>
              const auth0_domain = "ieeevis.us.auth0.com";
              const auth0_client_id = "oF5BXUklWOjSjUeg5Tzai2DysHITXYhT";
            </script><script src="/static/2025/js/modules/auth0protect.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2025/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2025/js/data/persistor.js"></script><script src="/static/2025/js/data/api.js"></script><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2025/css/Zilla.css" rel="stylesheet"><link href="/static/2025/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2025/css/main.css"><link rel="stylesheet" href="/static/2025/css/fa_solid.css"><link rel="stylesheet" href="/static/2025/css/lazy_load.css"><link rel="stylesheet" href="/static/2025/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2025 - Session: VIS Full Papers: Biomedical Visualization"><meta name="twitter:description" content="See the session and its presentations inside."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="See the session and its presentations inside."><meta name="title" property="og:title" content="Virtual IEEE VIS 2025 - Session: VIS Full Papers: Biomedical Visualization"><meta property="og:type" content="website"><title>IEEE VIS 2025 Content: VIS Full Papers: Biomedical Visualization</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style="display: none;"><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-8"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item" aria-current="page"><a href="events.html">All events</a></li><li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">Biomedical Visualization</li></ol></nav><h1 class="session-title">VIS Full Papers: Biomedical Visualization</h1><h3 class="session-url"><a href="https://ieeevis.org/year/2025/program/event_v-full.html" target="_blank"><span class="fas mr-1">&#xf57c;</span> https://ieeevis.org/year/2025/program/event_v-full.html</a></h3><h3 class="session-chair"><span class="fas mr-1">&#xf007;</span> Session chair: Sungbok Shin </h3><h3 class="session-room mt-4"> Room: Hall M1 </h3><h3 class="session-date"><span class="fas mr-1">&#xf017;</span><span class="format-date-span-full">2025-11-06T14:45:00+00:00 &ndash; 2025-11-06T16:00:00+00:00</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2025-11-06T14:45:00+00:00 &ndash; 2025-11-06T16:00:00+00:00</span><span class="current-time tztooltiptext"></span></span></h3></div><div class="col-md-1"></div><div class="col-md-3 session-links"><h5 class="session-info my-4"><a href="#list"><span class="fas mr-2">&#xf358;</span> Jump to event listing </a></h5><h5 class="session-info my-4"><a href="https://data.tech.ieeevis.org/storage/v1/object/public/ics/vis2025/full8.ics"><span class="fas mr-2">&#xf073;</span> Add to Calendar</a></h5></div></div><div class="row my-5 discord-public-link hide-auth-controls"><div class="col-md-8"><p><span class="fas mx-1">&#xf086;</span><a href="https://discord.com/channels/1422883912660549696/1430945302608609290" target="_blank">Discord link</a></p></div></div><div class="row my-5"><div class="col-md-8"><p>Recordings will be made available after the session.</p></div></div><hr><div class="row my-4"><div class="col-md-8"><h2 class="room_session_descriptor d-block py-2"><a name="list">Presentations in this session:</a></h2></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1204&#39;, &#39;session_id&#39;: &#39;full8&#39;, &#39;title&#39;: &#39;BDIViz: An Interactive Visualization System for Biomedical Schema Matching with LLM-Powered Validation&#39;, &#39;contributors&#39;: [&#39;Eden Wu&#39;, &#39;Juliana Freire&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T14:45:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T14:45:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T14:57:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Eden Wu&#39;, &#39;email&#39;: &#39;eden.wu@nyu.edu&#39;, &#39;affiliation&#39;: &#39;New York University&#39;}, {&#39;name&#39;: &#39;Dishita Turakhia&#39;, &#39;email&#39;: &#39;d.turakhia@nyu.edu&#39;, &#39;affiliation&#39;: &#39;New York University&#39;}, {&#39;name&#39;: &#39;Guande Wu&#39;, &#39;email&#39;: &#39;guandewu@nyu.edu&#39;, &#39;affiliation&#39;: &#39;New York University&#39;}, {&#39;name&#39;: &#39;Christos Koutras&#39;, &#39;email&#39;: &#39;christos.koutras@nyu.edu&#39;, &#39;affiliation&#39;: &#39;New York University&#39;}, {&#39;name&#39;: &#39;Sarah Keegan&#39;, &#39;email&#39;: &#39;sarah.keegan@nyulangone.org&#39;, &#39;affiliation&#39;: &#39;New York University School of Medicine&#39;}, {&#39;name&#39;: &#39;Wenke Liu&#39;, &#39;email&#39;: &#39;wenke.liu@nyulangone.org&#39;, &#39;affiliation&#39;: &#39;New York University School of Medicine&#39;}, {&#39;name&#39;: &#39;Beata Szeitz&#39;, &#39;email&#39;: &#39;beata.szeitz@nyulangone.org&#39;, &#39;affiliation&#39;: &#39;NYU Grossman School of Medicine&#39;}, {&#39;name&#39;: &#39;David Fenyo&#39;, &#39;email&#39;: &#39;david.fenyo@nyulangone.org&#39;, &#39;affiliation&#39;: &#39;NYU Grossman School of Medicine&#39;}, {&#39;name&#39;: &#39;Claudio Silva&#39;, &#39;email&#39;: &#39;csilva@nyu.edu&#39;, &#39;affiliation&#39;: &#39;New York University&#39;}, {&#39;name&#39;: &#39;Juliana Freire&#39;, &#39;email&#39;: &#39;juliana.freire@nyu.edu&#39;, &#39;affiliation&#39;: &#39;New York University&#39;}], &#39;abstract&#39;: &#39;Biomedical data harmonization is essential for enabling exploratory analyses and meta-studies, but the process of schema matching—identifying semantic correspondences between elements of disparate datasets (schemas)—remains a labor-intensive and error-prone task. Even state-of-the-art automated methods often yield low accuracy when applied to biomedical schemas due to the large number of attributes and nuanced semantic differences between them. We present BDIViz, a novel visual analytics system designed to streamline the schema matching process for biomedical data. Through formative studies with domain experts, we identified key requirements for an effective solution and developed interactive visualization techniques that address both scalability challenges and semantic ambiguity. BDIViz employs an ensemble approach that combines multiple matching methods with LLM-based validation, summarizes matches through interactive heatmaps, and provides coordinated views that enable users to quickly compare attributes and their values. Our method-agnostic design allows the system to integrate various schema matching algorithms and adapt to application-specific needs. Through two biomedical case studies and a within-subject user study with domain experts, we demonstrate that BDIViz significantly improves matching accuracy while reducing cognitive load and curation time compared to baseline approaches.&#39;, &#39;uid&#39;: &#39;e8f720e9-fa87-43c1-9d57-b8cc150f3cd3&#39;, &#39;keywords&#39;: [&#39;Schema matching&#39;, &#39;Biomedical data harmonization&#39;, &#39;Data visualization&#39;, &#39;User-in-the-loop&#39;, &#39;LLM-based schema matching&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2507.16117&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: &#39;Our work provides a reproducible pipeline, including thoroughly documented source code, public Docker images for streamlined deployment, and a live server that allows users to directly interact with the system. We also share source code, experiment datasets, and other supplemental materials to ensure transparency and enable others to re-analyze or extend our results.&#39;, &#39;open_access_supplemental_link&#39;: &#39;https://github.com/VIDA-NYU/bdi-viz&#39;} <h3 class="session-list-title"><a href="paper_e8f720e9-fa87-43c1-9d57-b8cc150f3cd3.html"> BDIViz: An Interactive Visualization System for Biomedical Schema Matching with LLM-Powered Validation <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Eden Wu, Dishita Turakhia, Guande Wu, Christos Koutras, Sarah Keegan, Wenke Liu, Beata Szeitz, David Fenyo, Claudio Silva, Juliana Freire </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Eden Wu, Juliana Freire </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T14:45:00.000Z &ndash; 2025-11-06T14:57:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1247&#39;, &#39;session_id&#39;: &#39;full8&#39;, &#39;title&#39;: &#39;TrajLens: Visual Analysis for Constructing Cell Developmental Trajectories in Cross-Sample Exploration&#39;, &#39;contributors&#39;: [&#39;Qipeng Wang&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T14:57:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T14:57:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T15:09:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Qipeng Wang&#39;, &#39;email&#39;: &#39;wangqipengscu@stu.scu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Sichuan University&#39;}, {&#39;name&#39;: &#39;Shaolun Ruan&#39;, &#39;email&#39;: &#39;haywardryan@foxmail.com&#39;, &#39;affiliation&#39;: &#39;Singapore Management University&#39;}, {&#39;name&#39;: &#39;Rui Sheng&#39;, &#39;email&#39;: &#39;rshengac@connect.ust.hk&#39;, &#39;affiliation&#39;: &#39;The Hong Kong University of Science and Technology&#39;}, {&#39;name&#39;: &#39;Yong WANG&#39;, &#39;email&#39;: &#39;yong-wang@ntu.edu.sg&#39;, &#39;affiliation&#39;: &#39;Nanyang Technological University&#39;}, {&#39;name&#39;: &#39;Min Zhu&#39;, &#39;email&#39;: &#39;zhumin@scu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Sichuan University&#39;}, {&#39;name&#39;: &#39;Huamin Qu&#39;, &#39;email&#39;: &#39;huamin@cse.ust.hk&#39;, &#39;affiliation&#39;: &#39;The Hong Kong University of Science and Technology&#39;}], &#39;abstract&#39;: &#34;Constructing cell developmental trajectories is a critical task in single-cell RNA sequencing (scRNA-seq) analysis, enabling the inference of potential cellular progression paths. However, current automated methods are limited to establishing cell developmental trajectories within individual samples, necessitating biologists to manually link cells across samples to construct complete cross-sample evolutionary trajectories that consider cellular spatial dynamics. This process demands substantial human effort due to the complex spatial correspondence between each pair of samples.\nTo address this challenge, we first proposed a GNN-based model to predict cross-sample cell developmental trajectories. We then developed TrajLens, a visual analytics system that supports biologists in exploring and refining the cell developmental trajectories based on predicted links. Specifically, we designed the visualization that integrates features on cell distribution and developmental direction across multiple samples, providing an overview of the spatial evolutionary patterns of cell populations along trajectories. Additionally, we included contour maps superimposed on the original cell distribution data, enabling biologists to explore them intuitively. To demonstrate our system&#39;s performance, we conducted quantitative evaluations of our model with two case studies and expert interviews to validate its usefulness and effectiveness.&#34;, &#39;uid&#39;: &#39;9d6c7874-e4fa-449b-88aa-4b3937241e7d&#39;, &#39;keywords&#39;: [&#39;Visual Analytics&#39;, &#39;Single-cell RNA Sequencing&#39;, &#39;Cell Developmental Trajectories&#39;], &#39;preprint_link&#39;: &#39;http://arxiv.org/abs/2507.15620&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://doi.org/10.17605/OSF.IO/ETFJ2&#39;} <h3 class="session-list-title"><a href="paper_9d6c7874-e4fa-449b-88aa-4b3937241e7d.html"> TrajLens: Visual Analysis for Constructing Cell Developmental Trajectories in Cross-Sample Exploration <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Qipeng Wang, Shaolun Ruan, Rui Sheng, Yong WANG, Min Zhu, Huamin Qu </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Qipeng Wang </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T14:57:00.000Z &ndash; 2025-11-06T15:09:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1291&#39;, &#39;session_id&#39;: &#39;full8&#39;, &#39;title&#39;: &#39;TrialCompass: Visual Analytics for Enhancing the Eligibility Criteria Design of Clinical Trials&#39;, &#39;contributors&#39;: [&#39;Rui Sheng&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T15:09:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T15:09:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T15:21:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Rui Sheng&#39;, &#39;email&#39;: &#39;rshengac@connect.ust.hk&#39;, &#39;affiliation&#39;: &#39;The Hong Kong University of Science and Technology&#39;}, {&#39;name&#39;: &#39;Xingbo Wang&#39;, &#39;email&#39;: &#39;wangxbzb@gmail.com&#39;, &#39;affiliation&#39;: &#39;Bosch Research North America &amp; Bosch Center for Artificial Intelligence (BCAI)&#39;}, {&#39;name&#39;: &#39;Jiachen Wang&#39;, &#39;email&#39;: &#39;wangjiachen@zju.edu.cn&#39;, &#39;affiliation&#39;: &#39;Zhejiang University&#39;}, {&#39;name&#39;: &#39;Xiaofu Jin&#39;, &#39;email&#39;: &#39;suffvier@gmail.com&#39;, &#39;affiliation&#39;: &#39;The Hong Kong University of Science and Technology&#39;}, {&#39;name&#39;: &#39;Zhonghua SHENG&#39;, &#39;email&#39;: &#39;szh@connect.ust.hk&#39;, &#39;affiliation&#39;: &#39;The Hong Kong University of Science and Technology&#39;}, {&#39;name&#39;: &#39;Zhenxing Xu&#39;, &#39;email&#39;: &#39;zhx2005@med.cornell.edu&#39;, &#39;affiliation&#39;: &#39;Weill Cornell Medical College&#39;}, {&#39;name&#39;: &#39;Suraj Rajendran&#39;, &#39;email&#39;: &#39;sur4002@med.cornell.edu&#39;, &#39;affiliation&#39;: &#39;Weill Cornell Medical College&#39;}, {&#39;name&#39;: &#39;Huamin Qu&#39;, &#39;email&#39;: &#39;huamin@cse.ust.hk&#39;, &#39;affiliation&#39;: &#39;The Hong Kong University of Science and Technology&#39;}, {&#39;name&#39;: &#39;Fei Wang&#39;, &#39;email&#39;: &#39;few2001@med.cornell.edu&#39;, &#39;affiliation&#39;: &#39;Weill Cornell Medicine&#39;}], &#39;abstract&#39;: &#39;Eligibility criteria play a critical role in clinical trials by determining the target patient population, which significantly influences the outcomes of medical interventions. However, current approaches for designing eligibility criteria have limitations to support interactive exploration of the large space of eligibility criteria. They also ignore incorporating detailed characteristics from the original electronic health record (EHR) data for criteria refinement. To address these limitations, we proposed TrialCompass, a visual analytics system integrating a novel workflow, which can empower clinicians to iteratively explore the vast space of eligibility criteria through knowledge-driven and outcome-driven approaches. TrialCompass supports history-tracking to help clinicians trace the evolution of their adjustments and decisions when exploring various forms of data (i.e., eligibility criteria, outcome metrics, and detailed characteristics of original EHR data) through these two approaches. This feature can help clinicians comprehend the impact of eligibility criteria on outcome metrics and patient characteristics, which facilitates systematic refinement of eligibility criteria. Using a real-world dataset, we demonstrated the effectiveness of TrialCompass in providing insights into designing eligibility criteria for septic shock and sepsis-associated acute kidney injury. We also discussed the research prospects of applying visual analytics to clinical trials.&#39;, &#39;uid&#39;: &#39;3f0a5ad9-2440-47b4-a741-f6b92c58bf8d&#39;, &#39;keywords&#39;: [&#39;Visual Analytics&#39;, &#39;Healthcare&#39;, &#39;Clinical Trials&#39;, &#39;Decision Making&#39;, &#39;Electronic Health Record (EHR)&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/pdf/2507.12298&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_3f0a5ad9-2440-47b4-a741-f6b92c58bf8d.html"> TrialCompass: Visual Analytics for Enhancing the Eligibility Criteria Design of Clinical Trials <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Rui Sheng, Xingbo Wang, Jiachen Wang, Xiaofu Jin, Zhonghua SHENG, Zhenxing Xu, Suraj Rajendran, Huamin Qu, Fei Wang </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Rui Sheng </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T15:09:00.000Z &ndash; 2025-11-06T15:21:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1426&#39;, &#39;session_id&#39;: &#39;full8&#39;, &#39;title&#39;: &#39;Understanding Aortic Dissection Hemodynamics: Evaluating Adapted Smoke Surfaces Against Streakline-Based Techniques&#39;, &#39;contributors&#39;: [&#39;Aaron Schroeder&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T15:21:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T15:21:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T15:33:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Aaron Schroeder&#39;, &#39;email&#39;: &#39;aar.schr@gmail.com&#39;, &#39;affiliation&#39;: &#39;Otto-von-Guericke-University&#39;}, {&#39;name&#39;: &#39;Kai Ostendorf&#39;, &#39;email&#39;: &#39;kai.ostendorf@st.ovgu.de&#39;, &#39;affiliation&#39;: &#39;Otto-von-Guericke University&#39;}, {&#39;name&#39;: &#39;Kathrin Baeumler&#39;, &#39;email&#39;: &#39;baeumler@stanford.edu&#39;, &#39;affiliation&#39;: &#39;Stanford University School of Medicine&#39;}, {&#39;name&#39;: &#39;Domenico Mastrodicasa&#39;, &#39;email&#39;: &#39;mastro@stanford.edu&#39;, &#39;affiliation&#39;: &#39;Stanford University&#39;}, {&#39;name&#39;: &#39;Dominik Fleischmann&#39;, &#39;email&#39;: &#39;d.fleischmann@stanford.edu&#39;, &#39;affiliation&#39;: &#39;Stanford University School of Medicine&#39;}, {&#39;name&#39;: &#39;Bernhard Preim&#39;, &#39;email&#39;: &#39;bernhard@isg.cs.uni-magdeburg.de&#39;, &#39;affiliation&#39;: &#39;University of Magdeburg&#39;}, {&#39;name&#39;: &#39;Holger Theisel&#39;, &#39;email&#39;: &#39;theisel@ovgu.de&#39;, &#39;affiliation&#39;: &#39;University of Magdeburg&#39;}, {&#39;name&#39;: &#39;Gabriel Mistelbauer&#39;, &#39;email&#39;: &#39;gmistelb@stanford.edu&#39;, &#39;affiliation&#39;: &#39;Stanford University School of Medicine&#39;}], &#39;abstract&#39;: &#39;Aortic dissection is a life-threatening cardiovascular disease characterized by blood entering the media layer of the aortic vessel wall. This creates a second flow channel, known as the false lumen, which weakens the aortic wall and can potentially lead to fatal aortic rupture. Current risk stratification of aortic dissections is primarily based on morphological features of the aorta. However, hemodynamics also play a significant role in disease progression, though their investigation and visualization remain challenging. Common flow visualizations often experience visual clutter, especially when dealing with the intricate morphologies of aortic dissections. In this work, we implement and evaluate different approaches to visualizing the flow in aortic dissections effectively. We employ three techniques, namely streaklines with depth-dependent halos, transparent streaklines, and smoke surfaces. The latter is a technique based on streak surfaces, enhanced with opacity modulations, to produce a smoke-like appearance that improves visual clarity. We adapt the original opacity modulation of smoke surfaces to visualize flow even within the complex geometries of aortic dissections, thereby enhancing visual fidelity. To effectively capture dissection hemodynamics, we developed customized seeding structures that adapt to the shape of the surrounding lumen. Our evaluation, conducted via an online questionnaire, included medical professionals, fluid simulation experts, and visualization specialists. By analyzing results across these groups, we highlight differences in preference and interpretability, offering insight into domain-specific needs. No single visualization technique emerged as the best overall. Smoke surfaces provide the best overall clarity and visual realism. However, participants found streaklines with halos to be the best for quantifying flow, dispite them introducing significant visual clutter. Transparent streaklines serve as a middle ground, offering improved clarity over halos while maintaining some level of detail. Across all participant groups, smoke surfaces were rated as the most visually appealing and lifelike, with medical professionals highlighting their resemblance to contrast-agent injections used in clinical practice.&#39;, &#39;uid&#39;: &#39;7b762da7-ec92-461b-ab0a-95e7e278234d&#39;, &#39;keywords&#39;: [&#39;Medical Visualization&#39;, &#39;Flow Visualization&#39;, &#39;Hemodynamics&#39;, &#39;Aortic Dissection.&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: &#39;https://github.com/aaschr/vis_2025_smoke_surfaces_for_AD&#39;} <h3 class="session-list-title"><a href="paper_7b762da7-ec92-461b-ab0a-95e7e278234d.html"> Understanding Aortic Dissection Hemodynamics: Evaluating Adapted Smoke Surfaces Against Streakline-Based Techniques <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Aaron Schroeder, Kai Ostendorf, Kathrin Baeumler, Domenico Mastrodicasa, Dominik Fleischmann, Bernhard Preim, Holger Theisel, Gabriel Mistelbauer </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Aaron Schroeder </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T15:21:00.000Z &ndash; 2025-11-06T15:33:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1787&#39;, &#39;session_id&#39;: &#39;full8&#39;, &#39;title&#39;: &#39;An Intelligent Interactive Visual Analytics System for Exploring Large and Multi-Scale Pathology Images&#39;, &#39;contributors&#39;: [&#39;Ruiqi Yang&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T15:33:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T15:33:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T15:45:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Chaoqing Xu&#39;, &#39;email&#39;: &#39;xucq@hzcu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Hangzhou City University&#39;}, {&#39;name&#39;: &#39;Ruiqi Yang&#39;, &#39;email&#39;: &#39;rickyyang0113@gmail.com&#39;, &#39;affiliation&#39;: &#39;Zhejiang University&#39;}, {&#39;name&#39;: &#39;Weihan Li&#39;, &#39;email&#39;: &#39;leewh@zju.edu.cn&#39;, &#39;affiliation&#39;: &#39;Zhejiang University&#39;}, {&#39;name&#39;: &#39;Xinyuan Fu&#39;, &#39;email&#39;: &#39;xinyuanfu0421@gmail.com&#39;, &#39;affiliation&#39;: &#39;School of Computer and Computing Science, Hangzhou City University&#39;}, {&#39;name&#39;: &#39;Liting Fang&#39;, &#39;email&#39;: &#39;flting.amanda@gmail.com&#39;, &#39;affiliation&#39;: &#39;School of Computer and Computing Science, Hangzhou City University&#39;}, {&#39;name&#39;: &#39;Zunlei Feng&#39;, &#39;email&#39;: &#39;zunleifeng@zju.edu.cn&#39;, &#39;affiliation&#39;: &#39;Zhejiang University&#39;}, {&#39;name&#39;: &#39;Can Wang&#39;, &#39;email&#39;: &#39;wcan@zju.edu.cn&#39;, &#39;affiliation&#39;: &#39;Zhejiang University&#39;}, {&#39;name&#39;: &#39;Mingli Song&#39;, &#39;email&#39;: &#39;songml@zju.edu.cn&#39;, &#39;affiliation&#39;: &#39;Hangzhou City University&#39;}, {&#39;name&#39;: &#39;Wei Chen&#39;, &#39;email&#39;: &#39;chenvis@zju.edu.cn&#39;, &#39;affiliation&#39;: &#39;Zhejiang University&#39;}], &#39;abstract&#39;: &#34;Pathology images are crucial for cancer diagnosis and treatment. Although artificial intelligence has driven rapid advancements in pathology image analysis, the interpretation of ultra-large and multi-scale pathology images in clinical practice still heavily relies on physicians&#39; experience. Clinicians need to repeatedly zoom in and out on individual slides to compare and assess pathological details — a process that is both time-consuming and prone to visual fatigue. The system first employs a diffusion model to perform tissue segmentation on pathology images, then calculates pathological tissue proportions and morphological metrics. Finally, through multi-scale dynamic comparison and multi-level visual evaluation, the system facilitates comprehensive and precise analysis of pathology images. The system provides clinicians with an intelligent and interactive tool for pathology image interpretation, enabling efficient visualization and precise analysis of pathological details, thereby reducing the effort require for detailed analysis.&#34;, &#39;uid&#39;: &#39;3ca02fd1-d387-44fa-b576-413ea269d949&#39;, &#39;keywords&#39;: [&#39;Pathology Image&#39;, &#39;Diffusion Model&#39;, &#39;Large-Scale&#39;, &#39;Visual Analytics&#39;, &#39;Interactive Exploration&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_3ca02fd1-d387-44fa-b576-413ea269d949.html"> An Intelligent Interactive Visual Analytics System for Exploring Large and Multi-Scale Pathology Images <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Chaoqing Xu, Ruiqi Yang, Weihan Li, Xinyuan Fu, Liting Fang, Zunlei Feng, Can Wang, Mingli Song, Wei Chen </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Ruiqi Yang </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T15:33:00.000Z &ndash; 2025-11-06T15:45:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1893&#39;, &#39;session_id&#39;: &#39;full8&#39;, &#39;title&#39;: &#39;EmbryoProfiler: A Visual Clinical Decision Support System for IVF&#39;, &#39;contributors&#39;: [&#39;Johannes Knittel&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T15:45:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T15:45:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T15:57:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Johannes Knittel&#39;, &#39;email&#39;: &#39;jknittel@seas.harvard.edu&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Simon Warchol&#39;, &#39;email&#39;: &#39;simonwarchol@g.harvard.edu&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Jakob Troidl&#39;, &#39;email&#39;: &#39;jakob.troidl@googlemail.com&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Camelia D. Brumar&#39;, &#39;email&#39;: &#39;camelia_daniela.brumar@tufts.edu&#39;, &#39;affiliation&#39;: &#39;Tufts University&#39;}, {&#39;name&#39;: &#39;Helen Yang&#39;, &#39;email&#39;: &#39;yuy068@g.harvard.edu&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Eric Mörth&#39;, &#39;email&#39;: &#39;eric.moerth@gmx.at&#39;, &#39;affiliation&#39;: &#39;Harvard Medical School&#39;}, {&#39;name&#39;: &#39;Robert Krüger&#39;, &#39;email&#39;: &#39;rk4815@nyu.edu&#39;, &#39;affiliation&#39;: &#39;New York University&#39;}, {&#39;name&#39;: &#39;Daniel Needleman&#39;, &#39;email&#39;: &#39;dan.needleman@gmail.com&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Dalit Ben-Yosef&#39;, &#39;email&#39;: &#39;dalitb@tasmc.health.gov.il&#39;, &#39;affiliation&#39;: &#39;Tel Aviv University&#39;}, {&#39;name&#39;: &#39;Hanspeter Pfister&#39;, &#39;email&#39;: &#39;pfister@seas.harvard.edu&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}], &#39;abstract&#39;: &#39;In-vitro fertilization (IVF) has become standard practice to address infertility, which affects more than one in ten couples in the US. However, current protocols yield relatively low success rates of about 20% per treatment cycle. A critical but complex and time-consuming step is the grading and selection of embryos for implantation. Although incubators with time-lapse microscopy have enabled computational analysis of embryo development, existing automated approaches either require extensive manual annotations or use opaque deep learning models that are hard for clinicians to validate and trust. We present EmbryoProfiler, a visual analytics system collaboratively developed with embryologists, biologists, and machine learning researchers to support clinicians in visually assessing embryo viability from time-lapse microscopy imagery. Our system incorporates a deep learning pipeline that automatically annotates microscopy images and extracts clinically interpretable features relevant for embryo grading. Our contributions include: (1) a semi-automatic, visualization-based workflow that guides clinicians through fertilization assessment, developmental timing evaluation, morphological inspection, and comparative analysis of embryos; (2) innovative interactive visualizations, such as cell-shape plots, designed to facilitate efficient analysis of morphological and developmental characteristics; and (3) an integrated, explainable machine learning classifier offering transparent, clinically-informed embryo viability scoring to predict live birth outcomes. Quantitative evaluation of our classifier and qualitative case studies conducted with practitioners demonstrate that EmbryoProfiler enables clinicians to make better-informed embryo selection decisions, potentially leading to improved clinical outcomes in IVF treatments.&#39;, &#39;uid&#39;: &#39;28a70097-2b4f-4ac5-9bb0-7b452093c16b&#39;, &#39;keywords&#39;: [&#39;in-vitro fertilization&#39;, &#39;embryo selection&#39;, &#39;visual analytics&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_28a70097-2b4f-4ac5-9bb0-7b452093c16b.html"> EmbryoProfiler: A Visual Clinical Decision Support System for IVF <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Johannes Knittel, Simon Warchol, Jakob Troidl, Camelia D. Brumar, Helen Yang, Eric Mörth, Robert Krüger, Daniel Needleman, Dalit Ben-Yosef, Hanspeter Pfister </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Johannes Knittel </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T15:45:00.000Z &ndash; 2025-11-06T15:57:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row my-5"><div class="col-md-8"><p>You may want to also jump to the parent event to see related presentations: <a href="event_v-full.html">VIS Full Papers</a></p></div></div><script src="/static/2025/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script><script>

$(document).ready(function() {
    setInterval(updateSessionStatus, 30 * 1000);
    updateSessionStatus(true)
})

function updateSessionStatus(onFirstLoad) {
    // We need to write the session timings into the page to calculate current/next session.
    // See blueprint_2025.py
    startTime = '2025-11-06T14:45:00+00:00'
    endTime = '2025-11-06T16:00:00+00:00'

    // We take a 8 minute grace period to the start of a session
    const sessionStart = moment(startTime).tz(current_timezone).subtract(8, 'minutes');
    const sessionEnd = moment(endTime).tz(current_timezone);

    const sessionIsCurrent = moment().tz(current_timezone).isBetween(sessionStart, sessionEnd);
    const sessionIsFuture = moment().tz(current_timezone).isBefore(sessionStart);
    const sessionIsPast = moment().tz(current_timezone).isAfter(sessionStart);

    const classesToHide = ['.future_session_alert', '.current_session_alert', '.past_session_alert', '.room_session_stream']
    classesToHide.forEach((c) => { $(c).hide();});
    if (sessionIsCurrent) {
        $('.current_session_alert').show();
    } else if (sessionIsFuture) {
        $('.future_session_alert').show();
    } else {
        // Session is in the future
        $('#zoom_alert').hide();
        $('.past_session_alert').show();
        $('.room_session_stream').show();
    }

    // Update youtube link for older sessions
    // EDIT - We don't need this when the conference isn't live
    if(sessionIsPast){
        const roomidjson = "m1-"+moment(startTime).format('ddd').toLowerCase()+".json"
        // console.log("this session was in:" , roomidjson)

        return fetch("https://virtual-data.ieeevis.org/"+roomidjson, {cache: "no-store"})
        .then(response => response.json())
        .then(data => {
            //console.log(data)
            // console.log('youtube_url: ' + data.youtube_url)
            //$("ytold").attr("href",data.youtube_url)

            // clear link element to avoid multiple appends
            document.getElementById("ytold").innerHTML = '';

            var a = document.createElement('a'); 
            var link = document.createTextNode(data.youtube_url);  
            a.appendChild(link); 
            a.title = "YouTube Link"; 
            a.href = data.youtube_url; 
            
            document.getElementById("ytold").appendChild(a);
        })
        .catch(error => {
            console.log("err: ", error);
        })
    }
    

}

</script></body></html>