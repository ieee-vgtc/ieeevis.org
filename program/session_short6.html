<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/2.1/auth0-spa-js.production.js"></script><script>
              const auth0_domain = "ieeevis.us.auth0.com";
              const auth0_client_id = "oF5BXUklWOjSjUeg5Tzai2DysHITXYhT";
            </script><script src="/static/2025/js/modules/auth0protect.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2025/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2025/js/data/persistor.js"></script><script src="/static/2025/js/data/api.js"></script><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2025/css/Zilla.css" rel="stylesheet"><link href="/static/2025/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2025/css/main.css"><link rel="stylesheet" href="/static/2025/css/fa_solid.css"><link rel="stylesheet" href="/static/2025/css/lazy_load.css"><link rel="stylesheet" href="/static/2025/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2025 - Session: VIS Short Papers: Visualization for Science"><meta name="twitter:description" content="See the session and its presentations inside."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="See the session and its presentations inside."><meta name="title" property="og:title" content="Virtual IEEE VIS 2025 - Session: VIS Short Papers: Visualization for Science"><meta property="og:type" content="website"><title>IEEE VIS 2025 Content: VIS Short Papers: Visualization for Science</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style="display: none;"><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-8"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item" aria-current="page"><a href="events.html">All events</a></li><li class="breadcrumb-item"><a href="event_v-short.html">VIS Short Papers</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">Visualization for Science</li></ol></nav><h1 class="session-title">VIS Short Papers: Visualization for Science</h1><h3 class="session-url"><a href="https://ieeevis.org/year/2025/program/event_v-short.html" target="_blank"><span class="fas mr-1">&#xf57c;</span> https://ieeevis.org/year/2025/program/event_v-short.html</a></h3><h3 class="session-chair"><span class="fas mr-1">&#xf007;</span> Session chair: Federico Luricich </h3><h3 class="session-room mt-4"> Room: Hall M1 </h3><h3 class="session-date"><span class="fas mr-1">&#xf017;</span><span class="format-date-span-full">2025-11-05T10:15:00+00:00 &ndash; 2025-11-05T11:30:00+00:00</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2025-11-05T10:15:00+00:00 &ndash; 2025-11-05T11:30:00+00:00</span><span class="current-time tztooltiptext"></span></span></h3></div><div class="col-md-1"></div><div class="col-md-3 session-links"><h5 class="session-info my-4"><a href="#list"><span class="fas mr-2">&#xf358;</span> Jump to event listing </a></h5><h5 class="session-info my-4"><a href="https://data.tech.ieeevis.org/storage/v1/object/public/ics/vis2025/short6.ics"><span class="fas mr-2">&#xf073;</span> Add to Calendar</a></h5></div></div><div class="row my-5 discord-public-link hide-auth-controls"><div class="col-md-8"><p><span class="fas mx-1">&#xf086;</span><a href="https://discord.com/channels/1422883912660549696/1430945433034952759" target="_blank">Discord link</a></p></div></div><div class="row my-5"><div class="col-md-8"><p>Recordings will be made available after the session.</p></div></div><hr><div class="row my-4"><div class="col-md-8"><h2 class="room_session_descriptor d-block py-2"><a name="list">Presentations in this session:</a></h2></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-short-1100&#39;, &#39;session_id&#39;: &#39;short6&#39;, &#39;title&#39;: &#39;Paraview-MCP: An Autonomous Visualization Agent with Direct Tool Use&#39;, &#39;contributors&#39;: [&#39;Haichao Miao&#39;], &#39;paper_type&#39;: &#39;Short&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T10:15:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T10:15:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T10:24:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Shusen Liu&#39;, &#39;email&#39;: &#39;shusen.liu.hust@gmail.com&#39;, &#39;affiliation&#39;: &#39;Lawrence Livermore National Laboratory&#39;}, {&#39;name&#39;: &#39;Haichao Miao&#39;, &#39;email&#39;: &#39;miao1@llnl.gov&#39;, &#39;affiliation&#39;: &#39;Lawrence Livermore National Laboratory&#39;}, {&#39;name&#39;: &#39;Peer-Timo Bremer&#39;, &#39;email&#39;: &#39;bremer5@llnl.gov&#39;, &#39;affiliation&#39;: &#39;Lawrence Livermore National Laboratory&#39;}], &#39;abstract&#39;: &#34;While powerful and well-established, tools like ParaView present a steep learning curve that can discourage many potential users. This work introduces ParaView-MCP, an autonomous agent that integrates modern multimodal large language models (MLLMs) with ParaView to not only lower the barrier to entry but also augment ParaView with intelligent decision support. By leveraging the state-of-the-art reasoning, command execution, and vision capabilities of MLLMs, ParaView-MCP enables users to interact with ParaView through natural language and visual inputs. Specifically, our system adopted the Model Context Protocol (MCP), a standardized interface for model-application communication, which facilitates direct interaction between MLLMs and ParaView&#39;s Python API, allowing seamless information exchange between the user, the language model, and the visualization tool itself. Furthermore, by implementing a visual feedback mechanism that allows the agent to observe the viewport, we unlock a range of new capabilities, including recreating visualizations from examples, closed-loop visualization parameter updates based on user-defined goals, and even cross-application collaboration involving multiple tools.&#34;, &#39;uid&#39;: &#39;881a464d-c01d-453c-8f14-8b59acdde104&#39;, &#39;keywords&#39;: [&#39;Agent&#39;, &#39;Tool Use&#39;, &#39;Model Context Protocol&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2505.07064&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: &#39;Well documented source code&#39;, &#39;open_access_supplemental_link&#39;: &#39;https://github.com/LLNL/paraview_mcp&#39;} <h3 class="session-list-title"><a href="paper_881a464d-c01d-453c-8f14-8b59acdde104.html"> Paraview-MCP: An Autonomous Visualization Agent with Direct Tool Use <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Shusen Liu, Haichao Miao, Peer-Timo Bremer </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Haichao Miao </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T10:15:00.000Z &ndash; 2025-11-05T10:24:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-short-1108&#39;, &#39;session_id&#39;: &#39;short6&#39;, &#39;title&#39;: &#39;Uncertain Mode Surfaces in 3D Symmetric Second-Order Tensor Field Ensembles&#39;, &#39;contributors&#39;: [&#39;Tim Gerrits&#39;], &#39;paper_type&#39;: &#39;Short&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T10:24:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T10:24:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T10:33:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Tim Gerrits&#39;, &#39;email&#39;: &#39;gerrits@vis.rwth-aachen.de&#39;, &#39;affiliation&#39;: &#39;RWTH Aachen University&#39;}], &#39;abstract&#39;: &#39;The analysis of 3D symmetric second-order tensor fields often relies on topological features such as degenerate tensor lines, neutral surfaces, and their generalization to mode surfaces, which reveal important structural insights into the data. However, uncertainty in such fields is typically visualized using derived scalar attributes or tensor glyph representations, which often fail to capture the global behavior. Recent advances have introduced uncertain topological features for tensor field ensembles by focusing on degenerate tensor locations. Yet, mode surfaces, including neutral surfaces and arbitrary mode surfaces are essential to a comprehensive understanding of tensor field topology. In this work, we present a generalization of uncertain degenerate tensor features to uncertain mode surfaces of arbitrary mode values, encompassing uncertain degenerate tensor lines as a special case. Our approach supports both surface and line geometries, forming a unified framework for analyzing uncertain mode-based topological features in tensor field ensembles. We demonstrate the effectiveness of our method on several real-world simulation datasets from engineering and materials science.&#39;, &#39;uid&#39;: &#39;565a0b31-3df7-4d49-859a-2a96dda32a65&#39;, &#39;keywords&#39;: [&#39;Second-Order Tensors&#39;, &#39;Symmetric Tensors&#39;, &#39;Tensor Topology&#39;, &#39;Tensor Mode&#39;, &#39;Uncertainty&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/pdf/2506.23406&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_565a0b31-3df7-4d49-859a-2a96dda32a65.html"> Uncertain Mode Surfaces in 3D Symmetric Second-Order Tensor Field Ensembles <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Tim Gerrits </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Tim Gerrits </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T10:24:00.000Z &ndash; 2025-11-05T10:33:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-short-1216&#39;, &#39;session_id&#39;: &#39;short6&#39;, &#39;title&#39;: &#39;Virtual Ray Sampling for Direct Volume Rendering using Hermite Interpolation&#39;, &#39;contributors&#39;: [&#39;Balázs Csébfalvi&#39;], &#39;paper_type&#39;: &#39;Short&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T10:33:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T10:33:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T10:42:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Balázs Csébfalvi&#39;, &#39;email&#39;: &#39;cseb@iit.bme.hu&#39;, &#39;affiliation&#39;: &#39;Budapest University of Technology and Economics&#39;}], &#39;abstract&#39;: &#39;Virtual sampling has been proposed as an alternative of pre-integration to reduce artifacts caused by an insufficient sampling of the ray profiles in volume-rendering applications. According to the originally recommended implementation, a 3D tricubic B-spline reconstruction is applied to evaluate true samples along the rays, while between the true samples, virtual samples are calculated by using a 1D Catmull-Rom spline interpolation. The virtual samples can be evaluated much faster, but they can still well approximate the true samples. Therefore, the rendering performance can be drastically improved at the cost of a very slight quality degradation. Nevertheless, in this paper, we show that the original virtual sampling scheme does not exploit the fact, that the applied tricubic B-spline reconstruction filter together with its analytic derivative filters provide Hermite samples. Therefore, it is more natural to use Hermite interpolation along the rays rather than Catmull-Rom spline interpolation. From a sampling-theoretical point of view, this modification requires half of the true samples to guarantee the same reconstruction quality. Furthermore, concerning the evaluation of the true samples, we also investigate a recently published GPU-accelerated triquadratic B-spline filtering as an alternative of the tricubic B-spline filtering.&#39;, &#39;uid&#39;: &#39;be118d02-63d2-4463-a135-af2c23073ad2&#39;, &#39;keywords&#39;: [&#39;Direct volume rendering&#39;, &#39;reconstruction filtering&#39;, &#39;virtual sampling.&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_be118d02-63d2-4463-a135-af2c23073ad2.html"> Virtual Ray Sampling for Direct Volume Rendering using Hermite Interpolation <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Balázs Csébfalvi </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Balázs Csébfalvi </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T10:33:00.000Z &ndash; 2025-11-05T10:42:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-short-1153&#39;, &#39;session_id&#39;: &#39;short6&#39;, &#39;title&#39;: &#39;SEG-RobustEye: Understanding medical image segmentation models&#39;, &#39;contributors&#39;: [&#39;Anna Vilanova&#39;], &#39;paper_type&#39;: &#39;Short&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T10:42:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T10:42:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T10:51:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Andreea Melania Popa&#39;, &#39;email&#39;: &#39;popa.ada@gmail.com&#39;, &#39;affiliation&#39;: &#39;Eindhoven University of Technolocy&#39;}, {&#39;name&#39;: &#39;Vidya Prasad&#39;, &#39;email&#39;: &#39;v.prasad@tue.nl&#39;, &#39;affiliation&#39;: &#39;Eindhoven University of Technology&#39;}, {&#39;name&#39;: &#39;Tim J.M. Jaspers&#39;, &#39;email&#39;: &#39;t.j.m.jaspers@tue.nl&#39;, &#39;affiliation&#39;: &#39;Eindhoven University of Technolocy&#39;}, {&#39;name&#39;: &#39;Fons van der Sommen&#39;, &#39;email&#39;: &#39;fvdsommen@tue.nl&#39;, &#39;affiliation&#39;: &#39;Eindhoven University of Technology&#39;}, {&#39;name&#39;: &#39;Anna Vilanova&#39;, &#39;email&#39;: &#39;a.vilanova@tue.nl&#39;, &#39;affiliation&#39;: &#39;Eindhoven University of Technology&#39;}], &#39;abstract&#39;: &#39;Deep learning (DL) models have proven to be suitable for various applications, achieving state-of-the-art performance. Despite that, they experience notable performance drops when subjected to realistic transformations in input data. Analyzing model behavior under input transformations is essential to preemptively identify possible\nbreaking points and understand what image characteristics might cause them before their failure in the real world. We introduce SEG-RobustEye, a visual analytics (VA) design developed to assist in the evaluation of the robustness of segmentation models for endoscopy images under realistic input transformations. SEG-RobustEye is based on ProactiV [13], a VA framework designed for understanding the behaviour of image-to-image translation models. SEG-RobustEye is a tailored instance of the framework and an extension of ProactiV for medical images, in concrete endoscopic images. These require visual designs that enhance the relevant features for such medical applications, which are different from general natural scenes. SEG-RobustEye is designed to discover features that affect the model behaviour under specific transformations.\nSEG-RobustEye connects the provided perspectives by ProactiV, i.e., global and instance level, and extends to subgroup level patterns. Subgroup level patterns facilitate the discovery and generalizability of selected subgroups of instances. The value of our approach was verified against real-world cases in endoscopy imaging by DL developers as proof of concept of the potential of SEG-RobustEye and, by extension, of ProactiV.\n\n[13] V. Prasad, R. J. van Sloun, A. Vilanova, and N. Pezzotti. ProactiV: Studying deep learning model behavior under input transformations. IEEE Transactions on Visualization and Computer Graphics, 30(8):5651–5665, 2024&#39;, &#39;uid&#39;: &#39;707ca454-9b92-46e1-88a4-98f997fb6434&#39;, &#39;keywords&#39;: [&#39;Visual analytics&#39;, &#39;explainable AI&#39;, &#39;medical imaging&#39;, &#39;input transformations&#39;, &#39;robustness analysis&#39;, &#39;model behavior&#39;, &#39;deep learning&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_707ca454-9b92-46e1-88a4-98f997fb6434.html"> SEG-RobustEye: Understanding medical image segmentation models <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Andreea Melania Popa, Vidya Prasad, Tim J.M. Jaspers, Fons van der Sommen, Anna Vilanova </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Anna Vilanova </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T10:42:00.000Z &ndash; 2025-11-05T10:51:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-short-1143&#39;, &#39;session_id&#39;: &#39;short6&#39;, &#39;title&#39;: &#39;Scope Meets Screen: Lessons Learned in Designing Composite Visualizations for Marksmanship Training Across Skill Levels&#39;, &#39;contributors&#39;: [&#39;Emin Zerman&#39;], &#39;paper_type&#39;: &#39;Short&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T10:51:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T10:51:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T11:00:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Emin Zerman&#39;, &#39;email&#39;: &#39;emin.zerman@miun.se&#39;, &#39;affiliation&#39;: &#39;Mid Sweden University&#39;}, {&#39;name&#39;: &#39;Jonas Carlsson&#39;, &#39;email&#39;: &#39;j_c_kc@live.se&#39;, &#39;affiliation&#39;: &#39;Mid Sweden University&#39;}, {&#39;name&#39;: &#39;Mårten Sjöström&#39;, &#39;email&#39;: &#39;marten.sjostrom@miun.se&#39;, &#39;affiliation&#39;: &#39;Mid Sweden University&#39;}], &#39;abstract&#39;: &#39;Marksmanship practices are required in various professions, including police, military personnel, hunters, as well as sports shooters, such as Olympic shooting, biathlon, and modern pentathlon. The current form of training and coaching is mostly based on repetition, where the coach does not see through the eyes of the shooter, and analysis is limited to stance and accuracy post-session. In this study, we present a shooting visualization system and evaluate its perceived effectiveness for both novice and expert shooters. To achieve this, five composite visualizations were developed using first-person shooting video recordings enriched with overlaid metrics and graphical summaries. These views were evaluated with 10 participants (5 expert marksmen, 5 novices) through a mixed-methods study including shot-count and aiming interpretation tasks, pairwise preference comparisons, and semi-structured interviews. The results show that a dashboard-style composite view, combining raw video with a polar plot and selected graphs, was preferred in 9 of 10 cases and supported understanding across skill levels. The insights gained from this design study point to the broader value of integrating first-person video with visual analytics for coaching, and we suggest directions for applying this approach to other precision-based sports.&#39;, &#39;uid&#39;: &#39;0f3ea5e8-4bc5-4e8a-8619-1ce981d4e8e1&#39;, &#39;keywords&#39;: [&#39;Composite visualization&#39;, &#39;sports coaching&#39;, &#39;marksmanship training&#39;, &#39;first-person video&#39;, &#39;user studies&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2507.00333&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_0f3ea5e8-4bc5-4e8a-8619-1ce981d4e8e1.html"> Scope Meets Screen: Lessons Learned in Designing Composite Visualizations for Marksmanship Training Across Skill Levels <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Emin Zerman, Jonas Carlsson, Mårten Sjöström </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Emin Zerman </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T10:51:00.000Z &ndash; 2025-11-05T11:00:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-short-1112&#39;, &#39;session_id&#39;: &#39;short6&#39;, &#39;title&#39;: &#39;Interactive Visual Analytics of Carbon Cycle Science&#39;, &#39;contributors&#39;: [&#39;Linh Pham&#39;], &#39;paper_type&#39;: &#39;Short&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T11:00:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T11:00:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T11:09:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Linh Pham&#39;, &#39;email&#39;: &#39;linhphaaam@gmail.com&#39;, &#39;affiliation&#39;: &#39;Havard University&#39;}, {&#39;name&#39;: &#39;Kevin Hu&#39;, &#39;email&#39;: &#39;inbox.kevin.hu@gmail.com&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Minyoung Joo&#39;, &#39;email&#39;: &#39;junaline4@gmail.com&#39;, &#39;affiliation&#39;: &#39;ArtCenter College of Design&#39;}, {&#39;name&#39;: &#39;Nathan White&#39;, &#39;email&#39;: &#39;ntwhite@wisc.edu&#39;, &#39;affiliation&#39;: &#39;University of Wisconsin - Madison&#39;}, {&#39;name&#39;: &#39;Anthony Bloom&#39;, &#39;email&#39;: &#39;alexis.a.bloom@jpl.nasa.gov&#39;, &#39;affiliation&#39;: &#39;Jet Propulsion Lab&#39;}, {&#39;name&#39;: &#39;Krys Blackwood&#39;, &#39;email&#39;: &#39;krys.t.blackwood@jpl.nasa.gov&#39;, &#39;affiliation&#39;: &#39;Jet Propulsion Lab&#39;}, {&#39;name&#39;: &#39;Santiago Lombeyda&#39;, &#39;email&#39;: &#39;santiago@caltech.edu&#39;, &#39;affiliation&#39;: &#39;California Institute of Technology&#39;}, {&#39;name&#39;: &#39;Hillary Mushkin&#39;, &#39;email&#39;: &#39;hmushkin@caltech.edu&#39;, &#39;affiliation&#39;: &#39;California Institute of Technology (Caltech)&#39;}, {&#39;name&#39;: &#39;Scott Davidoff&#39;, &#39;email&#39;: &#39;sd@scottdavidoff.com&#39;, &#39;affiliation&#39;: &#39;California Institute of Technology&#39;}], &#39;abstract&#39;: &#39;Tracking the flow of carbon (C) through the Earth’s terrestrial biosphere remains a major challenge to understanding how ecosystems respond to environmental change [12]. To build an understanding of this flow, researchers have recently developed models that include thousands of variables whose intricate inter-dependencies can make them difficult to interpret. To open this scientific black box, we partnered with C cycle scientists at the NASA Jet Propulsion Lab who developed the Carbon Data-Model (CARDAMOM) framework [5]. This paper presents a design study of CLOVE, a C science visual analytics application that encodes model dimensions in an intuitive way by using visual metaphors that correspond to the natural world. We describe how CLOVE encapsulates C states and fluxes in complex models, and explains how C cycle scientists can use it to diagnose their model outputs.&#39;, &#39;uid&#39;: &#39;9259ca04-ae61-4513-b066-711f3a75cbc1&#39;, &#39;keywords&#39;: [&#39;earth system&#39;, &#39;bayesian carbon cycle&#39;, &#39;design study&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_9259ca04-ae61-4513-b066-711f3a75cbc1.html"> Interactive Visual Analytics of Carbon Cycle Science <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Linh Pham, Kevin Hu, Minyoung Joo, Nathan White, Anthony Bloom, Krys Blackwood, Santiago Lombeyda, Hillary Mushkin, Scott Davidoff </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Linh Pham </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T11:00:00.000Z &ndash; 2025-11-05T11:09:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-short-1268&#39;, &#39;session_id&#39;: &#39;short6&#39;, &#39;title&#39;: &#39;Analyzing Time-Varying Scalar Fields using Piecewise-Linear Morse-Cerf Theory&#39;, &#39;contributors&#39;: [&#39;Amritendu Dhar&#39;], &#39;paper_type&#39;: &#39;Short&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T11:09:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T11:09:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T11:18:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Amritendu Dhar&#39;, &#39;email&#39;: &#39;amritendud@iisc.ac.in&#39;, &#39;affiliation&#39;: &#39;Indian Institute of Science, Bangalore&#39;}, {&#39;name&#39;: &#39;Apratim Chakraborty&#39;, &#39;email&#39;: &#39;apratimn@gmail.com&#39;, &#39;affiliation&#39;: &#39;TCG CREST&#39;}, {&#39;name&#39;: &#39;Vijay Natarajan&#39;, &#39;email&#39;: &#39;vijayn@iisc.ac.in&#39;, &#39;affiliation&#39;: &#39;Indian Institute of Science&#39;}], &#39;abstract&#39;: &#39;Morse-Cerf theory considers a one-parameter family of smooth\nfunctions defined on a manifold and studies the evolution of their\ncritical points with the parameter. This paper presents an adaptation\nof Morse-Cerf theory to a family of piecewise-linear (PL) functions.\nThe vertex diagram and Cerf diagram are introduced as representations\nof the evolution of critical points of the PL function. The\ncharacterization of a crossing in the vertex diagram based on the\nhomology of the lower links of vertices leads to the definition of a\ntopological descriptor for time-varying scalar fields. An algorithm\nfor computing the Cerf diagram and a measure for comparing two\nCerf diagrams are also described together with experimental results\non time-varying scalar fields.&#39;, &#39;uid&#39;: &#39;cdb6dc71-86fb-401f-a559-fa6c53347af5&#39;, &#39;keywords&#39;: [&#39;Time-varying scalar fields&#39;, &#39;topological descriptors&#39;, &#39;critical points&#39;, &#39;Morse theory&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2507.00725&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_cdb6dc71-86fb-401f-a559-fa6c53347af5.html"> Analyzing Time-Varying Scalar Fields using Piecewise-Linear Morse-Cerf Theory <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Amritendu Dhar, Apratim Chakraborty, Vijay Natarajan </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Amritendu Dhar </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T11:09:00.000Z &ndash; 2025-11-05T11:18:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-short-1220&#39;, &#39;session_id&#39;: &#39;short6&#39;, &#39;title&#39;: &#39;Volumetric Visualization of the Genome&#39;, &#39;contributors&#39;: [&#39;Roxana Bujack&#39;], &#39;paper_type&#39;: &#39;Short&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T11:18:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T11:18:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T11:27:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Roxana Bujack&#39;, &#39;email&#39;: &#39;bujack@lanl.gov&#39;, &#39;affiliation&#39;: &#39;Los Alamos National Laboratory&#39;}, {&#39;name&#39;: &#39;David Rogers&#39;, &#39;email&#39;: &#39;dhr@lanl.gov&#39;, &#39;affiliation&#39;: &#39;Los Alamos National Laboratory&#39;}, {&#39;name&#39;: &#39;Cullen Roth&#39;, &#39;email&#39;: &#39;croth@lanl.gov&#39;, &#39;affiliation&#39;: &#39;Los Alamos National Laboratory&#39;}, {&#39;name&#39;: &#39;Eric Small&#39;, &#39;email&#39;: &#39;emsmall@lanl.gov&#39;, &#39;affiliation&#39;: &#39;Los Alamos National Laboratory&#39;}, {&#39;name&#39;: &#39;Banerjee Shounak&#39;, &#39;email&#39;: &#39;baners4@lanl.gov&#39;, &#39;affiliation&#39;: &#39;Los Alamos National Laboratory&#39;}, {&#39;name&#39;: &#39;Vrinda Venu&#39;, &#39;email&#39;: &#39;vrindavenu7@gmail.com&#39;, &#39;affiliation&#39;: &#39;Los Alamos National Laboratory&#39;}, {&#39;name&#39;: &#39;Shawn Starkenburg&#39;, &#39;email&#39;: &#39;shawns@lanl.gov&#39;, &#39;affiliation&#39;: &#39;Los Alamos National Laboratory&#39;}, {&#39;name&#39;: &#39;Steadman, Christina Rene&#39;, &#39;email&#39;: &#39;crsteadman@lanl.gov&#39;, &#39;affiliation&#39;: &#39;Los Alamos National Laboratory&#39;}], &#39;abstract&#39;: &#39;Within the nucleus of a cell, the genetic material (DNA) is condensed, supercoiled, and wrapped around proteins called histones, so to form chromatin. Unlike its traditional visualization, the organization of chromatin is 3D and can be measured with whole-genome sequencing technologies such as Hi-C sequencing, the results of which are often graphically represented as flat 2D heat-maps or a 1D curve that looks like a hairball. Here we discuss a novel approach to represent these and other genomic data by transforming the visualization of the genome from a 1D curve embedded in 3D into a structured 3D volume. This abstraction prioritizes 3D spatial proximity of chromatin and enables advanced techniques like clipping, thresholding, and contouring. Our method allows for multi-variable encoding, thereby enhancing our ability to interpret multivariate relationships, offering a more complete and effective representation of genomic structures, chromosome organization, and data relationships.&#39;, &#39;uid&#39;: &#39;cab72096-2336-4e27-a4e2-c416dd102259&#39;, &#39;keywords&#39;: [&#39;Genome&#39;, &#39;volume&#39;, &#39;DNA&#39;, &#39;3D Hi-C&#39;, &#39;volumetric&#39;, &#39;abstraction.&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_cab72096-2336-4e27-a4e2-c416dd102259.html"> Volumetric Visualization of the Genome <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Roxana Bujack, David Rogers, Cullen Roth, Eric Small, Banerjee Shounak, Vrinda Venu, Shawn Starkenburg, Steadman, Christina Rene </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Roxana Bujack </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T11:18:00.000Z &ndash; 2025-11-05T11:27:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row my-5"><div class="col-md-8"><p>You may want to also jump to the parent event to see related presentations: <a href="event_v-short.html">VIS Short Papers</a></p></div></div><script src="/static/2025/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script><script>

$(document).ready(function() {
    setInterval(updateSessionStatus, 30 * 1000);
    updateSessionStatus(true)
})

function updateSessionStatus(onFirstLoad) {
    // We need to write the session timings into the page to calculate current/next session.
    // See blueprint_2025.py
    startTime = '2025-11-05T10:15:00+00:00'
    endTime = '2025-11-05T11:30:00+00:00'

    // We take a 8 minute grace period to the start of a session
    const sessionStart = moment(startTime).tz(current_timezone).subtract(8, 'minutes');
    const sessionEnd = moment(endTime).tz(current_timezone);

    const sessionIsCurrent = moment().tz(current_timezone).isBetween(sessionStart, sessionEnd);
    const sessionIsFuture = moment().tz(current_timezone).isBefore(sessionStart);
    const sessionIsPast = moment().tz(current_timezone).isAfter(sessionStart);

    const classesToHide = ['.future_session_alert', '.current_session_alert', '.past_session_alert', '.room_session_stream']
    classesToHide.forEach((c) => { $(c).hide();});
    if (sessionIsCurrent) {
        $('.current_session_alert').show();
    } else if (sessionIsFuture) {
        $('.future_session_alert').show();
    } else {
        // Session is in the future
        $('#zoom_alert').hide();
        $('.past_session_alert').show();
        $('.room_session_stream').show();
    }

    // Update youtube link for older sessions
    // EDIT - We don't need this when the conference isn't live
    if(sessionIsPast){
        const roomidjson = "m1-"+moment(startTime).format('ddd').toLowerCase()+".json"
        // console.log("this session was in:" , roomidjson)

        return fetch("https://virtual-data.ieeevis.org/"+roomidjson, {cache: "no-store"})
        .then(response => response.json())
        .then(data => {
            //console.log(data)
            // console.log('youtube_url: ' + data.youtube_url)
            //$("ytold").attr("href",data.youtube_url)

            // clear link element to avoid multiple appends
            document.getElementById("ytold").innerHTML = '';

            var a = document.createElement('a'); 
            var link = document.createTextNode(data.youtube_url);  
            a.appendChild(link); 
            a.title = "YouTube Link"; 
            a.href = data.youtube_url; 
            
            document.getElementById("ytold").appendChild(a);
        })
        .catch(error => {
            console.log("err: ", error);
        })
    }
    

}

</script></body></html>