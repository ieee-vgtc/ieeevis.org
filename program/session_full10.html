<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/2.1/auth0-spa-js.production.js"></script><script>
              const auth0_domain = "ieeevis.us.auth0.com";
              const auth0_client_id = "oF5BXUklWOjSjUeg5Tzai2DysHITXYhT";
            </script><script src="/static/2025/js/modules/auth0protect.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2025/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2025/js/data/persistor.js"></script><script src="/static/2025/js/data/api.js"></script><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2025/css/Zilla.css" rel="stylesheet"><link href="/static/2025/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2025/css/main.css"><link rel="stylesheet" href="/static/2025/css/fa_solid.css"><link rel="stylesheet" href="/static/2025/css/lazy_load.css"><link rel="stylesheet" href="/static/2025/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2025 - Session: VIS Full Papers: Dimensionality Reduction and Parameter Space Analysis"><meta name="twitter:description" content="See the session and its presentations inside."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="See the session and its presentations inside."><meta name="title" property="og:title" content="Virtual IEEE VIS 2025 - Session: VIS Full Papers: Dimensionality Reduction and Parameter Space Analysis"><meta property="og:type" content="website"><title>IEEE VIS 2025 Content: VIS Full Papers: Dimensionality Reduction and Parameter Space Analysis</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style="display: none;"><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-8"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item" aria-current="page"><a href="events.html">All events</a></li><li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">Dimensionality Reduction and Parameter Space Analysis</li></ol></nav><h1 class="session-title">VIS Full Papers: Dimensionality Reduction and Parameter Space Analysis</h1><h3 class="session-url"><a href="https://ieeevis.org/year/2025/program/event_v-full.html" target="_blank"><span class="fas mr-1">&#xf57c;</span> https://ieeevis.org/year/2025/program/event_v-full.html</a></h3><h3 class="session-chair"><span class="fas mr-1">&#xf007;</span> Session chair: Tobias Schreck </h3><h3 class="session-room mt-4"> Room: Hall E2 </h3><h3 class="session-date"><span class="fas mr-1">&#xf017;</span><span class="format-date-span-full">2025-11-05T14:45:00+00:00 &ndash; 2025-11-05T16:00:00+00:00</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2025-11-05T14:45:00+00:00 &ndash; 2025-11-05T16:00:00+00:00</span><span class="current-time tztooltiptext"></span></span></h3></div><div class="col-md-1"></div><div class="col-md-3 session-links"><h5 class="session-info my-4"><a href="#list"><span class="fas mr-2">&#xf358;</span> Jump to event listing </a></h5><h5 class="session-info my-4"><a href="https://data.tech.ieeevis.org/storage/v1/object/public/ics/vis2025/full10.ics"><span class="fas mr-2">&#xf073;</span> Add to Calendar</a></h5></div></div><div class="row my-5 discord-public-link hide-auth-controls"><div class="col-md-8"><p><span class="fas mx-1">&#xf086;</span><a href="https://discord.com/channels/1422883912660549696/1430945422318505994" target="_blank">Discord link</a></p></div></div><div class="row my-5"><div class="col-md-8"><p>Recordings will be made available after the session.</p></div></div><hr><div class="row my-4"><div class="col-md-8"><h2 class="room_session_descriptor d-block py-2"><a name="list">Presentations in this session:</a></h2></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1019&#39;, &#39;session_id&#39;: &#39;full10&#39;, &#39;title&#39;: &#39;Dataset-Adaptive Dimensionality Reduction&#39;, &#39;contributors&#39;: [&#39;Hyeon Jeon&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T14:45:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T14:45:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T14:57:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Hyeon Jeon&#39;, &#39;email&#39;: &#39;hj@hcil.snu.ac.kr&#39;, &#39;affiliation&#39;: &#39;Seoul National University&#39;}, {&#39;name&#39;: &#39;Jeongin Park&#39;, &#39;email&#39;: &#39;parkjeong02@snu.ac.kr&#39;, &#39;affiliation&#39;: &#39;Seoul National University&#39;}, {&#39;name&#39;: &#39;Soohyun Lee&#39;, &#39;email&#39;: &#39;dtngus0111@gmail.com&#39;, &#39;affiliation&#39;: &#39;Seoul National University&#39;}, {&#39;name&#39;: &#39;Dae Hyun Kim&#39;, &#39;email&#39;: &#39;dhkim16@yonsei.ac.kr&#39;, &#39;affiliation&#39;: &#39;Yonsei University&#39;}, {&#39;name&#39;: &#39;Sungbok Shin&#39;, &#39;email&#39;: &#39;sbshin90@cs.umd.edu&#39;, &#39;affiliation&#39;: &#39;Inria-Saclay, Université Paris-Saclay&#39;}, {&#39;name&#39;: &#39;Jinwook Seo&#39;, &#39;email&#39;: &#39;jseo@snu.ac.kr&#39;, &#39;affiliation&#39;: &#39;Seoul National University&#39;}], &#39;abstract&#39;: &#39;Selecting the appropriate dimensionality reduction (DR) technique and determining its optimal hyperparameter settings that maximize the accuracy of the output projections typically involves extensive trial and error, often resulting in unnecessary computational overhead. To address this challenge, we propose a dataset-adaptive approach to DR optimization guided by structural complexity metrics. These metrics quantify the intrinsic complexity of a dataset, predicting whether higher-dimensional spaces are necessary to represent it accurately. Since complex datasets are often inaccurately represented in two-dimensional projections, leveraging these metrics enables us to predict the maximum achievable accuracy of DR techniques for a given dataset, eliminating redundant trials in optimizing DR. We introduce the design and theoretical foundations of these structural complexity metrics. We quantitatively verify that our metrics effectively approximate the ground truth complexity of datasets and confirm their suitability for guiding dataset-adaptive DR workflow. Finally, we empirically show that our dataset-adaptive workflow significantly enhances the efficiency of DR optimization without compromising accuracy.&#39;, &#39;uid&#39;: &#39;3d30c2f2-5e29-4f5f-a3bc-05c9fb3e4ea0&#39;, &#39;keywords&#39;: [&#39;imensionality reduction&#39;, &#39;Structural complexity&#39;, &#39;High-dimensional data&#39;, &#39;Optimization&#39;, &#39;Dataset-adaptive workflow&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2507.11984&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: &#39;We publicized the source code&#39;, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_3d30c2f2-5e29-4f5f-a3bc-05c9fb3e4ea0.html"> Dataset-Adaptive Dimensionality Reduction <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Hyeon Jeon, Jeongin Park, Soohyun Lee, Dae Hyun Kim, Sungbok Shin, Jinwook Seo </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Hyeon Jeon </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T14:45:00.000Z &ndash; 2025-11-05T14:57:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1773&#39;, &#39;session_id&#39;: &#39;full10&#39;, &#39;title&#39;: &#39;ClimateSOM: A Visual Analysis Workflow for Climate Ensemble Datasets&#39;, &#39;contributors&#39;: [&#39;Yuya Kawakami&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T14:57:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T14:57:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:09:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Yuya Kawakami&#39;, &#39;email&#39;: &#39;ykawakami@ucdavis.edu&#39;, &#39;affiliation&#39;: &#39;University of California, Davis&#39;}, {&#39;name&#39;: &#39;Daniel Cayan&#39;, &#39;email&#39;: &#39;dcayan@ucsd.edu&#39;, &#39;affiliation&#39;: &#39;Scripps Institution of Oceanography&#39;}, {&#39;name&#39;: &#39;Dongyu Liu&#39;, &#39;email&#39;: &#39;dyuliu@ucdavis.edu&#39;, &#39;affiliation&#39;: &#39;University of California at Davis&#39;}, {&#39;name&#39;: &#39;Kwan-Liu Ma&#39;, &#39;email&#39;: &#39;ma@cs.ucdavis.edu&#39;, &#39;affiliation&#39;: &#39;University of California at Davis&#39;}], &#39;abstract&#39;: &#39;Ensemble datasets are ever more prevalent in various scientific domains. In climate science, ensemble datasets are used to capture variability in projections under plausible future conditions including greenhouse and aerosol emissions. Each ensemble model run produces projections that are fundamentally similar yet meaningfully distinct. Understanding this variability among ensemble model runs and analyzing its magnitude and patterns is a vital task for climate scientists. In this paper, we present ClimateSOM, a visual analysis workflow that leverages a self organizing map (SOM) and Large Language Models (LLMs) to support interactive exploration and interpretation of climate ensemble datasets. The workflow abstracts climate ensemble model runs—spatiotemporal time series—into a distribution over a 2D space that captures the variability among the ensemble model runs using a SOM. LLMs are integrated to assist in sensemaking of this SOM-defined 2D space, the basis for the visual analysis tasks. In all, ClimateSOM enables users to explore the variability among ensemble model runs, identify patterns, compare and cluster the ensemble model runs. To demonstrate the utility of ClimateSOM, we apply the workflow to an ensemble dataset of precipitation projections over California and the Northwestern United States. Furthermore, we conduct a short evaluation of our LLM integration, and conduct an expert review of the visual workflow and the insights from the case studies with six domain experts to evaluate our approach and its utility.&#39;, &#39;uid&#39;: &#39;34e579da-1d6a-4ba7-a6e1-4644a0d2c0b7&#39;, &#39;keywords&#39;: [&#39;Climate visual analytics&#39;, &#39;ensemble visualization&#39;, &#39;self-organizing maps&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_34e579da-1d6a-4ba7-a6e1-4644a0d2c0b7.html"> ClimateSOM: A Visual Analysis Workflow for Climate Ensemble Datasets <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Yuya Kawakami, Daniel Cayan, Dongyu Liu, Kwan-Liu Ma </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Yuya Kawakami </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T14:57:00.000Z &ndash; 2025-11-05T15:09:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1936&#39;, &#39;session_id&#39;: &#39;full10&#39;, &#39;title&#39;: &#39;SEAL: Spatially-resolved Embedding Analysis with Linked Imaging Data&#39;, &#39;contributors&#39;: [&#39;Simon Warchol&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T15:09:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T15:09:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:21:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Simon Warchol&#39;, &#39;email&#39;: &#39;simonwarchol@g.harvard.edu&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Grace Guo&#39;, &#39;email&#39;: &#39;gguo31@g.harvard.edu&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Johannes Knittel&#39;, &#39;email&#39;: &#39;jknittel@seas.harvard.edu&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Dan Freeman&#39;, &#39;email&#39;: &#39;dfreeman@g.harvard.edu&#39;, &#39;affiliation&#39;: &#39;Harvard Medical School&#39;}, {&#39;name&#39;: &#39;Usha Bhalla&#39;, &#39;email&#39;: &#39;usha_bhalla@g.harvard.edu&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Jeremy Muhlich&#39;, &#39;email&#39;: &#39;jeremy_muhlich@hms.harvard.edu&#39;, &#39;affiliation&#39;: &#39;Harvard Medical School&#39;}, {&#39;name&#39;: &#39;Peter Sorger&#39;, &#39;email&#39;: &#39;peter_sorger@hms.harvard.edu&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}, {&#39;name&#39;: &#39;Hanspeter Pfister&#39;, &#39;email&#39;: &#39;pfister@seas.harvard.edu&#39;, &#39;affiliation&#39;: &#39;Harvard University&#39;}], &#39;abstract&#39;: &#34;Dimensionality reduction techniques help analysts make sense of complex, high-dimensional spatial datasets, such as multiplexed tissue imaging, satellite imagery, and astronomical observations, by projecting data attributes into a two-dimensional space. However, these techniques typically abstract away crucial spatial, positional, and morphological contexts, complicating interpretation and limiting insights. To address these limitations, we present SEAL, an interactive visual analytics system designed to bridge the gap between abstract 2D embeddings and their rich spatial imaging context. SEAL introduces a novel hybrid-embedding visualization that preserves image and morphological information while integrating critical high-dimensional feature data. By adapting set visualization methods, SEAL allows analysts to identify, visualize, and compare selections—defined manually or algorithmically—in both the embedding and original spatial views, facilitating a deeper understanding of the spatial arrangement and morphological characteristics of entities of interest. To elucidate differences between selected sets of items, SEAL employs a scalable surrogate model to calculate feature importance scores, identifying the most influential features governing the position of objects within embeddings. These importance scores are visually summarized across selections, with mathematical set operations enabling detailed comparative analyses. We demonstrate SEAL&#39;s effectiveness and versatility through three case studies: colorectal cancer tissue analysis with a pharmacologist, melanoma investigation with a cell biologist, and exploration of sky survey data with an astronomer. These studies underscore the importance of integrating image context into embedding spaces when interpreting complex imaging datasets. Implemented as a standalone tool while also integrating seamlessly with computational notebooks, SEAL provides an interactive platform for spatially informed exploration of high-dimensional datasets, significantly enhancing interpretability and insight generation.&#34;, &#39;uid&#39;: &#39;3eefd0dc-4542-4d3b-8a9e-bd1530cdebab&#39;, &#39;keywords&#39;: [&#39;Dimensionality Reduction&#39;, &#39;Data Visualization&#39;, &#39;Spatial Image Analysis&#39;, &#39;Explainable AI&#39;, &#39;Feature Importance Modeling&#39;], &#39;preprint_link&#39;: &#39;https://www.biorxiv.org/content/10.1101/2025.07.19.665696&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_3eefd0dc-4542-4d3b-8a9e-bd1530cdebab.html"> SEAL: Spatially-resolved Embedding Analysis with Linked Imaging Data <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Simon Warchol, Grace Guo, Johannes Knittel, Dan Freeman, Usha Bhalla, Jeremy Muhlich, Peter Sorger, Hanspeter Pfister </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Simon Warchol </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T15:09:00.000Z &ndash; 2025-11-05T15:21:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-12-1098.R1&#39;, &#39;session_id&#39;: &#39;full10&#39;, &#39;title&#39;: &#39;A Critical Analysis of the Usage of Dimensionality Reduction in Four Domains&#39;, &#39;contributors&#39;: [&#39;Dylan Cashman&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T15:21:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T15:21:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:33:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Dylan Cashman&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Mark Keller&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Hyeon Jeon&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Bum Chul Kwon&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Qianwen Wang&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Dimensionality reduction is used as an important tool for unraveling the complexities of high-dimensional datasets in many fields of science, such as cell biology, chemical informatics, and physics. Visualizations of the dimensionally-reduced data enable scientists to delve into the intrinsic structures of their datasets and align them with established hypotheses. Visualization researchers have thus proposed many dimensionality reduction methods and interactive systems designed to uncover latent structures. At the same time, different scientific domains have formulated guidelines or common workflows for using dimensionality reduction techniques and visualizations for their respective fields. In this work, we present a critical analysis of the usage of dimensionality reduction in scientific domains outside of computer science. First, we conduct a bibliometric analysis of 21,249 academic publications that use dimensionality reduction to observe differences in the frequency of techniques across fields. Next, we conduct a survey of a 71-paper sample from four fields: biology, chemistry, physics, and business. Through this survey, we uncover common workflows, processes, and usage patterns, including the mixed use of confirmatory data analysis to validate a dataset and projection method and exploratory data analysis to then generate more hypotheses. We also find that misinterpretations and inappropriate usage is common, particularly in the visual interpretation of the resulting dimensionally reduced view. Lastly, we compare our observations with recent works in the visualization community in order to match work within our community to potential areas of impact outside our community. By comparing the usage found within scientific fields to the recent research output of the visualization community, we offer both validation of the progress of visualization research into dimensionality reduction and a call for action to produce techniques that meet the needs of scientific use...&#39;, &#39;uid&#39;: &#39;bbe3a438-83bd-4b6a-a694-75d70e7ed2f4&#39;, &#39;keywords&#39;: [&#39;Surveys&#39;, &#39;Data visualization&#39;, &#39;Dimensionality reduction&#39;, &#39;Data analysis&#39;, &#39;Measurement&#39;, &#39;Reviews&#39;, &#39;Physics&#39;, &#39;Electronic mail&#39;, &#39;Computer science&#39;, &#39;Bibliometrics&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2503.08836&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2025.3567989&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_bbe3a438-83bd-4b6a-a694-75d70e7ed2f4.html"> A Critical Analysis of the Usage of Dimensionality Reduction in Four Domains <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Dylan Cashman, Mark Keller, Hyeon Jeon, Bum Chul Kwon, Qianwen Wang </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Dylan Cashman </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T15:21:00.000Z &ndash; 2025-11-05T15:33:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-02-0090&#39;, &#39;session_id&#39;: &#39;full10&#39;, &#39;title&#39;: &#39;Interactive Visual Analysis of Spatial Sensitivities&#39;, &#39;contributors&#39;: [&#39;Marina Evers&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T15:33:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T15:33:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:45:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Marina Evers&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Simon Leistikow&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Hennes Rave&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Lars Linsen&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#34;Sensitivity analyses of simulation ensembles determine how simulation parameters influence the simulation&#39;s outcome. Commonly, one global numerical sensitivity value is computed per simulation parameter. However, when considering 3D spatial simulations, the analysis of localized sensitivities in different spatial regions is of importance in many applications. For analyzing the spatial variation of parameter sensitivity, one needs to compute a spatial sensitivity scalar field per simulation parameter. Given n simulation parameters, we obtain multi-field data consisting of n scalar fields when considering all simulation parameters. We propose an interactive visual analytics solution to analyze the multi-field sensitivity data. It supports the investigation of how strongly and in what way individual parameters influence the simulation outcome, in which spatial regions this is happening, and what the interplay of the simulation parameters is. Its central component is an overview visualization of all sensitivity fields that avoids 3D occlusions by linearizing the data using an adapted scheme of data-driven space-filling curves. The spatial sensitivity values are visualized in a combination of a Horizon Graph and a line chart. We validate our approach by applying it to synthetic and real-world ensemble data.&#34;, &#39;uid&#39;: &#39;e201eb31-fc6e-4bc1-8741-5f4ee5f98e1e&#39;, &#39;keywords&#39;: [&#39;Sensitivity analysis&#39;, &#39;Data visualization&#39;, &#39;Three-dimensional displays&#39;, &#39;Rendering (computer graphics)&#39;, &#39;Task analysis&#39;, &#39;Analytical models&#39;, &#39;Visual analytics&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2408.03817&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2024.3433001&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_e201eb31-fc6e-4bc1-8741-5f4ee5f98e1e.html"> Interactive Visual Analysis of Spatial Sensitivities <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Marina Evers, Simon Leistikow, Hennes Rave, Lars Linsen </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Marina Evers </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T15:33:00.000Z &ndash; 2025-11-05T15:45:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2023-04-0221.R2&#39;, &#39;session_id&#39;: &#39;full10&#39;, &#39;title&#39;: &#39;RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis&#39;, &#39;contributors&#39;: [&#39;Manfred Klaffenboeck&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-05T15:45:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-05T15:45:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-05T15:57:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Manfred Klaffenboeck&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Michael Gleicher&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Johannes Sorger&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Michael Wimmer&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Torsten Moeller&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Visual Parameter Space Analysis (VPSA) enables domain scientists to explore input-output relationships of computational models. Existing VPSA applications often feature multi-view visualizations designed by visualization experts for a specific scenario, making it hard for domain scientists to adapt them to their problems without professional help. We present RSVP, the Rapid Suggestive Visualization Prototyping system encoding VPSA knowledge to enable domain scientists to prototype custom visualization dashboards tailored to their specific needs. The system implements a task-oriented, multi-view visualization recommendation strategy over a visualization design space optimized for VPSA to guide users in meeting their analytical demands. We derived the VPSA knowledge implemented in the system by conducting an extensive meta design study over the body of work on VPSA. We show how this process can be used to perform a data and task abstraction, extract a common visualization design space, and derive a task-oriented VisRec strategy. User studies indicate that the system is user-friendly and can uncover novel insights.&#39;, &#39;uid&#39;: &#39;9f054a2c-3dee-41b8-97e4-d8fe354cbd73&#39;, &#39;keywords&#39;: [&#39;Data visualization&#39;, &#39;Visualization&#39;, &#39;Computational modeling&#39;, &#39;Analytical models&#39;, &#39;Image segmentation&#39;, &#39;Image color analysis&#39;, &#39;Data models&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2409.07105&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2024.3431930&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_9f054a2c-3dee-41b8-97e4-d8fe354cbd73.html"> RSVP for VPSA : A Meta Design Study on Rapid Suggestive Visualization Prototyping for Visual Parameter Space Analysis <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Manfred Klaffenboeck, Michael Gleicher, Johannes Sorger, Michael Wimmer, Torsten Moeller </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Manfred Klaffenboeck </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-05T15:45:00.000Z &ndash; 2025-11-05T15:57:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row my-5"><div class="col-md-8"><p>You may want to also jump to the parent event to see related presentations: <a href="event_v-full.html">VIS Full Papers</a></p></div></div><script src="/static/2025/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script><script>

$(document).ready(function() {
    setInterval(updateSessionStatus, 30 * 1000);
    updateSessionStatus(true)
})

function updateSessionStatus(onFirstLoad) {
    // We need to write the session timings into the page to calculate current/next session.
    // See blueprint_2025.py
    startTime = '2025-11-05T14:45:00+00:00'
    endTime = '2025-11-05T16:00:00+00:00'

    // We take a 8 minute grace period to the start of a session
    const sessionStart = moment(startTime).tz(current_timezone).subtract(8, 'minutes');
    const sessionEnd = moment(endTime).tz(current_timezone);

    const sessionIsCurrent = moment().tz(current_timezone).isBetween(sessionStart, sessionEnd);
    const sessionIsFuture = moment().tz(current_timezone).isBefore(sessionStart);
    const sessionIsPast = moment().tz(current_timezone).isAfter(sessionStart);

    const classesToHide = ['.future_session_alert', '.current_session_alert', '.past_session_alert', '.room_session_stream']
    classesToHide.forEach((c) => { $(c).hide();});
    if (sessionIsCurrent) {
        $('.current_session_alert').show();
    } else if (sessionIsFuture) {
        $('.future_session_alert').show();
    } else {
        // Session is in the future
        $('#zoom_alert').hide();
        $('.past_session_alert').show();
        $('.room_session_stream').show();
    }

    // Update youtube link for older sessions
    // EDIT - We don't need this when the conference isn't live
    if(sessionIsPast){
        const roomidjson = "e2-"+moment(startTime).format('ddd').toLowerCase()+".json"
        // console.log("this session was in:" , roomidjson)

        return fetch("https://virtual-data.ieeevis.org/"+roomidjson, {cache: "no-store"})
        .then(response => response.json())
        .then(data => {
            //console.log(data)
            // console.log('youtube_url: ' + data.youtube_url)
            //$("ytold").attr("href",data.youtube_url)

            // clear link element to avoid multiple appends
            document.getElementById("ytold").innerHTML = '';

            var a = document.createElement('a'); 
            var link = document.createTextNode(data.youtube_url);  
            a.appendChild(link); 
            a.title = "YouTube Link"; 
            a.href = data.youtube_url; 
            
            document.getElementById("ytold").appendChild(a);
        })
        .catch(error => {
            console.log("err: ", error);
        })
    }
    

}

</script></body></html>