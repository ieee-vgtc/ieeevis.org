<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><script src="https://cdn.auth0.com/js/auth0-spa-js/2.1/auth0-spa-js.production.js"></script><script>
              const auth0_domain = "ieeevis.us.auth0.com";
              const auth0_client_id = "oF5BXUklWOjSjUeg5Tzai2DysHITXYhT";
            </script><script src="/static/2025/js/modules/auth0protect.js"></script><script src="https://cdn.jsdelivr.net/npm/d3@6/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/handlebars@4.7.3/dist/handlebars.min.js" integrity="sha256-/PJBs6QWvXijOFIX04kZpLb6ZtSQckdOIavLWKKOgXU=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js" integrity="sha256-WqU1JavFxSAMcLP2WIOI+GB2zWmShMI82mTpLDcqFUg=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js" integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/moment-timezone@0.5.28/builds/moment-timezone-with-data.min.js" integrity="sha256-IWYg4uIC8/erItNXYvLtyYHioRi2zT1TFva8qaAU/ww=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.4.0/dist/umd/popper.min.js"></script><script src="https://cdn.jsdelivr.net/npm/tippy.js@6/dist/tippy-bundle.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/static/2025/js/libs_ext/typeahead.bundle.js"></script><script src="/static/2025/js/data/persistor.js"></script><script src="/static/2025/js/data/api.js"></script><link rel="shortcut icon" href="/static/2025/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha256-YLGeXaapI0/5IgZopewRJcFXomhRMlYYjugPLSyNjTY=" crossorigin="anonymous"><link href="/static/2025/css/Zilla.css" rel="stylesheet"><link href="/static/2025/css/Fira.css" rel="stylesheet"><link rel="stylesheet" href="/static/2025/css/main.css"><link rel="stylesheet" href="/static/2025/css/fa_solid.css"><link rel="stylesheet" href="/static/2025/css/lazy_load.css"><link rel="stylesheet" href="/static/2025/css/typeahead.css"><meta name="twitter:card" content="summary"><meta name="twitter:site" content="@ieeevis"><meta name="twitter:title" content="IEEE VIS 2025 - Session: VIS Full Papers: Analysts, Assemble!"><meta name="twitter:description" content="See the session and its presentations inside."><meta name="twitter:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="image" property="og:image" content="https://ieeevis.b-cdn.net/vis_2021/vis_preview.png"><meta name="description" property="og:description" content="See the session and its presentations inside."><meta name="title" property="og:title" content="Virtual IEEE VIS 2025 - Session: VIS Full Papers: Analysts, Assemble!"><meta property="og:type" content="website"><title>IEEE VIS 2025 Content: VIS Full Papers: Analysts, Assemble!</title></head><body data-bs-spy="scroll" data-bs-target="#nav-scrollspy" style="display: none;"><div class="container mb-5"><div class="tabs"></div><div class="content"><div class="row mt-3"><div class="col-md-8"><nav class="nav-breadcrumb mb-3" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item" aria-current="page"><a href="events.html">All events</a></li><li class="breadcrumb-item"><a href="event_v-full.html">VIS Full Papers</a></li><li class="breadcrumb-item active text-truncate" aria-current="page">Analysts, Assemble!</li></ol></nav><h1 class="session-title">VIS Full Papers: Analysts, Assemble!</h1><h3 class="session-url"><a href="https://ieeevis.org/year/2025/program/event_v-full.html" target="_blank"><span class="fas mr-1">&#xf57c;</span> https://ieeevis.org/year/2025/program/event_v-full.html</a></h3><h3 class="session-chair"><span class="fas mr-1">&#xf007;</span> Session chair: Tamara Munzner </h3><h3 class="session-room mt-4"> Room: Hall E1 </h3><h3 class="session-date"><span class="fas mr-1">&#xf017;</span><span class="format-date-span-full">2025-11-06T13:00:00+00:00 &ndash; 2025-11-06T14:15:00+00:00</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span><br><span style="margin-left: 2rem; font-size: 1rem;" class="timezone tztooltip"><span class="relative-time">2025-11-06T13:00:00+00:00 &ndash; 2025-11-06T14:15:00+00:00</span><span class="current-time tztooltiptext"></span></span></h3></div><div class="col-md-1"></div><div class="col-md-3 session-links"><h5 class="session-info my-4"><a href="#list"><span class="fas mr-2">&#xf358;</span> Jump to event listing </a></h5><h5 class="session-info my-4"><a href="https://data.tech.ieeevis.org/storage/v1/object/public/ics/vis2025/full3.ics"><span class="fas mr-2">&#xf073;</span> Add to Calendar</a></h5></div></div><div class="row my-5 discord-public-link hide-auth-controls"><div class="col-md-8"><p><span class="fas mx-1">&#xf086;</span><a href="https://discord.com/channels/1422883912660549696/1430945308053078097" target="_blank">Discord link</a></p></div></div><div class="row my-5"><div class="col-md-8"><p>Recordings will be made available after the session.</p></div></div><hr><div class="row my-4"><div class="col-md-8"><h2 class="room_session_descriptor d-block py-2"><a name="list">Presentations in this session:</a></h2></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1157&#39;, &#39;session_id&#39;: &#39;full3&#39;, &#39;title&#39;: &#39;Conch: Competitive Debate Analysis via Visualizing Clash Points and Hierarchical Strategies&#39;, &#39;contributors&#39;: [&#39;Qianhe Chen&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T13:00:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T13:00:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T13:12:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Qianhe Chen&#39;, &#39;email&#39;: &#39;qianhechen01@gmail.com&#39;, &#39;affiliation&#39;: &#39;Huazhong University of Science and Technology&#39;}, {&#39;name&#39;: &#39;Yong WANG&#39;, &#39;email&#39;: &#39;yong-wang@ntu.edu.sg&#39;, &#39;affiliation&#39;: &#39;Nanyang Technological University&#39;}, {&#39;name&#39;: &#39;Yixin Yu&#39;, &#39;email&#39;: &#39;sakaaanayu@gmail.com&#39;, &#39;affiliation&#39;: &#39;Huazhong University of Science and Technology&#39;}, {&#39;name&#39;: &#39;Xiyuan Zhu&#39;, &#39;email&#39;: &#39;addinistrator.fallindepart@gmail.com&#39;, &#39;affiliation&#39;: &#39;Huazhong University of Science and Technology&#39;}, {&#39;name&#39;: &#39;Xuerou Yu&#39;, &#39;email&#39;: &#39;2874849065@qq.com&#39;, &#39;affiliation&#39;: &#39;Huazhong University of Science and Technology&#39;}, {&#39;name&#39;: &#39;Ran Wang&#39;, &#39;email&#39;: &#39;rex_wang@hust.edu.cn&#39;, &#39;affiliation&#39;: &#39;School of Journalism and Information Communication, Huazhong University of Science and Technology&#39;}], &#39;abstract&#39;: &#34;In-depth analysis of competitive debates is essential for participants to develop argumentative skills and refine strategies, and further improve their debating performance. However, manual analysis of unstructured and unlabeled textual records of debating is time-consuming and ineffective, as it is challenging to reconstruct contextual semantics and track logical connections from raw data. To address this, we propose Conch, an interactive visualization system that systematically analyzes both what is debated and how it is debated. In particular, we propose a novel parallel spiral visualization that compactly traces the multidimensional evolution of clash points and participant interactions throughout debate process. In addition, we leverage large language models with well-designed prompts to automatically identify critical debate elements such as clash points, disagreements, viewpoints, and strategies, enabling participants to understand the debate context comprehensively. Finally, through two case studies on real-world debates and a carefully-designed user study, we demonstrate Conch&#39;s effectiveness and usability for competitive debate analysis.&#34;, &#39;uid&#39;: &#39;da138859-6a6c-4df2-813b-6a70e20d04a1&#39;, &#39;keywords&#39;: [&#39;Competitive debate&#39;, &#39;debate analysis&#39;, &#39;clash point&#39;, &#39;visual analytics&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2507.14482/&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: &#39;Our work introduces Conch, an interactive system that analyzes competitive debates through a novel spiral visualization and a hierarchical semantic framework. We provide all prompts, the full strategy framework, and the mathematical model of Conch in the supplemental materials, and we plan to open-source the implementation after further organization and documentation.&#39;, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_da138859-6a6c-4df2-813b-6a70e20d04a1.html"> Conch: Competitive Debate Analysis via Visualizing Clash Points and Hierarchical Strategies <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Qianhe Chen, Yong WANG, Yixin Yu, Xiyuan Zhu, Xuerou Yu, Ran Wang </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Qianhe Chen </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T13:00:00.000Z &ndash; 2025-11-06T13:12:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1335&#39;, &#39;session_id&#39;: &#39;full3&#39;, &#39;title&#39;: &#39;Calli-VA: A Visual Analytics System for Analyzing and Comparing Chinese Calligraphic Styles&#39;, &#39;contributors&#39;: [&#39;Jincheng Li&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T13:12:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T13:12:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T13:24:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Jincheng Li&#39;, &#39;email&#39;: &#39;jinchengli@bnu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Beijing Normal University&#39;}, {&#39;name&#39;: &#39;Jinpeng Wu&#39;, &#39;email&#39;: &#39;202422081016@mail.bnu.edu.cn&#39;, &#39;affiliation&#39;: &#39;北京师范大学 Beijing Normal University (中国大陆 Mainland, China)&#39;}, {&#39;name&#39;: &#39;Shaocong Tan&#39;, &#39;email&#39;: &#39;tanshaocong0108@gmail.com&#39;, &#39;affiliation&#39;: &#39;Peking University&#39;}, {&#39;name&#39;: &#39;Lin Du&#39;, &#39;email&#39;: &#39;202431081039@mail.bnu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Beijing Normal University&#39;}, {&#39;name&#39;: &#39;Yu Zhang&#39;, &#39;email&#39;: &#39;yuzhang94@outlook.com&#39;, &#39;affiliation&#39;: &#39;University of Oxford&#39;}, {&#39;name&#39;: &#39;Chaofan Yang&#39;, &#39;email&#39;: &#39;chaofanyang@pku.edu.cn&#39;, &#39;affiliation&#39;: &#39;Peking University&#39;}, {&#39;name&#39;: &#39;Jiadi Zhang&#39;, &#39;email&#39;: &#39;2206595287@pku.edu.cn&#39;, &#39;affiliation&#39;: &#39;Peking University&#39;}, {&#39;name&#39;: &#39;Rebecca Ruige Xu&#39;, &#39;email&#39;: &#39;rxu@syr.edu&#39;, &#39;affiliation&#39;: &#39;Syracuse University&#39;}, {&#39;name&#39;: &#39;Rui Shi&#39;, &#39;email&#39;: &#39;shirui@pku.edu.cn&#39;, &#39;affiliation&#39;: &#39;Peking University&#39;}, {&#39;name&#39;: &#39;Lu Bai&#39;, &#39;email&#39;: &#39;bailu@bnu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Beijing Normal University&#39;}, {&#39;name&#39;: &#39;Xiaoru Yuan&#39;, &#39;email&#39;: &#39;xiaoru.yuan@pku.edu.cn&#39;, &#39;affiliation&#39;: &#39;Peking University&#39;}], &#39;abstract&#39;: &#39;Chinese calligraphy is a quintessential element of Chinese cultural heritage. Analyzing and comparing calligraphic styles not only enhances the appreciation, learning, and advancement of calligraphy but also provides valuable insights into ancient China. However, such analysis remains challenging due to the limited scalability and possible inconsistencies of qualitative methods, as well as usability and misalignment issues in conventional quantitative approaches. We propose Calli-VA, a visual analytics system, to address these challenges. Calli-VA extracts character images and their corresponding strokes from original works and characterizes each character using systematic criteria. During analysis, the system defines the analysis scope by overview and uncovers relationships between characters. Explanation and recommendation mechanisms are integrated to help users understand patterns and guide further exploration. A documentation feature allows users to record and share their findings. We demonstrate the effectiveness of Calli-VA through three case studies and expert feedback.&#39;, &#39;uid&#39;: &#39;e61c0f73-21a5-4e16-bdb6-4038e74770ae&#39;, &#39;keywords&#39;: [&#39;Chinese calligraphy style analysis&#39;, &#39;image analysis&#39;, &#39;digital humanities&#39;, &#39;visual analytics.&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_e61c0f73-21a5-4e16-bdb6-4038e74770ae.html"> Calli-VA: A Visual Analytics System for Analyzing and Comparing Chinese Calligraphic Styles <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Jincheng Li, Jinpeng Wu, Shaocong Tan, Lin Du, Yu Zhang, Chaofan Yang, Jiadi Zhang, Rebecca Ruige Xu, Rui Shi, Lu Bai, Xiaoru Yuan </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Jincheng Li </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T13:12:00.000Z &ndash; 2025-11-06T13:24:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1558&#39;, &#39;session_id&#39;: &#39;full3&#39;, &#39;title&#39;: &#39;OwnershipTracker: A Visual Analytics Approach to Uncovering Historical Book Ownership Patterns&#39;, &#39;contributors&#39;: [&#39;Yiwen Xing&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T13:24:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T13:24:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T13:36:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Yiwen Xing&#39;, &#39;email&#39;: &#39;yiwen.xing@kcl.ac.uk&#39;, &#39;affiliation&#39;: &#34;King&#39;s College London&#34;}, {&#39;name&#39;: &#39;Meilai Ji&#39;, &#39;email&#39;: &#39;jimeilai222@gmail.com&#39;, &#39;affiliation&#39;: &#34;King&#39;s College London&#34;}, {&#39;name&#39;: &#39;Cristina Dondi&#39;, &#39;email&#39;: &#39;c.dondi@cerl.org&#39;, &#39;affiliation&#39;: &#39;University of Oxford&#39;}, {&#39;name&#39;: &#39;Alfie Abdul-Rahman&#39;, &#39;email&#39;: &#39;alfie.abdulrahman@gmail.com&#39;, &#39;affiliation&#39;: &#34;King&#39;s College London&#34;}], &#39;abstract&#39;: &#39;Ownership relationships of early printed books from the 15th century reveal complex patterns of distribution and possession, offering valuable insights for historical research. This paper presents OwnershipTracker, a visual analytics application developed to explore and trace these relationships using data from the Material Evidence in Incunabula (MEI) database. OwnershipTracker integrates bibliographic records, copy-specific data, and book provenance and ownership details, enabling users to uncover intricate ownership sequences over time. The application combines several visualization techniques, including network graphs to map connections between owners, timelines for temporal analysis, chord diagrams to quantify transfer patterns, and a distinctive, collaboratively designed spiderweb-like diagram highlighting converging and dispersing ownership transfers through specific owners. Developed iteratively with input from historical book researchers, the application underwent multiple refinements to align with domain research requirements. A summative evaluation with domain experts showcased the tool’s ability to address the defined requirements and tasks. The final version of OwnershipTracker is deployed and accessible at: https://booktracker.nms.kcl.ac.uk/ownership.&#39;, &#39;uid&#39;: &#39;4e91945c-334a-4953-87ed-1564920f05dc&#39;, &#39;keywords&#39;: [&#39;Design study&#39;, &#39;visualization application&#39;, &#39;human-centered design&#39;], &#39;preprint_link&#39;: &#39;https://kclpure.kcl.ac.uk/portal/en/publications/ownershiptracker-a-visual-analytics-approach-to-uncovering-histor&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_4e91945c-334a-4953-87ed-1564920f05dc.html"> OwnershipTracker: A Visual Analytics Approach to Uncovering Historical Book Ownership Patterns <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Yiwen Xing, Meilai Ji, Cristina Dondi, Alfie Abdul-Rahman </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Yiwen Xing </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T13:24:00.000Z &ndash; 2025-11-06T13:36:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-1645&#39;, &#39;session_id&#39;: &#39;full3&#39;, &#39;title&#39;: &#39;Interactive Hybrid Rice Breeding with Parametric Dual Projection&#39;, &#39;contributors&#39;: [&#39;Pengcheng Wang&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T13:36:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T13:36:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T13:48:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Changjian Chen&#39;, &#39;email&#39;: &#39;changjianchen@hnu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Hunan University&#39;}, {&#39;name&#39;: &#39;Pengcheng Wang&#39;, &#39;email&#39;: &#39;wangpengcheng@hnu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Hunan University&#39;}, {&#39;name&#39;: &#39;Fei Lyu&#39;, &#39;email&#39;: &#39;feilv@hnu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Hunan University&#39;}, {&#39;name&#39;: &#39;Zhuo Tang&#39;, &#39;email&#39;: &#39;ztang@hnu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Hunan University&#39;}, {&#39;name&#39;: &#39;Li Yang&#39;, &#39;email&#39;: &#39;yanglixt@hnu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Hunan University&#39;}, {&#39;name&#39;: &#39;Long Wang&#39;, &#39;email&#39;: &#39;wanglong8591@hnu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Hunan University&#39;}, {&#39;name&#39;: &#39;Yong Cai&#39;, &#39;email&#39;: &#39;caiyong911@hnu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Hunan University&#39;}, {&#39;name&#39;: &#39;Feng Yu&#39;, &#39;email&#39;: &#39;feng_yu@hnu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Hunan University&#39;}, {&#39;name&#39;: &#39;Kenli Li&#39;, &#39;email&#39;: &#39;lkl@hnu.edu.cn&#39;, &#39;affiliation&#39;: &#39;Hunan University&#39;}], &#39;abstract&#39;: &#39;Hybrid rice breeding crossbreeds different rice lines and cultivates the resulting hybrids in fields to select those with desirable agronomic traits, such as higher yields. Recently, genomic selection has emerged as an efficient way for hybrid rice breeding. It predicts the traits of hybrids based on their genes, which helps exclude many undesired hybrids, largely reducing the workload of field cultivation. However, due to the limited accuracy of genomic prediction models, breeders still need to combine their experience with the models to identify regulatory genes that control traits and select hybrids, which remains a time-consuming process. To ease this process, in this paper, we proposed a visual analysis method to facilitate interactive hybrid rice breeding. Regulatory gene identification and hybrid selection naturally ensemble a dual-analysis task. Therefore, we developed a parametric dual projection method with theoretical guarantees to facilitate interactive dual analysis. Based on this dual projection method, we further developed a gene visualization and a hybrid visualization to verify the identified regulatory genes and hybrids. The effectiveness of our method is demonstrated through the quantitative evaluation of the parametric dual projection method, identified regulatory genes and desired hybrids in the case study, and positive feedback from breeders.&#39;, &#39;uid&#39;: &#39;4009fec8-7d38-4e00-9e7d-f9493fb32941&#39;, &#39;keywords&#39;: [&#39;Hybrid rice breeding&#39;, &#39;dual projection&#39;, &#39;genomic prediction&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/abs/2507.11848&#39;, &#39;has_pdf&#39;: True, &#39;paper_award&#39;: None, &#39;doi&#39;: None, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_4009fec8-7d38-4e00-9e7d-f9493fb32941.html"> Interactive Hybrid Rice Breeding with Parametric Dual Projection <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Changjian Chen, Pengcheng Wang, Fei Lyu, Zhuo Tang, Li Yang, Long Wang, Yong Cai, Feng Yu, Kenli Li </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Pengcheng Wang </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T13:36:00.000Z &ndash; 2025-11-06T13:48:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-07-0651.R2&#39;, &#39;session_id&#39;: &#39;full3&#39;, &#39;title&#39;: &#39;ASight: Fine-tuning Auto-Scheduling Optimizations for Model Deployment via Visual Analytics&#39;, &#39;contributors&#39;: [&#39;Quan Li&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T13:48:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T13:48:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T14:00:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Laixin Xie&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Chenyang Zhang&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Ruofei Ma&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Xingxing Xing&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Wei Wan&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Quan Li&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;Upon completing the design and training phases, deploying a deep learning model to specific hardware becomes necessary prior to its implementation in practical applications. To enhance the performance of the model, the developers must optimize it to decrease inference latency. Auto-scheduling, an automated approach that generates optimization schemes, offers a feasible option for large-scale auto-deployment. Nevertheless, the low-level code generated by auto-scheduling closely resembles hardware coding and may present challenges for human comprehension, thereby hindering future manual optimization efforts. In this study, we introduce ASight, a visual analytics system to assist engineers in identifying performance bottlenecks, comprehending the auto-generated low-level code, and obtaining insights from auto-scheduling optimizations. We develop a subgraph matching algorithm capable of identifying graph isomorphism among Intermediate Representations to track performance bottlenecks from low-level metrics to high-level computational graphs. To address the substantial profiling metrics involved in auto-scheduling and derive optimization design principles by summarizing commonalities among auto-scheduling optimizations, we propose an enhanced visualization for the large search space of auto-scheduling. We validate the effectiveness of ASight through two case studies, one focused on a local machine and the other on a data center, along with a quantitative experiment exploring optimization design principles.&#39;, &#39;uid&#39;: &#39;0db7ecd3-a51e-4c72-bc36-d06d31c08c7f&#39;, &#39;keywords&#39;: [&#39;Optimization&#39;, &#39;Codes&#39;, &#39;Hardware&#39;, &#39;Schedules&#39;, &#39;Runtime&#39;, &#39;Measurement&#39;, &#39;Visual analytics&#39;, &#39;Optimal scheduling&#39;, &#39;Aerodynamics&#39;, &#39;Training&#39;], &#39;preprint_link&#39;: None, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2025.3574194&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_0db7ecd3-a51e-4c72-bc36-d06d31c08c7f.html"> ASight: Fine-tuning Auto-Scheduling Optimizations for Model Deployment via Visual Analytics <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Laixin Xie, Chenyang Zhang, Ruofei Ma, Xingxing Xing, Wei Wan, Quan Li </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Quan Li </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T13:48:00.000Z &ndash; 2025-11-06T14:00:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row mb-20"><div class="col-md-8 session-listing"> {&#39;slot_id&#39;: &#39;v-full-TVCG2024-02-0089&#39;, &#39;session_id&#39;: &#39;full3&#39;, &#39;title&#39;: &#39;PonziLens+: Visualizing Bytecode Actions for Smart Ponzi Scheme Identification&#39;, &#39;contributors&#39;: [&#39;Wen Xiaolin&#39;], &#39;paper_type&#39;: &#39;Full&#39;, &#39;presentation_mode&#39;: &#39;Premise&#39;, &#39;time_stamp&#39;: &#39;2025-11-06T14:00:00.000Z&#39;, &#39;time_start&#39;: &#39;2025-11-06T14:00:00.000Z&#39;, &#39;time_end&#39;: &#39;2025-11-06T14:12:00.000Z&#39;, &#39;authors&#39;: [{&#39;name&#39;: &#39;Xiaolin Wen&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Tai D. Nguyen&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Shaolun Ruan&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Qiaomu Shen&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Jun Sun&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Feida Zhu&#39;, &#39;email&#39;: None}, {&#39;name&#39;: &#39;Yong Wang&#39;, &#39;email&#39;: None}], &#39;abstract&#39;: &#39;With the prevalence of smart contracts, smart Ponzi schemes have become a common fraud on blockchain and have caused significant financial loss to cryptocurrency investors in the past few years. Despite the critical importance of detecting smart Ponzi schemes, a reliable and transparent identification approach adaptive to various smart Ponzi schemes is still missing. To fill the research gap, we first extract semantic-meaningful actions to represent the execution behaviors specified in smart contract bytecodes, which are derived from a literature review and in-depth interviews with domain experts. We then propose PonziLens+, a novel visual analytic approach that provides an intuitive and reliable analysis of Ponzi-scheme-related features within these execution behaviors. PonziLens+ has three visualization modules that intuitively reveal all potential behaviors of a smart contract, highlighting fraudulent features across three levels of detail. It can help smart contract investors and auditors achieve confident identification of any smart Ponzi schemes. We conducted two case studies and in-depth user interviews with 12 domain experts and common investors to evaluate PonziLens+. The results demonstrate the effectiveness and usability of PonziLens+ in achieving an effective identification of smart Ponzi schemes.&#39;, &#39;uid&#39;: &#39;65c676ce-bbd8-4a3f-a650-73e39c0dc99f&#39;, &#39;keywords&#39;: [&#39;Smart contracts&#39;, &#39;Blockchains&#39;, &#39;Codes&#39;, &#39;Fraud&#39;, &#39;Source coding&#39;, &#39;Data visualization&#39;, &#39;Flow graphs&#39;, &#39;Feature extraction&#39;, &#39;Reliability&#39;, &#39;Investment&#39;], &#39;preprint_link&#39;: &#39;https://arxiv.org/pdf/2412.18470&#39;, &#39;has_pdf&#39;: False, &#39;paper_award&#39;: None, &#39;doi&#39;: &#39;10.1109/TVCG.2024.3516379&#39;, &#39;fno&#39;: None, &#39;open_access_supplemental_question&#39;: None, &#39;open_access_supplemental_link&#39;: None} <h3 class="session-list-title"><a href="paper_65c676ce-bbd8-4a3f-a650-73e39c0dc99f.html"> PonziLens+: Visualizing Bytecode Actions for Smart Ponzi Scheme Identification <span class="fas mr-1">&#xf0c1;</span></a></h3><h5 class="session-list-presenter"> Authors: Xiaolin Wen, Tai D. Nguyen, Shaolun Ruan, Qiaomu Shen, Jun Sun, Feida Zhu, Yong Wang </h5><h4 class="session-list-presenter mt-3"><span class="fas mr-1">&#xf21d;</span> Wen Xiaolin </h4><h5 class="session-list-time"><span class="fas mr-1">&#xf017;</span><span class="format-date-span">2025-11-06T14:00:00.000Z &ndash; 2025-11-06T14:12:00.000Z</span><span alt="Change timezone on schedule page" class="timezone tztooltip"><strong>GMT<span class="selectedTimezone">-0600</span></strong><span class="tztooltiptext">Change your timezone on the schedule page</span></span></h5></div></div><div class="row my-5"><div class="col-md-8"><p>You may want to also jump to the parent event to see related presentations: <a href="event_v-full.html">VIS Full Papers</a></p></div></div><script src="/static/2025/js/views/timezone.js"></script></div></div><script type="text/javascript">
      $(document).ready(function () {
        if (location.hash !== "") {
          $('a[href="' + location.hash + '"]').tab("show");
        }

        $("a[data-toggle='tab']").on("shown.bs.tab", function (e) {
          var hash = $(e.target).attr("href");
          if (hash.substr(0, 1) == "#") {
            var position = $(window).scrollTop();
            location.replace("#" + hash.substr(1));
            $(window).scrollTop(position);
          }
        });

        const current_tz = getTimezone();
        $("#tzCurrent").html(moment().tz(current_tz).format("Z"));

        function getTimezone() {
          const urlTz = window.getUrlParameter && getUrlParameter('tz');
          if (urlTz) return urlTz;

          const storageTz = window.localStorage.getItem("tz")
          if (storageTz) return storageTz;

          return moment.tz.guess();
        }

        // find all parseable dates and localize them
        function formatDate(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY"))
        }

        function formatDateTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz)
          console.log("current_tz is ", current_tz, " element.text() is ", element.text(), " and atime is ", atime)
          element.html(atime.format("dddd, MMMM Do, YYYY @ HH:mm"))
        }

        function formatTimeSpan(element, includeDate) {
          const current_tz = getTimezone();
          console.log("current_tz is ", current_tz)
          // return '';
          // let parts = element.text().split(/[(\s-\s)|]/);
          let parts = element.text().split(" – ");
          let start = parts[0] && parts[0].trim();
          let end = parts[1] && parts[1].trim();

          let starttime = moment.utc(start).clone().tz(current_tz)
          let endtime = moment.utc(end).clone().tz(current_tz)

          //if(starttime.diff(endtime, "days") <= 0) // Making difference between the "D" numbers because the diff function
          // seems like not considering the timezone
          if (starttime.format("D") == endtime.format("D")) {
            element.html(starttime.format(
              "dddd, MMM Do, YYYY @ HH:mm") + " &ndash; " + endtime.format(
              "HH:mm"));
          } else {
            element.html(starttime.format(
              "dddd, MMM Do @ HH:mm") + " &ndash; " + endtime.format(
              "dddd, MMM Do @ HH:mm"))
          }
        }

        function formatTime(element) {
          const current_tz = getTimezone();
          let atime = moment.utc(element.text()).clone().tz(current_tz);
          element.html(atime.format("HH:mm"));
        }

        $(".format-just-date").each((_i, element) => {
          formatDate($(element));
        });

        $(".format-date").each((_i, element) => {
          formatDateTime($(element));
        });

        $(".format-date-span").each((_i, element) => {
          formatTimeSpan($(element));
        });

        $(".format-date-span-short").each((_i, element) => {
          formatTimeSpan($(element), false);
        });

        $(".format-date-span-full").each((_i, element) => {
          formatTimeSpan($(element), true);
        });

        $(".format-time").each((_i, element) => {
          formatTime($(element));
        });

        function gtag() {
          dataLayer.push(arguments);
        }

        
        
        
      });
    </script><script>

$(document).ready(function() {
    setInterval(updateSessionStatus, 30 * 1000);
    updateSessionStatus(true)
})

function updateSessionStatus(onFirstLoad) {
    // We need to write the session timings into the page to calculate current/next session.
    // See blueprint_2025.py
    startTime = '2025-11-06T13:00:00+00:00'
    endTime = '2025-11-06T14:15:00+00:00'

    // We take a 8 minute grace period to the start of a session
    const sessionStart = moment(startTime).tz(current_timezone).subtract(8, 'minutes');
    const sessionEnd = moment(endTime).tz(current_timezone);

    const sessionIsCurrent = moment().tz(current_timezone).isBetween(sessionStart, sessionEnd);
    const sessionIsFuture = moment().tz(current_timezone).isBefore(sessionStart);
    const sessionIsPast = moment().tz(current_timezone).isAfter(sessionStart);

    const classesToHide = ['.future_session_alert', '.current_session_alert', '.past_session_alert', '.room_session_stream']
    classesToHide.forEach((c) => { $(c).hide();});
    if (sessionIsCurrent) {
        $('.current_session_alert').show();
    } else if (sessionIsFuture) {
        $('.future_session_alert').show();
    } else {
        // Session is in the future
        $('#zoom_alert').hide();
        $('.past_session_alert').show();
        $('.room_session_stream').show();
    }

    // Update youtube link for older sessions
    // EDIT - We don't need this when the conference isn't live
    if(sessionIsPast){
        const roomidjson = "e1-"+moment(startTime).format('ddd').toLowerCase()+".json"
        // console.log("this session was in:" , roomidjson)

        return fetch("https://virtual-data.ieeevis.org/"+roomidjson, {cache: "no-store"})
        .then(response => response.json())
        .then(data => {
            //console.log(data)
            // console.log('youtube_url: ' + data.youtube_url)
            //$("ytold").attr("href",data.youtube_url)

            // clear link element to avoid multiple appends
            document.getElementById("ytold").innerHTML = '';

            var a = document.createElement('a'); 
            var link = document.createTextNode(data.youtube_url);  
            a.appendChild(link); 
            a.title = "YouTube Link"; 
            a.href = data.youtube_url; 
            
            document.getElementById("ytold").appendChild(a);
        })
        .catch(error => {
            console.log("err: ", error);
        })
    }
    

}

</script></body></html>